{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b07cb405-5c12-4e51-b7e9-270d2dc253fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "gc.collect()  \n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5300f956-9e75-452b-a512-a692acdbfe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ customization\n",
    "length = 24\n",
    "width = 24\n",
    "n1 = 13\n",
    "n2 = 13\n",
    "judge = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "16701a33-9fac-4b80-86ed-2ec25d248864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############### Problem context formulation\n",
    "\n",
    "def generate_rectangular_grid_sg(length, width, n1, n2=2, judge=0, z=0, height=0):\n",
    "    x_points = [i * (length / n1) for i in range(n1 + 1)]\n",
    "    y_points = [j * (width / n2) for j in range(n2, -1, -1)]\n",
    "\n",
    "    grid_points = []\n",
    "    for x in x_points:\n",
    "        for y in y_points:\n",
    "            if y == width / 2:\n",
    "                grid_points.append([x, y, height])\n",
    "            else:\n",
    "                grid_points.append([x, y, z])\n",
    "\n",
    "    if judge == 1:\n",
    "        corners = [\n",
    "            [x_points[0], y_points[0], z],\n",
    "            [x_points[0], y_points[-1], z],\n",
    "            [x_points[-1], y_points[0], z],\n",
    "            [x_points[-1], y_points[-1], z]\n",
    "        ]\n",
    "        grid_points = [point for point in grid_points if point not in corners]\n",
    "\n",
    "    return grid_points\n",
    "\n",
    "def plot_grid(grid_points, length, width):\n",
    "    x = [point[0] for point in grid_points]\n",
    "    y = [point[1] for point in grid_points]\n",
    "    z = [point[2] for point in grid_points]\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(x, y, z, c='r', marker='o', s=50, label='Grid Points')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def generate_connectivity_matrix(new_coords):\n",
    "    indexed_points = {tuple(point): idx + 1 for idx, point in enumerate(new_coords)}\n",
    "    connectivity = []\n",
    "\n",
    "    x_values = sorted(set(point[0] for point in new_coords))\n",
    "    for x in x_values:\n",
    "        points_on_line = [point for point in new_coords if point[0] == x]\n",
    "        points_on_line.sort(key=lambda p: p[1], reverse=True) \n",
    "\n",
    "        for i in range(len(points_on_line) - 1):\n",
    "            node1 = indexed_points[tuple(points_on_line[i])]\n",
    "            node2 = indexed_points[tuple(points_on_line[i + 1])]\n",
    "            connectivity.append([node1, node2])\n",
    "\n",
    "    y_values = sorted(set(point[1] for point in new_coords))\n",
    "    for y in y_values:\n",
    "        points_on_line = [point for point in new_coords if point[1] == y]\n",
    "        points_on_line.sort(key=lambda p: p[0])  \n",
    "\n",
    "        for i in range(len(points_on_line) - 1):\n",
    "            node1 = indexed_points[tuple(points_on_line[i])]\n",
    "            node2 = indexed_points[tuple(points_on_line[i + 1])]\n",
    "            connectivity.append([node1, node2])\n",
    "\n",
    "    return connectivity\n",
    "\n",
    "grid_points = generate_rectangular_grid_sg(length, width, n1, n2, judge)\n",
    "connectivity = generate_connectivity_matrix(grid_points)\n",
    "plot_grid(grid_points, length, width)\n",
    "\n",
    "\n",
    "###########################################################################################################################################################\n",
    "n_dof_per_node = 6  # Degrees of freedom per node\n",
    "grid_points = torch.tensor(grid_points, device=device, dtype=torch.float32)\n",
    "total_dof = n_dof_per_node * len(grid_points)\n",
    "\n",
    "########## Surrounding fixed\n",
    "x_max = grid_points[:, 0].max()\n",
    "x_min = grid_points[:, 0].min()\n",
    "y_max = grid_points[:, 1].max()\n",
    "y_min = grid_points[:, 1].min()\n",
    "\n",
    "Fixed_nodes = torch.where(\n",
    "    (grid_points[:, 1] == y_max) |  # y = y_max\n",
    "    (grid_points[:, 1] == y_min)    # y = y_min\n",
    ")[0]\n",
    "\n",
    "Fixed_nodes += 1\n",
    "Free_nodes = []\n",
    "\n",
    "n_elements = len(connectivity)\n",
    "n_nodes = len(grid_points)\n",
    "\n",
    "for i in range(1, n_nodes + 1):\n",
    "    if i not in Fixed_nodes:\n",
    "        Free_nodes.append(i)\n",
    "\n",
    "\n",
    "####### BCs\n",
    "fixed_dof = []\n",
    "for node in Fixed_nodes:\n",
    "    fixed_dof.extend([(node - 1) * 6 + i for i in range(6)])\n",
    "\n",
    "##########################################################################################################################################################\n",
    "##########################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07b82f9c-1387-4a36-94f5-8d0e0556bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Force condition\n",
    "def Force_mat(F_value, F_type, total_dof=total_dof, Free_nodes=Free_nodes, judge=0):\n",
    "    \n",
    "    F = torch.zeros(total_dof, dtype=torch.float32, device=device)\n",
    "    \n",
    "    if judge == 0:\n",
    "        F_value = torch.tensor([F_value] * len(Free_nodes), device=device) * 1000 # The force value/direction\n",
    "        F_type = [F_type] * len(Free_nodes)  # The force type\n",
    "    else:\n",
    "        F_value = torch.tensor(F_value) * 1000\n",
    "        F_value = torch.tensor(F_type)\n",
    "    \n",
    "    for idx, i in enumerate(Free_nodes):\n",
    "        F[6 * (i - 1) + F_type[idx]] = F_value[idx]  # unit: KN / KN*m\n",
    "        \n",
    "    return F, F_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1f89d49-4151-4fff-a3ef-8198e2f203f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Symmetry_shaper(grid_points, connectivity, free_nodes):\n",
    "    \n",
    "    connectivity = torch.tensor(connectivity, dtype=torch.long, device=device)\n",
    "    free_nodes = torch.tensor(free_nodes, dtype=torch.long, device=device)\n",
    "    \n",
    "    result_indices_x = []  \n",
    "    result_indices_y = []  \n",
    "    prev_x_list = []  \n",
    "    prev_y_list = []  \n",
    "    \n",
    "    for node in free_nodes:\n",
    "        node_coord = grid_points[node - 1] \n",
    "        x = node_coord[0]\n",
    "\n",
    "        if x in prev_x_list:\n",
    "            x_index = prev_x_list.index(x)\n",
    "        else:\n",
    "            result_indices_x.append([])\n",
    "            prev_x_list.append(x)\n",
    "            x_index = len(prev_x_list) - 1\n",
    "        \n",
    "        mask = (connectivity == node).any(dim=1)\n",
    "        candidate_indices = torch.where(mask)[0] # indexing connectivity\n",
    "        \n",
    "        for idx in candidate_indices:\n",
    "            conn = connectivity[idx]\n",
    "            coord1 = grid_points[conn[0] - 1]\n",
    "            coord2 = grid_points[conn[1] - 1]\n",
    "\n",
    "            if coord1[0] == coord2[0] and coord1[0] == x:\n",
    "                result_indices_x[x_index].append(idx.item())  \n",
    "    \n",
    "    for node in free_nodes:\n",
    "        node_coord = grid_points[node - 1]  \n",
    "        y = node_coord[1]\n",
    "        \n",
    "        if y in prev_y_list:\n",
    "            y_index = prev_y_list.index(y)\n",
    "        else:\n",
    "            result_indices_y.append([])\n",
    "            prev_y_list.append(y)\n",
    "            y_index = len(prev_y_list) - 1\n",
    "        \n",
    "        mask = (connectivity == node).any(dim=1)\n",
    "        candidate_indices = torch.where(mask)[0]\n",
    "           \n",
    "        for idx in candidate_indices:\n",
    "            conn = connectivity[idx]\n",
    "            coord1 = grid_points[conn[0] - 1]\n",
    "            coord2 = grid_points[conn[1] - 1]\n",
    "            if coord1[1] == coord2[1] and coord1[1] == y:\n",
    "                result_indices_y[y_index].append(idx.item()) \n",
    "\n",
    "    max_len_x = max(len(indices) for indices in result_indices_x) if result_indices_x else 0\n",
    "    max_len_y = max(len(indices) for indices in result_indices_y) if result_indices_y else 0\n",
    "    \n",
    "    for indices in result_indices_x:\n",
    "        indices += [-1] * (max_len_x - len(indices))\n",
    "    for indices in result_indices_y:\n",
    "        indices += [-1] * (max_len_y - len(indices))\n",
    "    \n",
    "    result_x = torch.tensor(result_indices_x, dtype=torch.long, device=device)\n",
    "    result_y = torch.tensor(result_indices_y, dtype=torch.long, device=device)\n",
    "    result_x = torch.unique(result_x, dim=1)\n",
    "    result_y = torch.unique(result_y, dim=1)\n",
    "\n",
    "    len_y = result_y.size(0)\n",
    "    half_y = len_y // 2\n",
    "    len_x = result_x.size(0)\n",
    "    half_x = len_x // 2\n",
    "    \n",
    "    y_upper = result_y[:half_y]  \n",
    "    y_lower = result_y[half_y:]\n",
    "    y_lower = torch.flip(y_lower, dims=[0])\n",
    "    x_upper = result_x[:half_x] \n",
    "    x_lower = result_x[half_x:]\n",
    "    x_lower = torch.flip(x_lower, dims=[0])\n",
    "    \n",
    "    idx_Y = torch.cat((y_upper, y_lower), dim=1)\n",
    "    idx_X = torch.cat((x_upper, x_lower), dim=1)\n",
    "\n",
    "    return idx_X, idx_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8f65d40c-f8d6-4e82-a533-2c27229836e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fdm(state_idx, grid_points, new_node_coords, \n",
    "            connectivity, Free_nodes, Fixed_nodes, force, SED,\n",
    "            save_dir=\"results\", max_states=6):\n",
    "    \"\"\"\n",
    "    多状态组合图保存函数\n",
    "    \n",
    "    参数:\n",
    "        state_idx: 状态序号 (0=初始, 1=第cut次, 2=第2*cut次...)\n",
    "        max_states: 组合图中最多显示的状态数\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 数据准备\n",
    "    x_orig = grid_points[:, 0].cpu().detach().numpy()\n",
    "    y_orig = grid_points[:, 1].cpu().detach().numpy()\n",
    "    z_orig = grid_points[:, 2].cpu().detach().numpy()\n",
    "    \n",
    "    x_fdm = new_node_coords[:, 0].cpu().detach().numpy()\n",
    "    y_fdm = new_node_coords[:, 1].cpu().detach().numpy()\n",
    "    z_fdm = new_node_coords[:, 2].cpu().detach().numpy()\n",
    "    \n",
    "    # 计算当前高度\n",
    "    current_height = max(z_fdm)\n",
    "    \n",
    "    # 初始化图形容器\n",
    "    if not hasattr(save_fdm, 'fig'):\n",
    "        save_fdm.fig = plt.figure(figsize=(24, 16))\n",
    "        save_fdm.axes = [save_fdm.fig.add_subplot(2, 3, i+1, projection='3d') \n",
    "                       for i in range(max_states)]\n",
    "        plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "        save_fdm.saved_states = 0\n",
    "        save_fdm.max_z = 0  # 用于统一z轴尺度\n",
    "    \n",
    "    # 检查是否已存满\n",
    "    if save_fdm.saved_states >= max_states:\n",
    "        filename = os.path.join(save_dir, f\"FDM_States_{max_states}.png\")\n",
    "        save_fdm.fig.savefig(filename, dpi=200, bbox_inches='tight')\n",
    "        plt.close(save_fdm.fig)\n",
    "        delattr(save_fdm, 'fig')\n",
    "        delattr(save_fdm, 'axes')\n",
    "        delattr(save_fdm, 'saved_states')\n",
    "        delattr(save_fdm, 'max_z')\n",
    "        print(f\"Saved full states to {filename}\")\n",
    "        return\n",
    "    \n",
    "    # 更新最大z值（用于统一坐标尺度）\n",
    "    if current_height > save_fdm.max_z:\n",
    "        save_fdm.max_z = current_height\n",
    "    \n",
    "    # 获取当前子图并清除旧内容\n",
    "    ax = save_fdm.axes[save_fdm.saved_states]\n",
    "    ax.clear()\n",
    "    \n",
    "    # ========== 可视化绘制 ==========\n",
    "    # 1. 绘制原始网格（浅灰色虚线）\n",
    "    for i, j in connectivity:\n",
    "        ax.plot([x_orig[i-1], x_orig[j-1]],\n",
    "                [y_orig[i-1], y_orig[j-1]],\n",
    "                [z_orig[i-1], z_orig[j-1]], \n",
    "                ':', color='#CCCCCC', linewidth=0.8, alpha=0.7)\n",
    "    \n",
    "    # 2. 绘制当前状态网格\n",
    "    color = '#1f77b4' if state_idx == 0 else '#ff7f0e'  # 初始蓝色，迭代橙色\n",
    "    for i, j in connectivity:\n",
    "        ax.plot([x_fdm[i-1], x_fdm[j-1]],\n",
    "                [y_fdm[i-1], y_fdm[j-1]],\n",
    "                [z_fdm[i-1], z_fdm[j-1]], \n",
    "                '-', color=color, linewidth=1.8, alpha=0.9)\n",
    "    \n",
    "    # 3. 标记固定节点（黑色实心圆）\n",
    "    for node in Fixed_nodes:\n",
    "        ax.scatter(x_fdm[node-1], y_fdm[node-1], z_fdm[node-1],\n",
    "                  c='black', s=50, marker='o', alpha=0.8)\n",
    "    \n",
    "    # 4. 添加高度标注（替换原来的力值标注）\n",
    "    ax.text(x=0.05, y=0.90, z=save_fdm.max_z*1.05,\n",
    "           s=f\"Height: {current_height:.2f}m\\nSE: {SED:.8f} \", \n",
    "           transform=ax.transAxes, \n",
    "           fontsize=10,\n",
    "           bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    # ========== 子图装饰 ==========\n",
    "    ax.set_xlabel('X (m)', fontsize=9)\n",
    "    ax.set_ylabel('Y (m)', fontsize=9)\n",
    "    ax.set_zlabel('Z (m)', fontsize=9)\n",
    "    ax.set_title(f\"State {state_idx}\" if state_idx > 0 else \"Initial State\", \n",
    "                fontsize=11, pad=12)\n",
    "    ax.set_zlim(0, save_fdm.max_z * 1.1)  # 统一z轴尺度\n",
    "    ax.view_init(elev=35, azim=45)\n",
    "    ax.grid(True, linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # 更新状态计数器\n",
    "    save_fdm.saved_states += 1\n",
    "    \n",
    "    # 如果是最后一个状态，立即保存\n",
    "    if save_fdm.saved_states == max_states:\n",
    "        filename = os.path.join(save_dir, f\"FDM_States_{max_states}.png\")\n",
    "        save_fdm.fig.savefig(filename, dpi=200, bbox_inches='tight')\n",
    "        plt.close(save_fdm.fig)\n",
    "        delattr(save_fdm, 'fig')\n",
    "        delattr(save_fdm, 'axes')\n",
    "        delattr(save_fdm, 'saved_states')\n",
    "        delattr(save_fdm, 'max_z')\n",
    "        print(f\"Saved full states to {filename}\")\n",
    "\n",
    "\n",
    "def finalize_fdm(save_dir=\"results\", completed=False):\n",
    "    \"\"\"\n",
    "    最终化处理函数\n",
    "    \n",
    "    参数:\n",
    "        save_dir: 保存目录\n",
    "        completed: 是否完成所有迭代 (True=已完成全部迭代，False=提前终止)\n",
    "    \"\"\"\n",
    "    if not hasattr(save_fdm, 'fig') or save_fdm.saved_states == 0:\n",
    "        return\n",
    "    \n",
    "    # 如果已完成所有迭代，保存当前进度（不强制填满）\n",
    "    if completed:\n",
    "        filename = os.path.join(save_dir, \n",
    "                              f\"FDM_States_completed_{save_fdm.saved_states}.png\")\n",
    "    # 如果是提前终止，保存上一次有效迭代\n",
    "    else:\n",
    "        # 回退一个状态，因为最后一次迭代可能不完整\n",
    "        save_fdm.saved_states = max(0, save_fdm.saved_states - 1)\n",
    "        filename = os.path.join(save_dir,\n",
    "                              f\"FDM_States_partial_{save_fdm.saved_states+1}.png\")\n",
    "    \n",
    "    # 保存图像\n",
    "    save_fdm.fig.savefig(filename, dpi=200, bbox_inches='tight')\n",
    "    plt.close(save_fdm.fig)\n",
    "    \n",
    "    # 打印保存信息\n",
    "    if completed:\n",
    "        print(f\"Saved completed states ({save_fdm.saved_states}/{len(save_fdm.axes)}) to {filename}\")\n",
    "    else:\n",
    "        print(f\"Saved last valid state ({save_fdm.saved_states+1}) to {filename}\")\n",
    "    \n",
    "    # 清理属性\n",
    "    for attr in ['fig', 'axes', 'saved_states', 'max_z']:\n",
    "        if hasattr(save_fdm, attr):\n",
    "            delattr(save_fdm, attr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e20f2d8-0295-4e2a-a6dc-7589f69af5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### FDM part \n",
    "C = torch.zeros(n_elements, n_nodes, dtype=torch.float32, device=device)\n",
    "for n, (i, j) in enumerate(connectivity):\n",
    "    C[n, i - 1] = 1\n",
    "    C[n, j - 1] = -1\n",
    "    \n",
    "px= torch.zeros(len(Free_nodes), 1, dtype=torch.float32, device=device)\n",
    "py = torch.zeros(len(Free_nodes), 1, dtype=torch.float32, device=device)\n",
    "pz = torch.zeros(len(Free_nodes), 1, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "fixed_idces = torch.tensor([node - 1 for node in Fixed_nodes], device=device)\n",
    "free_node_indices = torch.tensor([node - 1 for node in Free_nodes], device=device)\n",
    "\n",
    "CF = C[:, fixed_idces]\n",
    "CN = C[:, free_node_indices]\n",
    "\n",
    "def FDM(Q, F_value, CN=CN, CF=CF, px=px, py=py, pz=pz, \n",
    "        fixed_idces=fixed_idces, free_node_indices=free_node_indices,\n",
    "        node_coords=grid_points):\n",
    "    \n",
    "    pz[:, 0] = F_value\n",
    "        \n",
    "    Dn = torch.matmul(torch.transpose(CN, 0, 1), torch.matmul(Q, CN))\n",
    "    DF = torch.matmul(torch.transpose(CN, 0, 1), torch.matmul(Q, CF))\n",
    "    \n",
    "    \n",
    "    xF = node_coords[fixed_idces, 0].unsqueeze(1)\n",
    "    yF = node_coords[fixed_idces, 1].unsqueeze(1)\n",
    "    zF = node_coords[fixed_idces, 2].unsqueeze(1)\n",
    "    \n",
    "    xN = torch.matmul(torch.inverse(Dn), (px - torch.matmul(DF, xF)))\n",
    "    yN = torch.matmul(torch.inverse(Dn), (py - torch.matmul(DF, yF)))\n",
    "    zN = torch.matmul(torch.inverse(Dn), (pz - torch.matmul(DF, zF)))\n",
    "        \n",
    "    \n",
    "    new_node_coords = node_coords.clone()\n",
    "    new_node_coords[free_node_indices, 0] = xN.squeeze()\n",
    "    new_node_coords[free_node_indices, 1] = yN.squeeze()\n",
    "    new_node_coords[free_node_indices, 2] = zN.squeeze()\n",
    "    \n",
    "    return new_node_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "47d20880-8995-44f8-8eb3-b90ef080b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### FE part\n",
    "D_radius = 0.75\n",
    "D_young_modulus = 10e9 \n",
    "D_shear_modulus = 0.7e9 \n",
    "D_poisson_ratio = 0.3\n",
    "cross_section_angle_a = 0  \n",
    "cross_section_angle_b = 0  \n",
    "a_small_number = 1e-10\n",
    "\n",
    "def rotation(v, k, theta):\n",
    "    \"\"\"Rotation of vector v around axis k by angle theta.\"\"\"\n",
    "    k = k / torch.norm(k)  # Normalize k\n",
    "    cross_product = torch.cross(k, v)\n",
    "    dot_product = torch.dot(k, v)\n",
    "\n",
    "    # Ensure theta is a tensor\n",
    "    theta = torch.tensor(theta, dtype=torch.float32, device=device) if not isinstance(theta, torch.Tensor) else theta\n",
    "\n",
    "    v_rotated = v * torch.cos(theta) + cross_product * torch.sin(theta) + k * dot_product * (1 - torch.cos(theta))\n",
    "    return v_rotated\n",
    "\n",
    "class Beam:\n",
    "    def __init__(self, node_coordinates, R=D_radius, young_modulus=D_young_modulus,\n",
    "                 shear_modulus=D_shear_modulus, poisson_ratio=D_poisson_ratio, Beta_a=cross_section_angle_a,\n",
    "                 Beta_b=cross_section_angle_b):\n",
    "        self.node_coordinates = node_coordinates  # (2, 3) tensor for node coordinates\n",
    "\n",
    "        # Material and geometry\n",
    "        self.radius = R\n",
    "        self.young_modulus = young_modulus\n",
    "        self.shear_modulus = shear_modulus\n",
    "        self.poisson_ratio = poisson_ratio\n",
    "\n",
    "        # Cross-sectional properties\n",
    "        self.length = torch.norm(self.node_coordinates[1] - self.node_coordinates[0])  # Length of the beam\n",
    "        self.Iy = (torch.pi * self.radius ** 4) / 4 \n",
    "        self.Iz = self.Iy\n",
    "        self.A = torch.pi * self.radius ** 2\n",
    "        self.J = (torch.pi * self.radius ** 4) / 2\n",
    "\n",
    "        # Stiffness components\n",
    "        self.S_u = self.young_modulus * self.A / self.length\n",
    "        self.S_v1a = 12 * self.young_modulus * self.Iy / (self.length ** 3)\n",
    "        self.S_v1b = 6 * self.young_modulus * self.Iy / (self.length ** 2)\n",
    "        self.S_v2a = 12 * self.young_modulus * self.Iz / (self.length ** 3)\n",
    "        self.S_v2b = 6 * self.young_modulus * self.Iz / (self.length ** 2)\n",
    "        self.S_theta1a = 6 * self.young_modulus * self.Iy / (self.length ** 2)\n",
    "        self.S_theta1b = 4 * self.young_modulus * self.Iy / self.length\n",
    "        self.S_theta1c = 2 * self.young_modulus * self.Iy / self.length\n",
    "        self.S_theta2a = 6 * self.young_modulus * self.Iz / (self.length ** 2)\n",
    "        self.S_theta2b = 4 * self.young_modulus * self.Iz / self.length\n",
    "        self.S_theta2c = 2 * self.young_modulus * self.Iz / self.length\n",
    "        self.S_Tr = self.shear_modulus * self.J / self.length\n",
    "\n",
    "        # Section rotations at the two ends\n",
    "        self.Beta_a = Beta_a\n",
    "        self.Beta_b = Beta_b\n",
    "\n",
    "    def get_element_stiffness_matrix(self):\n",
    "        \"\"\"Element stiffness matrix.\"\"\"\n",
    "        K_element = torch.tensor([\n",
    "            [self.S_u, 0, 0, 0, 0, 0, -self.S_u, 0, 0, 0, 0, 0],\n",
    "            [0, self.S_v1a, 0, 0, 0, self.S_theta1a, 0, -self.S_v1a, 0, 0, 0, self.S_theta1a],\n",
    "            [0, 0, self.S_v2a, 0, -self.S_theta2a, 0, 0, 0, -self.S_v2a, 0, -self.S_theta2a, 0],\n",
    "            [0, 0, 0, self.S_Tr, 0, 0, 0, 0, 0, -self.S_Tr, 0, 0],\n",
    "            [0, 0, -self.S_v2b, 0, self.S_theta2b, 0, 0, 0, self.S_v2b, 0, self.S_theta2c, 0],\n",
    "            [0, self.S_v1b, 0, 0, 0, self.S_theta1b, 0, -self.S_v1b, 0, 0, 0, self.S_theta1c],\n",
    "            [-self.S_u, 0, 0, 0, 0, 0, self.S_u, 0, 0, 0, 0, 0],\n",
    "            [0, -self.S_v1a, 0, 0, 0, -self.S_theta1a, 0, self.S_v1a, 0, 0, 0, -self.S_theta1a],\n",
    "            [0, 0, -self.S_v2a, 0, self.S_theta2a, 0, 0, 0, self.S_v2a, 0, self.S_theta2a, 0],\n",
    "            [0, 0, 0, -self.S_Tr, 0, 0, 0, 0, 0, self.S_Tr, 0, 0],\n",
    "            [0, 0, -self.S_v2b, 0, self.S_theta2c, 0, 0, 0, self.S_v2b, 0, self.S_theta2b, 0],\n",
    "            [0, self.S_v1b, 0, 0, 0, self.S_theta1c, 0, -self.S_v1b, 0, 0, 0, self.S_theta1b],\n",
    "        ], dtype=torch.float32, device=device)\n",
    "\n",
    "        return K_element\n",
    "\n",
    "    def System_Transform(self):\n",
    "        \"\"\"Coordinate transformation matrix.\"\"\"\n",
    "        vector_x = self.node_coordinates[1, 0] - self.node_coordinates[0, 0]\n",
    "        vector_y = self.node_coordinates[1, 1] - self.node_coordinates[0, 1]\n",
    "        vector_z = self.node_coordinates[1, 2] - self.node_coordinates[0, 2]\n",
    "        length = torch.norm(self.node_coordinates[1] - self.node_coordinates[0])\n",
    "        \n",
    "        z_value = torch.clamp(vector_z / length, min=-1 + 1e-6, max=1 - 1e-6)\n",
    "        ceta = torch.acos(z_value)\n",
    "        value = vector_x / torch.sqrt(vector_y ** 2 + vector_x ** 2 + a_small_number)\n",
    "        value = torch.clamp(value, min=-1 + 1e-6, max=1 - 1e-6)\n",
    "        alpha = torch.acos(value)\n",
    "\n",
    "        Projection_Z_x = - vector_z / length * torch.sin(alpha)\n",
    "        Projection_Z_y = - vector_z / length * torch.cos(alpha)\n",
    "        Projection_Z_z = torch.cos(torch.pi / 2 - ceta)\n",
    "\n",
    "        V_projection = torch.stack([Projection_Z_x, Projection_Z_y, Projection_Z_z])\n",
    "        X_axis = torch.stack([vector_x / length, vector_y / length, vector_z / length])\n",
    "        Z_axis_a = rotation(V_projection, X_axis, self.Beta_a)\n",
    "        Y_axis_a = rotation(Z_axis_a, X_axis, -torch.pi / 2)\n",
    "        Z_axis_a = Z_axis_a / torch.norm(Z_axis_a)\n",
    "        Y_axis_a = Y_axis_a / torch.norm(Y_axis_a)\n",
    "\n",
    "        lambda_matrix = torch.stack([X_axis, Y_axis_a, Z_axis_a], dim=0)\n",
    "        matrix_T = torch.zeros((12, 12), dtype=torch.float32, device=device)\n",
    "        for i in range(0, 12, 3):\n",
    "            matrix_T[i:i + 3, i:i + 3] = lambda_matrix\n",
    "        return matrix_T\n",
    "\n",
    "    def nodal_transform(self):\n",
    "        \"\"\"Coordinate transformation matrix.\"\"\"\n",
    "        vector_x = self.node_coordinates[1, 0] - self.node_coordinates[0, 0]\n",
    "        vector_y = self.node_coordinates[1, 1] - self.node_coordinates[0, 1]\n",
    "        vector_z = self.node_coordinates[1, 2] - self.node_coordinates[0, 2]\n",
    "        length = torch.norm(self.node_coordinates[1] - self.node_coordinates[0])\n",
    "        \n",
    "        z_value = torch.clamp(vector_z / length, min=-1 + 1e-6, max=1 - 1e-6)\n",
    "        ceta = torch.acos(z_value)\n",
    "        value = vector_x / torch.sqrt(vector_y ** 2 + vector_x ** 2 + a_small_number)\n",
    "        value = torch.clamp(value, min=-1 + 1e-6, max=1 - 1e-6)\n",
    "        alpha = torch.acos(value)\n",
    "\n",
    "        Projection_Z_x = - vector_z / length * torch.sin(alpha)\n",
    "        Projection_Z_y = - vector_z / length * torch.cos(alpha)\n",
    "        Projection_Z_z = torch.cos(torch.pi / 2 - ceta)\n",
    "\n",
    "        V_projection = torch.stack([Projection_Z_x, Projection_Z_y, Projection_Z_z])\n",
    "        X_axis = torch.stack([vector_x / length, vector_y / length, vector_z / length])\n",
    "        Z_axis_a = rotation(V_projection, X_axis, self.Beta_a)\n",
    "        Y_axis_a = rotation(Z_axis_a, X_axis, -torch.pi / 2)\n",
    "        Z_axis_a = Z_axis_a / torch.norm(Z_axis_a)\n",
    "        Y_axis_a = Y_axis_a / torch.norm(Y_axis_a)\n",
    "\n",
    "        lambda_matrix = torch.stack([X_axis, Y_axis_a, Z_axis_a], dim=0)\n",
    "        return lambda_matrix\n",
    "\n",
    "\n",
    "def assemble_stiffness_matrix(beams, n_nodes, n_dof_per_node, connectivity):\n",
    "    \"\"\"Global stiffness matrix assembly.\"\"\"\n",
    "    total_dof = n_nodes * n_dof_per_node  # Total degrees of freedom\n",
    "    K_global = torch.zeros((total_dof, total_dof), dtype=torch.float32, device=device)\n",
    "    \n",
    "    for idx, (i, j) in enumerate(connectivity):\n",
    "        Matrix_T = beams[idx].System_Transform()  # Get transformation matrix\n",
    "        K_element = torch.matmul(torch.transpose(Matrix_T, 0, 1),\n",
    "                                 torch.matmul(beams[idx].get_element_stiffness_matrix(), Matrix_T))\n",
    "\n",
    "        start_idx = (i - 1) * n_dof_per_node\n",
    "        end_idx = (j - 1) * n_dof_per_node\n",
    "        K_global[start_idx:start_idx + 6, start_idx:start_idx + 6] += K_element[0:6, 0:6]\n",
    "        K_global[end_idx:end_idx + 6, end_idx:end_idx + 6] += K_element[6:12, 6:12]\n",
    "        K_global[start_idx:start_idx + 6, end_idx:end_idx + 6] += K_element[0:6, 6:12]\n",
    "        K_global[end_idx:end_idx + 6, start_idx:start_idx + 6] += K_element[6:12, 0:6]\n",
    "\n",
    "    return K_global\n",
    "\n",
    "def robust_solve(K_global, F, fixed_dof, max_attempts=3):\n",
    "    \n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        reg = 1e-6 * torch.eye(K_global.shape[0], device=K_global.device)\n",
    "        reg[fixed_dof, fixed_dof] = 0  \n",
    "        K_reg = K_global + reg\n",
    "        \n",
    "        try:\n",
    "            displacements = torch.linalg.solve(\n",
    "                K_reg.to(torch.float64), \n",
    "                F.to(torch.float64)\n",
    "            )\n",
    "            return displacements.to(K_global.dtype)\n",
    "            \n",
    "        except RuntimeError:\n",
    "            diag = torch.diag(K_global)\n",
    "            extreme_mask = (diag > 1e12) & (~torch.isin(torch.arange(len(diag)), torch.tensor(fixed_dof)))  \n",
    "            K_reg[extreme_mask] = 0\n",
    "            K_reg[:, extreme_mask] = 0\n",
    "            K_reg[extreme_mask, extreme_mask] = 1e12  \n",
    "            \n",
    "            K_reg[fixed_dof, :] = 0\n",
    "            K_reg[:, fixed_dof] = 0\n",
    "            K_reg[fixed_dof, fixed_dof] = 1e10  \n",
    "            \n",
    "            try:\n",
    "                displacements, info = torch.linalg.cg(\n",
    "                    K_reg.to(torch.float64),\n",
    "                    F.to(torch.float64),\n",
    "                    maxiter=5000,\n",
    "                    atol=1e-6\n",
    "                )\n",
    "                if info > 0:\n",
    "                    raise RuntimeError(\"CG nah nah\")\n",
    "                return displacements.to(K_global.dtype)\n",
    "                \n",
    "            except:\n",
    "                K_pinv = torch.linalg.pinv(K_reg)\n",
    "                K_pinv[fixed_dof, :] = 0  \n",
    "                displacements = K_pinv @ F\n",
    "                print(\"警告：使用伪逆求解，精度可能降低\")\n",
    "                return displacements\n",
    "                \n",
    "        attempts += 1\n",
    "    \n",
    "    raise RuntimeError(\"无法求解线性系统\")\n",
    "\n",
    "\n",
    "def Strain_E(node_coords, connectivity, fixed_dof, F):\n",
    "    # Element Assembly\n",
    "    Beam_lens = []\n",
    "    beams = []\n",
    "    for connection in connectivity:\n",
    "        node_1_coords = node_coords[connection[0] - 1]\n",
    "        node_2_coords = node_coords[connection[1] - 1]\n",
    "        beam = Beam(node_coordinates=torch.stack([node_1_coords, node_2_coords]),\n",
    "                    R=D_radius, young_modulus=D_young_modulus,\n",
    "                    shear_modulus=D_shear_modulus, poisson_ratio=D_poisson_ratio, Beta_a=cross_section_angle_a,\n",
    "                    Beta_b=cross_section_angle_b)\n",
    "        beams.append(beam)\n",
    "        Beam_lens.append(beam.length)\n",
    "    \n",
    "    # Stiffness renewal\n",
    "    K_global = assemble_stiffness_matrix(beams, n_nodes=len(node_coords), n_dof_per_node=6, connectivity=connectivity)\n",
    "    K_global[fixed_dof, :] = 0\n",
    "    K_global[:, fixed_dof] = 0\n",
    "    K_global[fixed_dof, fixed_dof] = 1e10\n",
    "\n",
    "    displacements = robust_solve(K_global, F, fixed_dof)\n",
    "\n",
    "    # Compute strain energy\n",
    "    strain_energy_list = []\n",
    "    force_list = []\n",
    "    ASE_list = []\n",
    "    V_list = []\n",
    "    Local_d = torch.zeros(len(connectivity), 12, dtype=torch.float32, device=device)\n",
    "    for n, (i, j) in enumerate(connectivity):\n",
    "        matrix_T = beams[n].System_Transform()\n",
    "        Tep_displacements = torch.cat(\n",
    "            [displacements[6 * (i - 1):6 * (i - 1) + 6], displacements[6 * (j - 1):6 * (j - 1) + 6]], dim=0)\n",
    "        Local_d_n = torch.matmul(Tep_displacements, matrix_T.T)\n",
    "        Local_d[n, :] = Local_d_n.clone()\n",
    "        K_l = beams[n].get_element_stiffness_matrix()\n",
    "        strain_energy_list.append(0.5 * torch.matmul(Local_d_n, torch.matmul(K_l, Local_d_n.reshape(-1, 1))))\n",
    "        force_list.append(torch.matmul(K_l, Local_d_n.reshape(-1, 1)))\n",
    "        ASE_list.append(0.5 * (Local_d_n[0]-Local_d_n[6]) * beams[n].S_u * (Local_d_n[0]-Local_d_n[6]))  \n",
    "        V_list.append(beams[n].A * beams[n].length)\n",
    "    \n",
    "     \n",
    "    \n",
    "    Strain_energy = torch.stack(strain_energy_list)\n",
    "    forces = torch.stack(force_list)\n",
    "    ASE = torch.stack(ASE_list)\n",
    "    lens = torch.stack(Beam_lens)\n",
    "    # epsilon = Local_d[:, 0] / lens\n",
    "    # Axial_d = Local_d[:, 0]\n",
    "    V = torch.stack(V_list)\n",
    "    SED = Strain_energy / lens \n",
    "    R = torch.var(SED)\n",
    "    \n",
    "    return Strain_energy, forces, displacements, ASE, lens, R, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b0eee265-1543-4bc1-97cc-052afac52100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_difference_gradient(q, idx_X, idx_Y, r, F_value, connectivity, fixed_dof, F_fe, h=1e-6):\n",
    "    ini = time.time()\n",
    "    n_params = q.shape[0]\n",
    "    grad = torch.zeros_like(q)\n",
    "    \n",
    "    for i in range(n_params):\n",
    "        # 创建扰动变量（避免原地修改）\n",
    "        q_plus = q.detach().clone()\n",
    "        q_minus = q.detach().clone()\n",
    "        \n",
    "        # 施加扰动（注意：必须创建新Tensor）\n",
    "        q_plus[i] += h\n",
    "        q_minus[i] -= h\n",
    "        \n",
    "        # 正向扰动计算\n",
    "        q_vec_plus = torch.zeros(n_elements, device=q.device)\n",
    "        for j in range(len(idx_X)):\n",
    "            q_vec_plus[idx_X[j,:]] = q_plus[j]\n",
    "        for j in range(len(idx_Y)):\n",
    "            q_vec_plus[idx_Y[j,:]] = q_plus[j+len(idx_X)]\n",
    "        SE_plus = Strain_E(FDM(torch.diag(q_vec_plus/r), F_value), connectivity, fixed_dof, F_fe)[0].sum()\n",
    "        \n",
    "        # 负向扰动计算\n",
    "        q_vec_minus = torch.zeros_like(q_vec_plus)\n",
    "        for j in range(len(idx_X)):\n",
    "            q_vec_minus[idx_X[j,:]] = q_minus[j]\n",
    "        for j in range(len(idx_Y)):\n",
    "            q_vec_minus[idx_Y[j,:]] = q_minus[j+len(idx_X)]\n",
    "        SE_minus = Strain_E(FDM(torch.diag(q_vec_minus/r), F_value), connectivity, fixed_dof, F_fe)[0].sum()\n",
    "        \n",
    "        # 中心差分\n",
    "        grad[i] = (SE_plus - SE_minus) / (2 * h)\n",
    "        \n",
    "    end = time.time() - ini\n",
    "    print(end)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6a0336ab-bc02-4f04-895b-42c2e68ea4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(q, gradients, step):\n",
    "    \n",
    "    q.data -= gradients / torch.norm(gradients ) * step\n",
    "\n",
    "    return q\n",
    "    \n",
    "def check_available_memory():\n",
    "    \"\"\"返回当前可用CPU内存（MB）\"\"\"\n",
    "    return psutil.virtual_memory().available / (1024 ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "86fd1b29-f434-459c-aba0-02a7417ef84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r tensor(-0.0010)\n"
     ]
    }
   ],
   "source": [
    "############### Formulating :::::\n",
    "####### Gradient descent\n",
    "step = 0.001\n",
    "epochs = 400\n",
    "# Initilizing\n",
    "patience = 20\n",
    "count = 0\n",
    "idx_X, idx_Y = Symmetry_shaper(grid_points, connectivity, Free_nodes)\n",
    "####### Force Condition\n",
    "\n",
    "_, F_value = Force_mat(- 1, 2)\n",
    "F_fe_g, _ = Force_mat(-1, 2)\n",
    "\n",
    "F_fe = F_fe_g\n",
    "\n",
    "r = 1 / torch.max(F_value)\n",
    "\n",
    "print('r', r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8cb6bac7-335e-40b4-88d1-66be149fe042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ite 0\n",
      "Iter 0 - Available Memory: 2394.23 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3161152.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9177e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0000, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9963e-01,  9.9962e-01,  9.9962e-01,  9.9962e-01,  9.9962e-01,\n",
      "         9.9962e-01,  9.9962e-01, -2.5936e-06, -3.2533e-06, -3.5697e-06,\n",
      "        -4.0625e-06, -4.9898e-06, -5.3282e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 0: Normalized Gradient = 0.05105757340788841, Adaptive learning rate = 0.001\n",
      "ite 1\n",
      "Iter 1 - Available Memory: 8636.97 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4432, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3161894.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9221e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0080, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9926e-01,  9.9925e-01,  9.9924e-01,  9.9924e-01,  9.9924e-01,\n",
      "         9.9924e-01,  9.9924e-01, -2.5927e-06, -3.2523e-06, -3.5688e-06,\n",
      "        -4.0611e-06, -4.9889e-06, -5.3280e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 2\n",
      "Iter 2 - Available Memory: 7578.01 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4433, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3162628., grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9264e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0160, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9889e-01,  9.9887e-01,  9.9887e-01,  9.9886e-01,  9.9886e-01,\n",
      "         9.9886e-01,  9.9886e-01, -2.5912e-06, -3.2509e-06, -3.5659e-06,\n",
      "        -4.0595e-06, -4.9880e-06, -5.3272e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 3\n",
      "Iter 3 - Available Memory: 7125.62 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4434, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3163365.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9307e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0240, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9852e-01,  9.9850e-01,  9.9849e-01,  9.9848e-01,  9.9848e-01,\n",
      "         9.9848e-01,  9.9848e-01, -2.5896e-06, -3.2494e-06, -3.5647e-06,\n",
      "        -4.0574e-06, -4.9872e-06, -5.3242e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 4\n",
      "Iter 4 - Available Memory: 6667.49 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4435, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3164100.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9350e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0320, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9814e-01,  9.9812e-01,  9.9811e-01,  9.9810e-01,  9.9810e-01,\n",
      "         9.9810e-01,  9.9810e-01, -2.5883e-06, -3.2479e-06, -3.5633e-06,\n",
      "        -4.0565e-06, -4.9842e-06, -5.3243e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 5\n",
      "Iter 5 - Available Memory: 6363.46 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4436, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3164841., grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9393e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0401, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9777e-01,  9.9775e-01,  9.9773e-01,  9.9772e-01,  9.9772e-01,\n",
      "         9.9772e-01,  9.9772e-01, -2.5870e-06, -3.2446e-06, -3.5612e-06,\n",
      "        -4.0532e-06, -4.9818e-06, -5.3225e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 5: Normalized Gradient = 0.051033731549978256, Adaptive learning rate = 0.001\n",
      "ite 6\n",
      "Iter 6 - Available Memory: 6073.16 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4437, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3165578.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9436e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0481, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9740e-01,  9.9737e-01,  9.9735e-01,  9.9734e-01,  9.9734e-01,\n",
      "         9.9734e-01,  9.9733e-01, -2.5851e-06, -3.2438e-06, -3.5599e-06,\n",
      "        -4.0522e-06, -4.9790e-06, -5.3212e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 7\n",
      "Iter 7 - Available Memory: 5931.38 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4438, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3166318.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9480e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0561, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9703e-01,  9.9700e-01,  9.9698e-01,  9.9697e-01,  9.9696e-01,\n",
      "         9.9696e-01,  9.9695e-01, -2.5843e-06, -3.2414e-06, -3.5569e-06,\n",
      "        -4.0506e-06, -4.9785e-06, -5.3197e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 8\n",
      "Iter 8 - Available Memory: 5795.10 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4439, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3167058.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9523e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0642, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9666e-01,  9.9662e-01,  9.9660e-01,  9.9659e-01,  9.9658e-01,\n",
      "         9.9657e-01,  9.9657e-01, -2.5824e-06, -3.2396e-06, -3.5553e-06,\n",
      "        -4.0488e-06, -4.9774e-06, -5.3189e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 9\n",
      "Iter 9 - Available Memory: 5649.84 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4440, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3167802.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9567e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0722, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9629e-01,  9.9624e-01,  9.9622e-01,  9.9621e-01,  9.9620e-01,\n",
      "         9.9619e-01,  9.9619e-01, -2.5815e-06, -3.2395e-06, -3.5562e-06,\n",
      "        -4.0465e-06, -4.9755e-06, -5.3171e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 10\n",
      "Iter 10 - Available Memory: 5526.12 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4441, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3168541., grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9610e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0803, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9592e-01,  9.9587e-01,  9.9584e-01,  9.9583e-01,  9.9582e-01,\n",
      "         9.9581e-01,  9.9581e-01, -2.5798e-06, -3.2373e-06, -3.5535e-06,\n",
      "        -4.0455e-06, -4.9749e-06, -5.3163e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 10: Normalized Gradient = 0.05100938677787781, Adaptive learning rate = 0.001\n",
      "ite 11\n",
      "Iter 11 - Available Memory: 5401.48 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4441, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3169284.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9653e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0883, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9555e-01,  9.9549e-01,  9.9546e-01,  9.9545e-01,  9.9544e-01,\n",
      "         9.9543e-01,  9.9543e-01, -2.5787e-06, -3.2364e-06, -3.5511e-06,\n",
      "        -4.0434e-06, -4.9721e-06, -5.3162e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 12\n",
      "Iter 12 - Available Memory: 5291.07 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4442, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3170028.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9697e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.0964, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9518e-01,  9.9512e-01,  9.9508e-01,  9.9507e-01,  9.9506e-01,\n",
      "         9.9505e-01,  9.9505e-01, -2.5771e-06, -3.2339e-06, -3.5490e-06,\n",
      "        -4.0417e-06, -4.9704e-06, -5.3137e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 13\n",
      "Iter 13 - Available Memory: 5157.18 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4443, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3170768., grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9740e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1045, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9480e-01,  9.9474e-01,  9.9471e-01,  9.9469e-01,  9.9468e-01,\n",
      "         9.9467e-01,  9.9467e-01, -2.5752e-06, -3.2303e-06, -3.5476e-06,\n",
      "        -4.0389e-06, -4.9680e-06, -5.3122e-06])\n",
      "Wins_grad tensor([0.0189, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 14\n",
      "Iter 14 - Available Memory: 5028.71 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4444, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3171513.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9784e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1126, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9443e-01,  9.9437e-01,  9.9433e-01,  9.9431e-01,  9.9430e-01,\n",
      "         9.9429e-01,  9.9429e-01, -2.5742e-06, -3.2300e-06, -3.5450e-06,\n",
      "        -4.0373e-06, -4.9651e-06, -5.3099e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 15\n",
      "Iter 15 - Available Memory: 4859.12 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4445, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3172261.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9828e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1207, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9406e-01,  9.9399e-01,  9.9395e-01,  9.9393e-01,  9.9392e-01,\n",
      "         9.9391e-01,  9.9391e-01, -2.5723e-06, -3.2289e-06, -3.5447e-06,\n",
      "        -4.0351e-06, -4.9645e-06, -5.3089e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 15: Normalized Gradient = 0.05098513513803482, Adaptive learning rate = 0.001\n",
      "ite 16\n",
      "Iter 16 - Available Memory: 6853.02 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4446, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3173006.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9872e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1287, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9369e-01,  9.9362e-01,  9.9357e-01,  9.9355e-01,  9.9354e-01,\n",
      "         9.9353e-01,  9.9353e-01, -2.5713e-06, -3.2271e-06, -3.5433e-06,\n",
      "        -4.0332e-06, -4.9625e-06, -5.3077e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 17\n",
      "Iter 17 - Available Memory: 6377.91 MB\n",
      "Ratio tensor(0.9979, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4447, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3173752.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9915e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1369, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9332e-01,  9.9324e-01,  9.9319e-01,  9.9317e-01,  9.9316e-01,\n",
      "         9.9315e-01,  9.9315e-01, -2.5702e-06, -3.2258e-06, -3.5416e-06,\n",
      "        -4.0325e-06, -4.9595e-06, -5.3064e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 18\n",
      "Iter 18 - Available Memory: 6022.30 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4448, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3174500., grad_fn=<DotBackward0>)\n",
      "R: tensor(8.9959e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1449, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9295e-01,  9.9286e-01,  9.9282e-01,  9.9279e-01,  9.9278e-01,\n",
      "         9.9277e-01,  9.9276e-01, -2.5688e-06, -3.2238e-06, -3.5390e-06,\n",
      "        -4.0303e-06, -4.9586e-06, -5.3033e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 19\n",
      "Iter 19 - Available Memory: 5755.80 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4449, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3175247., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0003e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1530, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9258e-01,  9.9249e-01,  9.9244e-01,  9.9241e-01,  9.9240e-01,\n",
      "         9.9239e-01,  9.9238e-01, -2.5671e-06, -3.2220e-06, -3.5370e-06,\n",
      "        -4.0297e-06, -4.9565e-06, -5.3021e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 20\n",
      "Iter 20 - Available Memory: 5588.36 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4450, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3175994.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0047e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1612, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9221e-01,  9.9211e-01,  9.9206e-01,  9.9203e-01,  9.9202e-01,\n",
      "         9.9201e-01,  9.9200e-01, -2.5652e-06, -3.2195e-06, -3.5358e-06,\n",
      "        -4.0251e-06, -4.9545e-06, -5.3013e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 20: Normalized Gradient = 0.05096061900258064, Adaptive learning rate = 0.001\n",
      "ite 21\n",
      "Iter 21 - Available Memory: 5489.50 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4451, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3176748., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0091e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1693, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9183e-01,  9.9174e-01,  9.9168e-01,  9.9166e-01,  9.9164e-01,\n",
      "         9.9163e-01,  9.9162e-01, -2.5641e-06, -3.2177e-06, -3.5340e-06,\n",
      "        -4.0259e-06, -4.9522e-06, -5.2992e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 22\n",
      "Iter 22 - Available Memory: 5436.32 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4452, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3177495.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0135e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1774, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9146e-01,  9.9136e-01,  9.9130e-01,  9.9128e-01,  9.9126e-01,\n",
      "         9.9125e-01,  9.9124e-01, -2.5630e-06, -3.2169e-06, -3.5315e-06,\n",
      "        -4.0229e-06, -4.9530e-06, -5.2986e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 23\n",
      "Iter 23 - Available Memory: 5368.44 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4453, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3178248.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0179e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1856, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9109e-01,  9.9099e-01,  9.9093e-01,  9.9090e-01,  9.9088e-01,\n",
      "         9.9087e-01,  9.9086e-01, -2.5609e-06, -3.2153e-06, -3.5292e-06,\n",
      "        -4.0193e-06, -4.9480e-06, -5.2963e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 24\n",
      "Iter 24 - Available Memory: 5271.09 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4454, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3178999., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0223e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.1937, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9072e-01,  9.9061e-01,  9.9055e-01,  9.9052e-01,  9.9050e-01,\n",
      "         9.9049e-01,  9.9048e-01, -2.5598e-06, -3.2139e-06, -3.5290e-06,\n",
      "        -4.0192e-06, -4.9478e-06, -5.2969e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 25\n",
      "Iter 25 - Available Memory: 5233.34 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4455, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3179750.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0267e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2019, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.9035e-01,  9.9024e-01,  9.9017e-01,  9.9014e-01,  9.9012e-01,\n",
      "         9.9011e-01,  9.9010e-01, -2.5585e-06, -3.2122e-06, -3.5260e-06,\n",
      "        -4.0177e-06, -4.9483e-06, -5.2950e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 25: Normalized Gradient = 0.050936467945575714, Adaptive learning rate = 0.001\n",
      "ite 26\n",
      "Iter 26 - Available Memory: 5217.30 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4455, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3180507., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0312e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2100, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8998e-01,  9.8986e-01,  9.8979e-01,  9.8976e-01,  9.8974e-01,\n",
      "         9.8972e-01,  9.8972e-01, -2.5568e-06, -3.2092e-06, -3.5247e-06,\n",
      "        -4.0151e-06, -4.9437e-06, -5.2917e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 27\n",
      "Iter 27 - Available Memory: 5134.72 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4456, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3181259.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0356e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2182, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8961e-01,  9.8948e-01,  9.8941e-01,  9.8938e-01,  9.8936e-01,\n",
      "         9.8934e-01,  9.8934e-01, -2.5557e-06, -3.2091e-06, -3.5235e-06,\n",
      "        -4.0144e-06, -4.9426e-06, -5.2918e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 28\n",
      "Iter 28 - Available Memory: 5050.61 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4457, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3182013., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0400e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2263, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8924e-01,  9.8911e-01,  9.8904e-01,  9.8900e-01,  9.8898e-01,\n",
      "         9.8896e-01,  9.8896e-01, -2.5533e-06, -3.2067e-06, -3.5234e-06,\n",
      "        -4.0133e-06, -4.9406e-06, -5.2895e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0193, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 29\n",
      "Iter 29 - Available Memory: 4974.09 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4458, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3182773.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0445e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2345, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8887e-01,  9.8873e-01,  9.8866e-01,  9.8862e-01,  9.8860e-01,\n",
      "         9.8858e-01,  9.8858e-01, -2.5526e-06, -3.2054e-06, -3.5204e-06,\n",
      "        -4.0095e-06, -4.9389e-06, -5.2889e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0194, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 30\n",
      "Iter 30 - Available Memory: 4941.29 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4459, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3183527.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0489e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2427, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8849e-01,  9.8836e-01,  9.8828e-01,  9.8824e-01,  9.8822e-01,\n",
      "         9.8820e-01,  9.8819e-01, -2.5505e-06, -3.2030e-06, -3.5185e-06,\n",
      "        -4.0080e-06, -4.9350e-06, -5.2853e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 30: Normalized Gradient = 0.050912391394376755, Adaptive learning rate = 0.001\n",
      "ite 31\n",
      "Iter 31 - Available Memory: 4953.05 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4460, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3184286.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0534e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2509, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8812e-01,  9.8798e-01,  9.8790e-01,  9.8786e-01,  9.8784e-01,\n",
      "         9.8782e-01,  9.8781e-01, -2.5503e-06, -3.2016e-06, -3.5162e-06,\n",
      "        -4.0057e-06, -4.9353e-06, -5.2844e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 32\n",
      "Iter 32 - Available Memory: 4871.67 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4461, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3185042.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0578e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2591, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8775e-01,  9.8761e-01,  9.8752e-01,  9.8748e-01,  9.8746e-01,\n",
      "         9.8744e-01,  9.8743e-01, -2.5491e-06, -3.2011e-06, -3.5154e-06,\n",
      "        -4.0045e-06, -4.9348e-06, -5.2851e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 33\n",
      "Iter 33 - Available Memory: 4823.46 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4462, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3185800.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0623e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2673, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8738e-01,  9.8723e-01,  9.8715e-01,  9.8710e-01,  9.8708e-01,\n",
      "         9.8706e-01,  9.8705e-01, -2.5474e-06, -3.1983e-06, -3.5128e-06,\n",
      "        -4.0028e-06, -4.9307e-06, -5.2832e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 34\n",
      "Iter 34 - Available Memory: 4798.92 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4463, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3186558., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0667e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2755, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8701e-01,  9.8686e-01,  9.8677e-01,  9.8672e-01,  9.8670e-01,\n",
      "         9.8668e-01,  9.8667e-01, -2.5455e-06, -3.1968e-06, -3.5124e-06,\n",
      "        -4.0011e-06, -4.9304e-06, -5.2818e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 35\n",
      "Iter 35 - Available Memory: 4912.86 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4464, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3187322.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0713e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2837, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8664e-01,  9.8648e-01,  9.8639e-01,  9.8635e-01,  9.8632e-01,\n",
      "         9.8630e-01,  9.8629e-01, -2.5438e-06, -3.1949e-06, -3.5103e-06,\n",
      "        -4.0001e-06, -4.9274e-06, -5.2795e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 35: Normalized Gradient = 0.05088832974433899, Adaptive learning rate = 0.001\n",
      "ite 36\n",
      "Iter 36 - Available Memory: 4818.73 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4465, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3188081., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0757e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.2919, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8627e-01,  9.8610e-01,  9.8601e-01,  9.8597e-01,  9.8594e-01,\n",
      "         9.8592e-01,  9.8591e-01, -2.5425e-06, -3.1931e-06, -3.5084e-06,\n",
      "        -3.9980e-06, -4.9248e-06, -5.2770e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 37\n",
      "Iter 37 - Available Memory: 4756.36 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4466, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3188842., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0802e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3001, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8590e-01,  9.8573e-01,  9.8563e-01,  9.8559e-01,  9.8556e-01,\n",
      "         9.8554e-01,  9.8553e-01, -2.5412e-06, -3.1917e-06, -3.5063e-06,\n",
      "        -3.9947e-06, -4.9247e-06, -5.2785e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 38\n",
      "Iter 38 - Available Memory: 4666.05 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4467, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3189604.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0847e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3084, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8552e-01,  9.8535e-01,  9.8525e-01,  9.8521e-01,  9.8518e-01,\n",
      "         9.8516e-01,  9.8515e-01, -2.5396e-06, -3.1904e-06, -3.5059e-06,\n",
      "        -3.9940e-06, -4.9204e-06, -5.2745e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 39\n",
      "Iter 39 - Available Memory: 4677.63 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4468, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3190368., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0892e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3166, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8515e-01,  9.8498e-01,  9.8488e-01,  9.8483e-01,  9.8480e-01,\n",
      "         9.8478e-01,  9.8477e-01, -2.5391e-06, -3.1891e-06, -3.5037e-06,\n",
      "        -3.9930e-06, -4.9208e-06, -5.2728e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 40\n",
      "Iter 40 - Available Memory: 4538.43 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4469, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3191131., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0937e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3248, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8478e-01,  9.8460e-01,  9.8450e-01,  9.8445e-01,  9.8442e-01,\n",
      "         9.8440e-01,  9.8439e-01, -2.5366e-06, -3.1855e-06, -3.5000e-06,\n",
      "        -3.9890e-06, -4.9179e-06, -5.2712e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "Iteration 40: Normalized Gradient = 0.050863850861787796, Adaptive learning rate = 0.001\n",
      "ite 41\n",
      "Iter 41 - Available Memory: 4438.33 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4470, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3191896.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.0982e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3331, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8441e-01,  9.8423e-01,  9.8412e-01,  9.8407e-01,  9.8404e-01,\n",
      "         9.8402e-01,  9.8401e-01, -2.5355e-06, -3.1846e-06, -3.4995e-06,\n",
      "        -3.9880e-06, -4.9170e-06, -5.2721e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0194, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0003, 0.0003])\n",
      "ite 42\n",
      "Iter 42 - Available Memory: 4464.59 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4471, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3192663.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1027e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3413, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8404e-01,  9.8385e-01,  9.8374e-01,  9.8369e-01,  9.8366e-01,\n",
      "         9.8364e-01,  9.8363e-01, -2.5343e-06, -3.1830e-06, -3.4982e-06,\n",
      "        -3.9855e-06, -4.9156e-06, -5.2705e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 43\n",
      "Iter 43 - Available Memory: 4312.31 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4472, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3193425.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1072e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3496, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8367e-01,  9.8347e-01,  9.8336e-01,  9.8331e-01,  9.8328e-01,\n",
      "         9.8326e-01,  9.8325e-01, -2.5326e-06, -3.1810e-06, -3.4956e-06,\n",
      "        -3.9845e-06, -4.9126e-06, -5.2669e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 44\n",
      "Iter 44 - Available Memory: 4194.83 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4473, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3194197.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1118e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3578, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8330e-01,  9.8310e-01,  9.8299e-01,  9.8293e-01,  9.8290e-01,\n",
      "         9.8288e-01,  9.8286e-01, -2.5312e-06, -3.1800e-06, -3.4941e-06,\n",
      "        -3.9830e-06, -4.9115e-06, -5.2663e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 45\n",
      "Iter 45 - Available Memory: 6383.16 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4474, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3194963., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1163e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3661, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8292e-01,  9.8272e-01,  9.8261e-01,  9.8255e-01,  9.8252e-01,\n",
      "         9.8249e-01,  9.8248e-01, -2.5300e-06, -3.1771e-06, -3.4929e-06,\n",
      "        -3.9817e-06, -4.9102e-06, -5.2670e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 45: Normalized Gradient = 0.05083981156349182, Adaptive learning rate = 0.001\n",
      "ite 46\n",
      "Iter 46 - Available Memory: 6181.81 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4475, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3195732.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1208e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3744, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8255e-01,  9.8235e-01,  9.8223e-01,  9.8217e-01,  9.8214e-01,\n",
      "         9.8211e-01,  9.8210e-01, -2.5287e-06, -3.1768e-06, -3.4908e-06,\n",
      "        -3.9792e-06, -4.9077e-06, -5.2650e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 47\n",
      "Iter 47 - Available Memory: 5977.36 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4475, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3196502.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1253e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3827, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8218e-01,  9.8197e-01,  9.8185e-01,  9.8179e-01,  9.8176e-01,\n",
      "         9.8173e-01,  9.8172e-01, -2.5271e-06, -3.1744e-06, -3.4887e-06,\n",
      "        -3.9761e-06, -4.9052e-06, -5.2616e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 48\n",
      "Iter 48 - Available Memory: 5751.30 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4476, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3197274.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1299e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3910, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8181e-01,  9.8160e-01,  9.8147e-01,  9.8142e-01,  9.8138e-01,\n",
      "         9.8135e-01,  9.8134e-01, -2.5263e-06, -3.1737e-06, -3.4876e-06,\n",
      "        -3.9757e-06, -4.9036e-06, -5.2611e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0194, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 49\n",
      "Iter 49 - Available Memory: 5557.01 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4477, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3198045., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1345e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.3993, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8144e-01,  9.8122e-01,  9.8110e-01,  9.8104e-01,  9.8100e-01,\n",
      "         9.8097e-01,  9.8096e-01, -2.5239e-06, -3.1717e-06, -3.4857e-06,\n",
      "        -3.9736e-06, -4.9015e-06, -5.2593e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 50\n",
      "Iter 50 - Available Memory: 5315.04 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4478, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3198813.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1390e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4076, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8107e-01,  9.8085e-01,  9.8072e-01,  9.8066e-01,  9.8062e-01,\n",
      "         9.8059e-01,  9.8058e-01, -2.5228e-06, -3.1698e-06, -3.4844e-06,\n",
      "        -3.9717e-06, -4.9022e-06, -5.2585e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 50: Normalized Gradient = 0.0508156456053257, Adaptive learning rate = 0.001\n",
      "ite 51\n",
      "Iter 51 - Available Memory: 5067.57 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4479, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3199586.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1435e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4159, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8070e-01,  9.8047e-01,  9.8034e-01,  9.8028e-01,  9.8024e-01,\n",
      "         9.8021e-01,  9.8020e-01, -2.5212e-06, -3.1676e-06, -3.4823e-06,\n",
      "        -3.9700e-06, -4.8982e-06, -5.2560e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 52\n",
      "Iter 52 - Available Memory: 4998.52 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4480, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3200359., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1481e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4242, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.8033e-01,  9.8009e-01,  9.7996e-01,  9.7990e-01,  9.7986e-01,\n",
      "         9.7983e-01,  9.7982e-01, -2.5202e-06, -3.1671e-06, -3.4813e-06,\n",
      "        -3.9672e-06, -4.8977e-06, -5.2547e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 53\n",
      "Iter 53 - Available Memory: 4801.21 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4481, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3201132.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1527e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4325, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7995e-01,  9.7972e-01,  9.7958e-01,  9.7952e-01,  9.7948e-01,\n",
      "         9.7945e-01,  9.7944e-01, -2.5185e-06, -3.1647e-06, -3.4793e-06,\n",
      "        -3.9673e-06, -4.8964e-06, -5.2550e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 54\n",
      "Iter 54 - Available Memory: 4729.51 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4482, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3201908., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1573e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4409, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7958e-01,  9.7934e-01,  9.7921e-01,  9.7914e-01,  9.7910e-01,\n",
      "         9.7907e-01,  9.7906e-01, -2.5176e-06, -3.1638e-06, -3.4760e-06,\n",
      "        -3.9634e-06, -4.8919e-06, -5.2524e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 55\n",
      "Iter 55 - Available Memory: 4627.77 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4483, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3202682.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1618e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4492, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7921e-01,  9.7897e-01,  9.7883e-01,  9.7876e-01,  9.7872e-01,\n",
      "         9.7869e-01,  9.7868e-01, -2.5155e-06, -3.1610e-06, -3.4744e-06,\n",
      "        -3.9616e-06, -4.8906e-06, -5.2499e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 55: Normalized Gradient = 0.05079152062535286, Adaptive learning rate = 0.001\n",
      "ite 56\n",
      "Iter 56 - Available Memory: 4537.94 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4484, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3203462., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1664e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4576, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7884e-01,  9.7859e-01,  9.7845e-01,  9.7838e-01,  9.7834e-01,\n",
      "         9.7831e-01,  9.7830e-01, -2.5139e-06, -3.1588e-06, -3.4718e-06,\n",
      "        -3.9605e-06, -4.8903e-06, -5.2490e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 57\n",
      "Iter 57 - Available Memory: 4452.77 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4485, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3204236., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1710e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4659, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7847e-01,  9.7822e-01,  9.7807e-01,  9.7800e-01,  9.7796e-01,\n",
      "         9.7793e-01,  9.7791e-01, -2.5128e-06, -3.1568e-06, -3.4710e-06,\n",
      "        -3.9594e-06, -4.8885e-06, -5.2487e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 58\n",
      "Iter 58 - Available Memory: 4399.79 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4486, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3205015., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1756e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4743, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7810e-01,  9.7784e-01,  9.7769e-01,  9.7762e-01,  9.7758e-01,\n",
      "         9.7755e-01,  9.7753e-01, -2.5116e-06, -3.1569e-06, -3.4711e-06,\n",
      "        -3.9564e-06, -4.8847e-06, -5.2467e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 59\n",
      "Iter 59 - Available Memory: 5786.50 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4487, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3205794.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1802e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4826, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7773e-01,  9.7746e-01,  9.7732e-01,  9.7724e-01,  9.7720e-01,\n",
      "         9.7717e-01,  9.7715e-01, -2.5100e-06, -3.1545e-06, -3.4673e-06,\n",
      "        -3.9546e-06, -4.8840e-06, -5.2458e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 60\n",
      "Iter 60 - Available Memory: 5492.59 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4488, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3206575., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1848e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4910, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7736e-01,  9.7709e-01,  9.7694e-01,  9.7686e-01,  9.7682e-01,\n",
      "         9.7679e-01,  9.7677e-01, -2.5084e-06, -3.1525e-06, -3.4657e-06,\n",
      "        -3.9535e-06, -4.8808e-06, -5.2440e-06])\n",
      "Wins_grad tensor([0.0189, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 60: Normalized Gradient = 0.05076761916279793, Adaptive learning rate = 0.001\n",
      "ite 61\n",
      "Iter 61 - Available Memory: 5092.27 MB\n",
      "Ratio tensor(0.9980, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4489, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3207354.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1895e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.4994, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7698e-01,  9.7671e-01,  9.7656e-01,  9.7649e-01,  9.7644e-01,\n",
      "         9.7641e-01,  9.7639e-01, -2.5072e-06, -3.1509e-06, -3.4651e-06,\n",
      "        -3.9518e-06, -4.8784e-06, -5.2421e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0193, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 62\n",
      "Iter 62 - Available Memory: 6412.03 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4490, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3208136.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1941e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5078, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7661e-01,  9.7634e-01,  9.7618e-01,  9.7611e-01,  9.7606e-01,\n",
      "         9.7603e-01,  9.7601e-01, -2.5056e-06, -3.1486e-06, -3.4627e-06,\n",
      "        -3.9500e-06, -4.8785e-06, -5.2405e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 63\n",
      "Iter 63 - Available Memory: 6154.91 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4491, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3208915., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.1987e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5161, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7624e-01,  9.7596e-01,  9.7580e-01,  9.7573e-01,  9.7568e-01,\n",
      "         9.7565e-01,  9.7563e-01, -2.5042e-06, -3.1472e-06, -3.4614e-06,\n",
      "        -3.9474e-06, -4.8768e-06, -5.2401e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 64\n",
      "Iter 64 - Available Memory: 6032.19 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4492, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3209698.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2033e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5245, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7587e-01,  9.7559e-01,  9.7542e-01,  9.7535e-01,  9.7530e-01,\n",
      "         9.7527e-01,  9.7525e-01, -2.5027e-06, -3.1455e-06, -3.4592e-06,\n",
      "        -3.9456e-06, -4.8747e-06, -5.2385e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 65\n",
      "Iter 65 - Available Memory: 5305.30 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4493, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3210484., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2080e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5329, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7550e-01,  9.7521e-01,  9.7505e-01,  9.7497e-01,  9.7492e-01,\n",
      "         9.7488e-01,  9.7487e-01, -2.5013e-06, -3.1436e-06, -3.4571e-06,\n",
      "        -3.9431e-06, -4.8723e-06, -5.2373e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 65: Normalized Gradient = 0.05074368044734001, Adaptive learning rate = 0.001\n",
      "ite 66\n",
      "Iter 66 - Available Memory: 5251.82 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4494, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3211266., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2126e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5414, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7513e-01,  9.7483e-01,  9.7467e-01,  9.7459e-01,  9.7454e-01,\n",
      "         9.7450e-01,  9.7449e-01, -2.4998e-06, -3.1420e-06, -3.4578e-06,\n",
      "        -3.9436e-06, -4.8728e-06, -5.2372e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 67\n",
      "Iter 67 - Available Memory: 5207.27 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4495, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3212050., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2173e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5498, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7476e-01,  9.7446e-01,  9.7429e-01,  9.7421e-01,  9.7416e-01,\n",
      "         9.7412e-01,  9.7411e-01, -2.4982e-06, -3.1403e-06, -3.4543e-06,\n",
      "        -3.9408e-06, -4.8699e-06, -5.2342e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 68\n",
      "Iter 68 - Available Memory: 5032.29 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4496, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3212837.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2219e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5582, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7438e-01,  9.7408e-01,  9.7391e-01,  9.7383e-01,  9.7378e-01,\n",
      "         9.7374e-01,  9.7373e-01, -2.4973e-06, -3.1392e-06, -3.4529e-06,\n",
      "        -3.9393e-06, -4.8687e-06, -5.2344e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 69\n",
      "Iter 69 - Available Memory: 4659.80 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4497, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3213620.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2265e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5666, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7401e-01,  9.7371e-01,  9.7353e-01,  9.7345e-01,  9.7340e-01,\n",
      "         9.7336e-01,  9.7335e-01, -2.4954e-06, -3.1368e-06, -3.4516e-06,\n",
      "        -3.9368e-06, -4.8652e-06, -5.2308e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 70\n",
      "Iter 70 - Available Memory: 4599.42 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4498, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3214408., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2312e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5751, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7364e-01,  9.7333e-01,  9.7316e-01,  9.7307e-01,  9.7302e-01,\n",
      "         9.7298e-01,  9.7297e-01, -2.4941e-06, -3.1357e-06, -3.4497e-06,\n",
      "        -3.9339e-06, -4.8633e-06, -5.2290e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 70: Normalized Gradient = 0.05071936547756195, Adaptive learning rate = 0.001\n",
      "ite 71\n",
      "Iter 71 - Available Memory: 4519.99 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4499, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3215198., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2359e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5835, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7327e-01,  9.7296e-01,  9.7278e-01,  9.7269e-01,  9.7264e-01,\n",
      "         9.7260e-01,  9.7258e-01, -2.4926e-06, -3.1340e-06, -3.4475e-06,\n",
      "        -3.9343e-06, -4.8633e-06, -5.2285e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 72\n",
      "Iter 72 - Available Memory: 4564.96 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4500, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3215985., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2406e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.5920, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7290e-01,  9.7258e-01,  9.7240e-01,  9.7231e-01,  9.7226e-01,\n",
      "         9.7222e-01,  9.7220e-01, -2.4919e-06, -3.1323e-06, -3.4452e-06,\n",
      "        -3.9322e-06, -4.8608e-06, -5.2271e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 73\n",
      "Iter 73 - Available Memory: 4369.88 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4501, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3216774.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2452e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6004, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7253e-01,  9.7220e-01,  9.7202e-01,  9.7194e-01,  9.7188e-01,\n",
      "         9.7184e-01,  9.7182e-01, -2.4898e-06, -3.1316e-06, -3.4426e-06,\n",
      "        -3.9286e-06, -4.8578e-06, -5.2247e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 74\n",
      "Iter 74 - Available Memory: 4257.79 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4502, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3217564.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2499e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6089, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7216e-01,  9.7183e-01,  9.7164e-01,  9.7156e-01,  9.7150e-01,\n",
      "         9.7146e-01,  9.7144e-01, -2.4885e-06, -3.1287e-06, -3.4418e-06,\n",
      "        -3.9276e-06, -4.8564e-06, -5.2238e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 75\n",
      "Iter 75 - Available Memory: 4199.61 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4503, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3218356., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2546e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6173, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7178e-01,  9.7145e-01,  9.7127e-01,  9.7118e-01,  9.7112e-01,\n",
      "         9.7108e-01,  9.7106e-01, -2.4872e-06, -3.1272e-06, -3.4400e-06,\n",
      "        -3.9238e-06, -4.8541e-06, -5.2206e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 75: Normalized Gradient = 0.050695404410362244, Adaptive learning rate = 0.001\n",
      "ite 76\n",
      "Iter 76 - Available Memory: 4091.89 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4504, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3219150., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2594e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6258, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7141e-01,  9.7108e-01,  9.7089e-01,  9.7080e-01,  9.7074e-01,\n",
      "         9.7070e-01,  9.7068e-01, -2.4859e-06, -3.1251e-06, -3.4392e-06,\n",
      "        -3.9244e-06, -4.8531e-06, -5.2215e-06])\n",
      "Wins_grad tensor([0.0188, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 77\n",
      "Iter 77 - Available Memory: 4144.46 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4505, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3219940.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2640e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6343, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7104e-01,  9.7070e-01,  9.7051e-01,  9.7042e-01,  9.7036e-01,\n",
      "         9.7032e-01,  9.7030e-01, -2.4839e-06, -3.1243e-06, -3.4372e-06,\n",
      "        -3.9229e-06, -4.8497e-06, -5.2191e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 78\n",
      "Iter 78 - Available Memory: 3990.85 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4506, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3220735., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2687e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6428, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7067e-01,  9.7032e-01,  9.7013e-01,  9.7004e-01,  9.6998e-01,\n",
      "         9.6994e-01,  9.6992e-01, -2.4822e-06, -3.1223e-06, -3.4346e-06,\n",
      "        -3.9190e-06, -4.8486e-06, -5.2176e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 79\n",
      "Iter 79 - Available Memory: 3906.66 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4507, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3221528.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2735e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6513, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.7030e-01,  9.6995e-01,  9.6975e-01,  9.6966e-01,  9.6960e-01,\n",
      "         9.6956e-01,  9.6954e-01, -2.4810e-06, -3.1198e-06, -3.4335e-06,\n",
      "        -3.9172e-06, -4.8466e-06, -5.2151e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 80\n",
      "Iter 80 - Available Memory: 3812.76 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4508, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3222324., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2782e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6598, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6993e-01,  9.6957e-01,  9.6938e-01,  9.6928e-01,  9.6922e-01,\n",
      "         9.6918e-01,  9.6916e-01, -2.4798e-06, -3.1182e-06, -3.4310e-06,\n",
      "        -3.9142e-06, -4.8455e-06, -5.2161e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 80: Normalized Gradient = 0.05067145824432373, Adaptive learning rate = 0.001\n",
      "ite 81\n",
      "Iter 81 - Available Memory: 3730.99 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4509, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3223118., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2829e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6683, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6956e-01,  9.6920e-01,  9.6900e-01,  9.6890e-01,  9.6884e-01,\n",
      "         9.6880e-01,  9.6878e-01, -2.4788e-06, -3.1170e-06, -3.4302e-06,\n",
      "        -3.9152e-06, -4.8451e-06, -5.2153e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0193, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 82\n",
      "Iter 82 - Available Memory: 3835.01 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4510, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3223914.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2876e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6768, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6918e-01,  9.6882e-01,  9.6862e-01,  9.6852e-01,  9.6846e-01,\n",
      "         9.6842e-01,  9.6840e-01, -2.4767e-06, -3.1154e-06, -3.4279e-06,\n",
      "        -3.9133e-06, -4.8422e-06, -5.2127e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 83\n",
      "Iter 83 - Available Memory: 3638.68 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4511, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3224713.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2924e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6853, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6881e-01,  9.6845e-01,  9.6824e-01,  9.6814e-01,  9.6808e-01,\n",
      "         9.6804e-01,  9.6802e-01, -2.4756e-06, -3.1136e-06, -3.4265e-06,\n",
      "        -3.9124e-06, -4.8395e-06, -5.2111e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 84\n",
      "Iter 84 - Available Memory: 3524.89 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4512, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3225515.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.2972e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.6939, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6844e-01,  9.6807e-01,  9.6786e-01,  9.6776e-01,  9.6770e-01,\n",
      "         9.6766e-01,  9.6764e-01, -2.4737e-06, -3.1112e-06, -3.4252e-06,\n",
      "        -3.9088e-06, -4.8382e-06, -5.2099e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0192, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 85\n",
      "Iter 85 - Available Memory: 3297.73 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4513, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3226311.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3019e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7024, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6807e-01,  9.6769e-01,  9.6748e-01,  9.6739e-01,  9.6732e-01,\n",
      "         9.6728e-01,  9.6725e-01, -2.4723e-06, -3.1094e-06, -3.4230e-06,\n",
      "        -3.9073e-06, -4.8371e-06, -5.2076e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 85: Normalized Gradient = 0.05064759775996208, Adaptive learning rate = 0.001\n",
      "ite 86\n",
      "Iter 86 - Available Memory: 3330.56 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4514, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3227111.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3066e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7109, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6770e-01,  9.6732e-01,  9.6711e-01,  9.6701e-01,  9.6694e-01,\n",
      "         9.6690e-01,  9.6687e-01, -2.4712e-06, -3.1082e-06, -3.4202e-06,\n",
      "        -3.9056e-06, -4.8349e-06, -5.2072e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 87\n",
      "Iter 87 - Available Memory: 3334.79 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4515, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3227911.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3114e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7195, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6733e-01,  9.6694e-01,  9.6673e-01,  9.6663e-01,  9.6656e-01,\n",
      "         9.6652e-01,  9.6649e-01, -2.4694e-06, -3.1067e-06, -3.4192e-06,\n",
      "        -3.9028e-06, -4.8321e-06, -5.2043e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 88\n",
      "Iter 88 - Available Memory: 3275.55 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4516, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3228710.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3161e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7280, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6696e-01,  9.6657e-01,  9.6635e-01,  9.6625e-01,  9.6618e-01,\n",
      "         9.6613e-01,  9.6611e-01, -2.4685e-06, -3.1045e-06, -3.4176e-06,\n",
      "        -3.9018e-06, -4.8291e-06, -5.2025e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 89\n",
      "Iter 89 - Available Memory: 3193.80 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4517, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3229515., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3209e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7366, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6658e-01,  9.6619e-01,  9.6597e-01,  9.6587e-01,  9.6580e-01,\n",
      "         9.6575e-01,  9.6573e-01, -2.4669e-06, -3.1031e-06, -3.4156e-06,\n",
      "        -3.9009e-06, -4.8279e-06, -5.2017e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 90\n",
      "Iter 90 - Available Memory: 7360.33 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4518, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3230319.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3257e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7452, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6621e-01,  9.6581e-01,  9.6559e-01,  9.6549e-01,  9.6542e-01,\n",
      "         9.6537e-01,  9.6535e-01, -2.4652e-06, -3.1013e-06, -3.4130e-06,\n",
      "        -3.8980e-06, -4.8255e-06, -5.1993e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 90: Normalized Gradient = 0.05062364786863327, Adaptive learning rate = 0.001\n",
      "ite 91\n",
      "Iter 91 - Available Memory: 6966.76 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4519, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3231122.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3305e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7537, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6584e-01,  9.6544e-01,  9.6522e-01,  9.6511e-01,  9.6504e-01,\n",
      "         9.6499e-01,  9.6497e-01, -2.4640e-06, -3.0993e-06, -3.4123e-06,\n",
      "        -3.8970e-06, -4.8261e-06, -5.1997e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 92\n",
      "Iter 92 - Available Memory: 6801.02 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4520, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3231924.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3353e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7623, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6547e-01,  9.6506e-01,  9.6484e-01,  9.6473e-01,  9.6466e-01,\n",
      "         9.6461e-01,  9.6459e-01, -2.4627e-06, -3.0990e-06, -3.4107e-06,\n",
      "        -3.8938e-06, -4.8212e-06, -5.1977e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 93\n",
      "Iter 93 - Available Memory: 6433.92 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4521, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3232732., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3401e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7709, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6510e-01,  9.6469e-01,  9.6446e-01,  9.6435e-01,  9.6428e-01,\n",
      "         9.6423e-01,  9.6421e-01, -2.4606e-06, -3.0964e-06, -3.4079e-06,\n",
      "        -3.8931e-06, -4.8208e-06, -5.1967e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 94\n",
      "Iter 94 - Available Memory: 6284.04 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4522, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3233538.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3449e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7795, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6473e-01,  9.6431e-01,  9.6408e-01,  9.6397e-01,  9.6390e-01,\n",
      "         9.6385e-01,  9.6383e-01, -2.4597e-06, -3.0945e-06, -3.4066e-06,\n",
      "        -3.8901e-06, -4.8201e-06, -5.1936e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0193, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 95\n",
      "Iter 95 - Available Memory: 6084.19 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4523, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3234347.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3497e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7881, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6436e-01,  9.6394e-01,  9.6370e-01,  9.6359e-01,  9.6352e-01,\n",
      "         9.6347e-01,  9.6345e-01, -2.4591e-06, -3.0932e-06, -3.4049e-06,\n",
      "        -3.8888e-06, -4.8179e-06, -5.1925e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 95: Normalized Gradient = 0.0505998320877552, Adaptive learning rate = 0.001\n",
      "ite 96\n",
      "Iter 96 - Available Memory: 5977.34 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4524, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3235150., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3545e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.7967, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6398e-01,  9.6356e-01,  9.6333e-01,  9.6322e-01,  9.6314e-01,\n",
      "         9.6309e-01,  9.6307e-01, -2.4568e-06, -3.0921e-06, -3.4044e-06,\n",
      "        -3.8875e-06, -4.8161e-06, -5.1913e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 97\n",
      "Iter 97 - Available Memory: 5540.13 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4525, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3235961., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3593e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8053, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6361e-01,  9.6318e-01,  9.6295e-01,  9.6284e-01,  9.6276e-01,\n",
      "         9.6271e-01,  9.6269e-01, -2.4553e-06, -3.0904e-06, -3.4014e-06,\n",
      "        -3.8862e-06, -4.8146e-06, -5.1903e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 98\n",
      "Iter 98 - Available Memory: 5219.70 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4526, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3236771.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3641e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8139, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6324e-01,  9.6281e-01,  9.6257e-01,  9.6246e-01,  9.6238e-01,\n",
      "         9.6233e-01,  9.6231e-01, -2.4539e-06, -3.0879e-06, -3.3991e-06,\n",
      "        -3.8833e-06, -4.8105e-06, -5.1892e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 99\n",
      "Iter 99 - Available Memory: 5059.60 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4527, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3237581.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3690e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8226, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6287e-01,  9.6243e-01,  9.6219e-01,  9.6208e-01,  9.6200e-01,\n",
      "         9.6195e-01,  9.6193e-01, -2.4524e-06, -3.0858e-06, -3.3985e-06,\n",
      "        -3.8810e-06, -4.8101e-06, -5.1886e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 100\n",
      "Iter 100 - Available Memory: 6433.50 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4528, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3238393., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3738e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8312, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6250e-01,  9.6206e-01,  9.6181e-01,  9.6170e-01,  9.6162e-01,\n",
      "         9.6157e-01,  9.6154e-01, -2.4516e-06, -3.0849e-06, -3.3958e-06,\n",
      "        -3.8788e-06, -4.8071e-06, -5.1847e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0193, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 100: Normalized Gradient = 0.05057590827345848, Adaptive learning rate = 0.001\n",
      "ite 101\n",
      "Iter 101 - Available Memory: 6714.02 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4529, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3239205., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3786e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8399, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6213e-01,  9.6168e-01,  9.6144e-01,  9.6132e-01,  9.6124e-01,\n",
      "         9.6119e-01,  9.6116e-01, -2.4493e-06, -3.0816e-06, -3.3944e-06,\n",
      "        -3.8771e-06, -4.8063e-06, -5.1832e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 102\n",
      "Iter 102 - Available Memory: 6434.80 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4530, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3240019.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3835e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8485, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6175e-01,  9.6130e-01,  9.6106e-01,  9.6094e-01,  9.6086e-01,\n",
      "         9.6081e-01,  9.6078e-01, -2.4480e-06, -3.0803e-06, -3.3932e-06,\n",
      "        -3.8758e-06, -4.8038e-06, -5.1827e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 103\n",
      "Iter 103 - Available Memory: 6295.87 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4531, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3240829., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3883e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8572, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6138e-01,  9.6093e-01,  9.6068e-01,  9.6056e-01,  9.6048e-01,\n",
      "         9.6043e-01,  9.6040e-01, -2.4470e-06, -3.0789e-06, -3.3919e-06,\n",
      "        -3.8745e-06, -4.8043e-06, -5.1818e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 104\n",
      "Iter 104 - Available Memory: 5967.17 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4532, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3241645.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3932e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8658, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6101e-01,  9.6055e-01,  9.6030e-01,  9.6018e-01,  9.6010e-01,\n",
      "         9.6005e-01,  9.6002e-01, -2.4452e-06, -3.0769e-06, -3.3877e-06,\n",
      "        -3.8713e-06, -4.8018e-06, -5.1809e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 105\n",
      "Iter 105 - Available Memory: 5805.34 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4533, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3242463., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.3981e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8745, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6064e-01,  9.6018e-01,  9.5992e-01,  9.5980e-01,  9.5972e-01,\n",
      "         9.5967e-01,  9.5964e-01, -2.4438e-06, -3.0761e-06, -3.3881e-06,\n",
      "        -3.8705e-06, -4.7989e-06, -5.1791e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 105: Normalized Gradient = 0.050552211701869965, Adaptive learning rate = 0.001\n",
      "ite 106\n",
      "Iter 106 - Available Memory: 5600.14 MB\n",
      "Ratio tensor(0.9981, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4534, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3243278.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4029e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8832, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.6027e-01,  9.5980e-01,  9.5955e-01,  9.5942e-01,  9.5934e-01,\n",
      "         9.5929e-01,  9.5926e-01, -2.4420e-06, -3.0740e-06, -3.3871e-06,\n",
      "        -3.8674e-06, -4.7967e-06, -5.1766e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 107\n",
      "Iter 107 - Available Memory: 5438.22 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4535, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3244094., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4078e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.8919, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5990e-01,  9.5942e-01,  9.5917e-01,  9.5904e-01,  9.5896e-01,\n",
      "         9.5891e-01,  9.5888e-01, -2.4413e-06, -3.0722e-06, -3.3849e-06,\n",
      "        -3.8653e-06, -4.7943e-06, -5.1745e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 108\n",
      "Iter 108 - Available Memory: 5331.66 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4536, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3244910.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4127e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9006, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5953e-01,  9.5905e-01,  9.5879e-01,  9.5867e-01,  9.5858e-01,\n",
      "         9.5853e-01,  9.5850e-01, -2.4396e-06, -3.0703e-06, -3.3826e-06,\n",
      "        -3.8644e-06, -4.7938e-06, -5.1748e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 109\n",
      "Iter 109 - Available Memory: 5223.54 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4537, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3245729., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4176e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9092, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5915e-01,  9.5867e-01,  9.5841e-01,  9.5829e-01,  9.5820e-01,\n",
      "         9.5815e-01,  9.5812e-01, -2.4378e-06, -3.0691e-06, -3.3803e-06,\n",
      "        -3.8623e-06, -4.7925e-06, -5.1724e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 110\n",
      "Iter 110 - Available Memory: 5164.11 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4538, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3246550., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4225e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9179, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5878e-01,  9.5830e-01,  9.5803e-01,  9.5791e-01,  9.5782e-01,\n",
      "         9.5777e-01,  9.5774e-01, -2.4366e-06, -3.0671e-06, -3.3786e-06,\n",
      "        -3.8602e-06, -4.7885e-06, -5.1696e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 110: Normalized Gradient = 0.0505281500518322, Adaptive learning rate = 0.001\n",
      "ite 111\n",
      "Iter 111 - Available Memory: 5444.47 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4539, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3247368., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4274e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9267, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5841e-01,  9.5792e-01,  9.5765e-01,  9.5753e-01,  9.5744e-01,\n",
      "         9.5739e-01,  9.5736e-01, -2.4352e-06, -3.0655e-06, -3.3772e-06,\n",
      "        -3.8592e-06, -4.7885e-06, -5.1711e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 112\n",
      "Iter 112 - Available Memory: 5276.75 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4541, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3248193.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4323e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9354, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5804e-01,  9.5754e-01,  9.5728e-01,  9.5715e-01,  9.5706e-01,\n",
      "         9.5701e-01,  9.5698e-01, -2.4333e-06, -3.0639e-06, -3.3735e-06,\n",
      "        -3.8556e-06, -4.7860e-06, -5.1679e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0192, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 113\n",
      "Iter 113 - Available Memory: 5189.53 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4542, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3249013., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4372e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9441, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5767e-01,  9.5717e-01,  9.5690e-01,  9.5677e-01,  9.5668e-01,\n",
      "         9.5662e-01,  9.5660e-01, -2.4324e-06, -3.0627e-06, -3.3736e-06,\n",
      "        -3.8554e-06, -4.7837e-06, -5.1671e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 114\n",
      "Iter 114 - Available Memory: 5152.62 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4543, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3249833.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4421e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9528, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5730e-01,  9.5679e-01,  9.5652e-01,  9.5639e-01,  9.5630e-01,\n",
      "         9.5624e-01,  9.5622e-01, -2.4311e-06, -3.0610e-06, -3.3708e-06,\n",
      "        -3.8531e-06, -4.7814e-06, -5.1647e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 115\n",
      "Iter 115 - Available Memory: 5285.05 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4544, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3250657.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4470e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9616, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5692e-01,  9.5642e-01,  9.5614e-01,  9.5601e-01,  9.5592e-01,\n",
      "         9.5586e-01,  9.5584e-01, -2.4301e-06, -3.0586e-06, -3.3700e-06,\n",
      "        -3.8498e-06, -4.7803e-06, -5.1642e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 115: Normalized Gradient = 0.05050426349043846, Adaptive learning rate = 0.001\n",
      "ite 116\n",
      "Iter 116 - Available Memory: 5146.43 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4545, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3251482., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4520e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9703, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5655e-01,  9.5604e-01,  9.5576e-01,  9.5563e-01,  9.5554e-01,\n",
      "         9.5548e-01,  9.5545e-01, -2.4284e-06, -3.0570e-06, -3.3679e-06,\n",
      "        -3.8503e-06, -4.7783e-06, -5.1644e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 117\n",
      "Iter 117 - Available Memory: 5056.16 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4546, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3252306.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4569e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9791, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5618e-01,  9.5566e-01,  9.5539e-01,  9.5525e-01,  9.5516e-01,\n",
      "         9.5510e-01,  9.5507e-01, -2.4267e-06, -3.0550e-06, -3.3657e-06,\n",
      "        -3.8471e-06, -4.7754e-06, -5.1622e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 118\n",
      "Iter 118 - Available Memory: 4926.00 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4547, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3253134.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4619e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9878, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5581e-01,  9.5529e-01,  9.5501e-01,  9.5487e-01,  9.5478e-01,\n",
      "         9.5472e-01,  9.5469e-01, -2.4254e-06, -3.0536e-06, -3.3637e-06,\n",
      "        -3.8461e-06, -4.7734e-06, -5.1598e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 119\n",
      "Iter 119 - Available Memory: 4801.53 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4548, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3253962., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4668e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(21.9966, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5544e-01,  9.5491e-01,  9.5463e-01,  9.5450e-01,  9.5440e-01,\n",
      "         9.5434e-01,  9.5431e-01, -2.4235e-06, -3.0521e-06, -3.3620e-06,\n",
      "        -3.8437e-06, -4.7733e-06, -5.1591e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 120\n",
      "Iter 120 - Available Memory: 4662.41 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4549, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3254787., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4718e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0054, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5507e-01,  9.5454e-01,  9.5425e-01,  9.5412e-01,  9.5402e-01,\n",
      "         9.5396e-01,  9.5393e-01, -2.4225e-06, -3.0493e-06, -3.3610e-06,\n",
      "        -3.8419e-06, -4.7702e-06, -5.1567e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 120: Normalized Gradient = 0.05048051476478577, Adaptive learning rate = 0.001\n",
      "ite 121\n",
      "Iter 121 - Available Memory: 4721.89 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4550, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3255616., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4767e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0141, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5470e-01,  9.5416e-01,  9.5387e-01,  9.5374e-01,  9.5364e-01,\n",
      "         9.5358e-01,  9.5355e-01, -2.4208e-06, -3.0479e-06, -3.3589e-06,\n",
      "        -3.8398e-06, -4.7688e-06, -5.1540e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 122\n",
      "Iter 122 - Available Memory: 4570.89 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4551, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3256448.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4817e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0229, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5432e-01,  9.5378e-01,  9.5350e-01,  9.5336e-01,  9.5326e-01,\n",
      "         9.5320e-01,  9.5317e-01, -2.4194e-06, -3.0472e-06, -3.3567e-06,\n",
      "        -3.8393e-06, -4.7676e-06, -5.1539e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 123\n",
      "Iter 123 - Available Memory: 4517.52 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4552, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3257274.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4867e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0317, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5395e-01,  9.5341e-01,  9.5312e-01,  9.5298e-01,  9.5288e-01,\n",
      "         9.5282e-01,  9.5279e-01, -2.4180e-06, -3.0452e-06, -3.3565e-06,\n",
      "        -3.8371e-06, -4.7656e-06, -5.1520e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 124\n",
      "Iter 124 - Available Memory: 6635.61 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4553, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3258105.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4916e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0405, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5358e-01,  9.5303e-01,  9.5274e-01,  9.5260e-01,  9.5250e-01,\n",
      "         9.5244e-01,  9.5241e-01, -2.4166e-06, -3.0429e-06, -3.3528e-06,\n",
      "        -3.8347e-06, -4.7641e-06, -5.1510e-06])\n",
      "Wins_grad tensor([0.0188, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 125\n",
      "Iter 125 - Available Memory: 6409.92 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4554, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3258938.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.4966e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0493, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5321e-01,  9.5266e-01,  9.5236e-01,  9.5222e-01,  9.5212e-01,\n",
      "         9.5206e-01,  9.5203e-01, -2.4154e-06, -3.0411e-06, -3.3520e-06,\n",
      "        -3.8330e-06, -4.7613e-06, -5.1502e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 125: Normalized Gradient = 0.0504566989839077, Adaptive learning rate = 0.001\n",
      "ite 126\n",
      "Iter 126 - Available Memory: 6168.92 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4555, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3259771.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5016e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0581, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5284e-01,  9.5228e-01,  9.5198e-01,  9.5184e-01,  9.5174e-01,\n",
      "         9.5168e-01,  9.5165e-01, -2.4141e-06, -3.0396e-06, -3.3500e-06,\n",
      "        -3.8310e-06, -4.7595e-06, -5.1495e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 127\n",
      "Iter 127 - Available Memory: 5805.33 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4556, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3260604., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5066e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0670, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5247e-01,  9.5190e-01,  9.5160e-01,  9.5146e-01,  9.5136e-01,\n",
      "         9.5130e-01,  9.5127e-01, -2.4120e-06, -3.0380e-06, -3.3481e-06,\n",
      "        -3.8282e-06, -4.7568e-06, -5.1458e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 128\n",
      "Iter 128 - Available Memory: 5394.14 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4557, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3261438., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5116e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0758, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5209e-01,  9.5153e-01,  9.5123e-01,  9.5108e-01,  9.5099e-01,\n",
      "         9.5092e-01,  9.5089e-01, -2.4109e-06, -3.0357e-06, -3.3457e-06,\n",
      "        -3.8260e-06, -4.7562e-06, -5.1445e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 129\n",
      "Iter 129 - Available Memory: 5321.04 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4558, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3262274., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5166e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0846, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5172e-01,  9.5115e-01,  9.5085e-01,  9.5071e-01,  9.5061e-01,\n",
      "         9.5054e-01,  9.5051e-01, -2.4089e-06, -3.0344e-06, -3.3449e-06,\n",
      "        -3.8265e-06, -4.7541e-06, -5.1434e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 130\n",
      "Iter 130 - Available Memory: 5227.02 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4559, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3263110.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5217e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.0935, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5135e-01,  9.5078e-01,  9.5047e-01,  9.5033e-01,  9.5023e-01,\n",
      "         9.5016e-01,  9.5013e-01, -2.4076e-06, -3.0335e-06, -3.3431e-06,\n",
      "        -3.8234e-06, -4.7518e-06, -5.1425e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 130: Normalized Gradient = 0.05043303593993187, Adaptive learning rate = 0.001\n",
      "ite 131\n",
      "Iter 131 - Available Memory: 5287.66 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4560, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3263948.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5267e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1023, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5098e-01,  9.5040e-01,  9.5009e-01,  9.4995e-01,  9.4985e-01,\n",
      "         9.4978e-01,  9.4975e-01, -2.4067e-06, -3.0313e-06, -3.3418e-06,\n",
      "        -3.8207e-06, -4.7507e-06, -5.1388e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 132\n",
      "Iter 132 - Available Memory: 5190.20 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4562, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3264784.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5317e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1112, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5061e-01,  9.5002e-01,  9.4971e-01,  9.4957e-01,  9.4947e-01,\n",
      "         9.4940e-01,  9.4937e-01, -2.4046e-06, -3.0295e-06, -3.3389e-06,\n",
      "        -3.8191e-06, -4.7480e-06, -5.1387e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 133\n",
      "Iter 133 - Available Memory: 5154.41 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4563, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3265624.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5368e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1200, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.5024e-01,  9.4965e-01,  9.4934e-01,  9.4919e-01,  9.4909e-01,\n",
      "         9.4902e-01,  9.4898e-01, -2.4036e-06, -3.0286e-06, -3.3373e-06,\n",
      "        -3.8184e-06, -4.7468e-06, -5.1376e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 134\n",
      "Iter 134 - Available Memory: 5090.35 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4564, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3266465., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5418e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1289, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4986e-01,  9.4927e-01,  9.4896e-01,  9.4881e-01,  9.4871e-01,\n",
      "         9.4864e-01,  9.4860e-01, -2.4017e-06, -3.0266e-06, -3.3360e-06,\n",
      "        -3.8156e-06, -4.7450e-06, -5.1364e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 135\n",
      "Iter 135 - Available Memory: 4996.59 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4565, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3267304.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5468e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1378, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4949e-01,  9.4890e-01,  9.4858e-01,  9.4843e-01,  9.4833e-01,\n",
      "         9.4826e-01,  9.4822e-01, -2.4006e-06, -3.0245e-06, -3.3338e-06,\n",
      "        -3.8126e-06, -4.7410e-06, -5.1347e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 135: Normalized Gradient = 0.05040937662124634, Adaptive learning rate = 0.001\n",
      "ite 136\n",
      "Iter 136 - Available Memory: 4846.91 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4566, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3268143.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5519e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1467, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4912e-01,  9.4852e-01,  9.4820e-01,  9.4805e-01,  9.4795e-01,\n",
      "         9.4788e-01,  9.4784e-01, -2.3993e-06, -3.0231e-06, -3.3316e-06,\n",
      "        -3.8126e-06, -4.7408e-06, -5.1356e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 137\n",
      "Iter 137 - Available Memory: 4762.52 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4567, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3268986., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5569e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1556, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4875e-01,  9.4814e-01,  9.4782e-01,  9.4767e-01,  9.4757e-01,\n",
      "         9.4750e-01,  9.4746e-01, -2.3980e-06, -3.0207e-06, -3.3299e-06,\n",
      "        -3.8110e-06, -4.7386e-06, -5.1316e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 138\n",
      "Iter 138 - Available Memory: 4601.83 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4568, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3269830., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5620e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1645, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4838e-01,  9.4777e-01,  9.4745e-01,  9.4729e-01,  9.4719e-01,\n",
      "         9.4712e-01,  9.4708e-01, -2.3961e-06, -3.0194e-06, -3.3294e-06,\n",
      "        -3.8087e-06, -4.7362e-06, -5.1294e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 139\n",
      "Iter 139 - Available Memory: 4418.47 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4569, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3270673., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5671e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1734, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4801e-01,  9.4739e-01,  9.4707e-01,  9.4692e-01,  9.4681e-01,\n",
      "         9.4674e-01,  9.4670e-01, -2.3946e-06, -3.0178e-06, -3.3279e-06,\n",
      "        -3.8063e-06, -4.7356e-06, -5.1284e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 140\n",
      "Iter 140 - Available Memory: 4323.89 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4570, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3271520., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5722e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1823, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4763e-01,  9.4702e-01,  9.4669e-01,  9.4654e-01,  9.4643e-01,\n",
      "         9.4636e-01,  9.4632e-01, -2.3931e-06, -3.0154e-06, -3.3249e-06,\n",
      "        -3.8032e-06, -4.7316e-06, -5.1262e-06])\n",
      "Wins_grad tensor([0.0187, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 140: Normalized Gradient = 0.05038578808307648, Adaptive learning rate = 0.001\n",
      "ite 141\n",
      "Iter 141 - Available Memory: 4511.09 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4571, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3272365.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5773e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.1912, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4726e-01,  9.4664e-01,  9.4631e-01,  9.4616e-01,  9.4605e-01,\n",
      "         9.4598e-01,  9.4594e-01, -2.3915e-06, -3.0135e-06, -3.3231e-06,\n",
      "        -3.8020e-06, -4.7301e-06, -5.1257e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 142\n",
      "Iter 142 - Available Memory: 4378.49 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4572, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3273206.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5823e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2001, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4689e-01,  9.4626e-01,  9.4593e-01,  9.4578e-01,  9.4567e-01,\n",
      "         9.4559e-01,  9.4556e-01, -2.3905e-06, -3.0125e-06, -3.3211e-06,\n",
      "        -3.8009e-06, -4.7293e-06, -5.1245e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 143\n",
      "Iter 143 - Available Memory: 5639.63 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4573, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3274057.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5874e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2091, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4652e-01,  9.4589e-01,  9.4556e-01,  9.4540e-01,  9.4529e-01,\n",
      "         9.4521e-01,  9.4518e-01, -2.3888e-06, -3.0114e-06, -3.3191e-06,\n",
      "        -3.7988e-06, -4.7276e-06, -5.1228e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 144\n",
      "Iter 144 - Available Memory: 6845.45 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4574, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3274902., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5925e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2180, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4615e-01,  9.4551e-01,  9.4518e-01,  9.4502e-01,  9.4491e-01,\n",
      "         9.4483e-01,  9.4480e-01, -2.3880e-06, -3.0089e-06, -3.3173e-06,\n",
      "        -3.7961e-06, -4.7246e-06, -5.1229e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 145\n",
      "Iter 145 - Available Memory: 6574.63 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4575, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3275753., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.5976e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2270, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4578e-01,  9.4513e-01,  9.4480e-01,  9.4464e-01,  9.4453e-01,\n",
      "         9.4445e-01,  9.4442e-01, -2.3864e-06, -3.0075e-06, -3.3172e-06,\n",
      "        -3.7942e-06, -4.7226e-06, -5.1186e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 145: Normalized Gradient = 0.05036185309290886, Adaptive learning rate = 0.001\n",
      "ite 146\n",
      "Iter 146 - Available Memory: 6347.28 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4577, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3276605., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6028e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2359, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4540e-01,  9.4476e-01,  9.4442e-01,  9.4426e-01,  9.4415e-01,\n",
      "         9.4407e-01,  9.4404e-01, -2.3846e-06, -3.0049e-06, -3.3145e-06,\n",
      "        -3.7932e-06, -4.7210e-06, -5.1177e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0192, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 147\n",
      "Iter 147 - Available Memory: 6190.57 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4578, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3277451.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6079e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2449, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4503e-01,  9.4438e-01,  9.4404e-01,  9.4388e-01,  9.4377e-01,\n",
      "         9.4369e-01,  9.4366e-01, -2.3832e-06, -3.0041e-06, -3.3127e-06,\n",
      "        -3.7900e-06, -4.7195e-06, -5.1168e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 148\n",
      "Iter 148 - Available Memory: 5997.67 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4579, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3278307.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6130e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2539, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4466e-01,  9.4401e-01,  9.4367e-01,  9.4350e-01,  9.4339e-01,\n",
      "         9.4331e-01,  9.4328e-01, -2.3814e-06, -3.0019e-06, -3.3105e-06,\n",
      "        -3.7878e-06, -4.7184e-06, -5.1146e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 149\n",
      "Iter 149 - Available Memory: 5762.64 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4580, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3279157.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6181e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2628, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4429e-01,  9.4363e-01,  9.4329e-01,  9.4313e-01,  9.4301e-01,\n",
      "         9.4293e-01,  9.4290e-01, -2.3804e-06, -3.0000e-06, -3.3083e-06,\n",
      "        -3.7879e-06, -4.7164e-06, -5.1158e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 150\n",
      "Iter 150 - Available Memory: 5553.73 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4581, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3280011.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6233e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2718, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4392e-01,  9.4325e-01,  9.4291e-01,  9.4275e-01,  9.4263e-01,\n",
      "         9.4255e-01,  9.4252e-01, -2.3788e-06, -2.9993e-06, -3.3073e-06,\n",
      "        -3.7861e-06, -4.7144e-06, -5.1147e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 150: Normalized Gradient = 0.0503384992480278, Adaptive learning rate = 0.001\n",
      "ite 151\n",
      "Iter 151 - Available Memory: 6161.62 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4582, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3280865.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6284e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2808, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4355e-01,  9.4288e-01,  9.4253e-01,  9.4237e-01,  9.4225e-01,\n",
      "         9.4217e-01,  9.4213e-01, -2.3776e-06, -2.9978e-06, -3.3067e-06,\n",
      "        -3.7832e-06, -4.7121e-06, -5.1122e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 152\n",
      "Iter 152 - Available Memory: 5812.77 MB\n",
      "Ratio tensor(0.9982, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4583, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3281720., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6336e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2898, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4317e-01,  9.4250e-01,  9.4215e-01,  9.4199e-01,  9.4187e-01,\n",
      "         9.4179e-01,  9.4175e-01, -2.3763e-06, -2.9953e-06, -3.3018e-06,\n",
      "        -3.7819e-06, -4.7113e-06, -5.1099e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0192, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 153\n",
      "Iter 153 - Available Memory: 5712.21 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4584, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3282574.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6387e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.2988, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4280e-01,  9.4213e-01,  9.4177e-01,  9.4161e-01,  9.4149e-01,\n",
      "         9.4141e-01,  9.4137e-01, -2.3747e-06, -2.9937e-06, -3.3008e-06,\n",
      "        -3.7778e-06, -4.7087e-06, -5.1088e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 154\n",
      "Iter 154 - Available Memory: 5565.91 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4585, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3283433., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6439e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3078, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4243e-01,  9.4175e-01,  9.4140e-01,  9.4123e-01,  9.4111e-01,\n",
      "         9.4103e-01,  9.4099e-01, -2.3735e-06, -2.9923e-06, -3.3003e-06,\n",
      "        -3.7777e-06, -4.7068e-06, -5.1060e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 155\n",
      "Iter 155 - Available Memory: 5470.61 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4586, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3284287.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6491e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3169, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4206e-01,  9.4137e-01,  9.4102e-01,  9.4085e-01,  9.4073e-01,\n",
      "         9.4065e-01,  9.4061e-01, -2.3711e-06, -2.9891e-06, -3.2979e-06,\n",
      "        -3.7753e-06, -4.7045e-06, -5.1056e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 155: Normalized Gradient = 0.05031467601656914, Adaptive learning rate = 0.001\n",
      "ite 156\n",
      "Iter 156 - Available Memory: 5353.67 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4587, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3285147.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6543e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3259, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4169e-01,  9.4100e-01,  9.4064e-01,  9.4047e-01,  9.4035e-01,\n",
      "         9.4027e-01,  9.4023e-01, -2.3702e-06, -2.9876e-06, -3.2972e-06,\n",
      "        -3.7749e-06, -4.7033e-06, -5.1045e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 157\n",
      "Iter 157 - Available Memory: 5305.39 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4588, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3286007.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6595e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3349, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4132e-01,  9.4062e-01,  9.4026e-01,  9.4009e-01,  9.3997e-01,\n",
      "         9.3989e-01,  9.3985e-01, -2.3684e-06, -2.9868e-06, -3.2944e-06,\n",
      "        -3.7732e-06, -4.7002e-06, -5.1033e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 158\n",
      "Iter 158 - Available Memory: 5438.18 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4590, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3286863.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6646e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3440, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4094e-01,  9.4024e-01,  9.3988e-01,  9.3971e-01,  9.3959e-01,\n",
      "         9.3951e-01,  9.3947e-01, -2.3669e-06, -2.9843e-06, -3.2926e-06,\n",
      "        -3.7695e-06, -4.7006e-06, -5.1013e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 159\n",
      "Iter 159 - Available Memory: 5267.68 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4591, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3287728.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6698e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3530, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4057e-01,  9.3987e-01,  9.3951e-01,  9.3934e-01,  9.3921e-01,\n",
      "         9.3913e-01,  9.3909e-01, -2.3658e-06, -2.9828e-06, -3.2916e-06,\n",
      "        -3.7686e-06, -4.6969e-06, -5.0998e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0002,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 160\n",
      "Iter 160 - Available Memory: 5045.10 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4592, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3288588., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6750e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3621, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.4020e-01,  9.3949e-01,  9.3913e-01,  9.3896e-01,  9.3883e-01,\n",
      "         9.3875e-01,  9.3871e-01, -2.3647e-06, -2.9814e-06, -3.2897e-06,\n",
      "        -3.7653e-06, -4.6955e-06, -5.0971e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 160: Normalized Gradient = 0.05029110610485077, Adaptive learning rate = 0.001\n",
      "ite 161\n",
      "Iter 161 - Available Memory: 4878.25 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4593, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3289452.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6803e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3711, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3983e-01,  9.3912e-01,  9.3875e-01,  9.3858e-01,  9.3845e-01,\n",
      "         9.3837e-01,  9.3833e-01, -2.3623e-06, -2.9792e-06, -3.2868e-06,\n",
      "        -3.7645e-06, -4.6934e-06, -5.0975e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 162\n",
      "Iter 162 - Available Memory: 4744.24 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4594, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3290317., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6855e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3802, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3946e-01,  9.3874e-01,  9.3837e-01,  9.3820e-01,  9.3807e-01,\n",
      "         9.3799e-01,  9.3795e-01, -2.3617e-06, -2.9778e-06, -3.2851e-06,\n",
      "        -3.7628e-06, -4.6917e-06, -5.0957e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 163\n",
      "Iter 163 - Available Memory: 5011.82 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4595, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3291180.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6907e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3893, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3909e-01,  9.3836e-01,  9.3799e-01,  9.3782e-01,  9.3769e-01,\n",
      "         9.3761e-01,  9.3757e-01, -2.3600e-06, -2.9764e-06, -3.2849e-06,\n",
      "        -3.7604e-06, -4.6901e-06, -5.0942e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 164\n",
      "Iter 164 - Available Memory: 4814.68 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4596, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3292044.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.6959e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.3984, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3871e-01,  9.3799e-01,  9.3762e-01,  9.3744e-01,  9.3731e-01,\n",
      "         9.3723e-01,  9.3719e-01, -2.3592e-06, -2.9740e-06, -3.2821e-06,\n",
      "        -3.7594e-06, -4.6885e-06, -5.0927e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0191, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 165\n",
      "Iter 165 - Available Memory: 4620.47 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4597, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3292912., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7012e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4075, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3834e-01,  9.3761e-01,  9.3724e-01,  9.3706e-01,  9.3693e-01,\n",
      "         9.3685e-01,  9.3681e-01, -2.3566e-06, -2.9726e-06, -3.2798e-06,\n",
      "        -3.7581e-06, -4.6867e-06, -5.0903e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 165: Normalized Gradient = 0.05026760324835777, Adaptive learning rate = 0.001\n",
      "ite 166\n",
      "Iter 166 - Available Memory: 4644.08 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4598, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3293777.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7064e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4166, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3797e-01,  9.3723e-01,  9.3686e-01,  9.3668e-01,  9.3655e-01,\n",
      "         9.3647e-01,  9.3643e-01, -2.3556e-06, -2.9708e-06, -3.2789e-06,\n",
      "        -3.7569e-06, -4.6856e-06, -5.0905e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 167\n",
      "Iter 167 - Available Memory: 4532.01 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4599, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3294647.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7117e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4257, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3760e-01,  9.3686e-01,  9.3648e-01,  9.3630e-01,  9.3617e-01,\n",
      "         9.3609e-01,  9.3605e-01, -2.3545e-06, -2.9690e-06, -3.2764e-06,\n",
      "        -3.7531e-06, -4.6834e-06, -5.0902e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 168\n",
      "Iter 168 - Available Memory: 4478.11 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4601, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3295517., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7169e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4348, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3723e-01,  9.3648e-01,  9.3610e-01,  9.3592e-01,  9.3579e-01,\n",
      "         9.3571e-01,  9.3567e-01, -2.3530e-06, -2.9670e-06, -3.2755e-06,\n",
      "        -3.7507e-06, -4.6813e-06, -5.0879e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 169\n",
      "Iter 169 - Available Memory: 4384.48 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4602, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3296385., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7222e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4439, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3686e-01,  9.3611e-01,  9.3573e-01,  9.3555e-01,  9.3541e-01,\n",
      "         9.3533e-01,  9.3528e-01, -2.3513e-06, -2.9658e-06, -3.2720e-06,\n",
      "        -3.7500e-06, -4.6779e-06, -5.0850e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 170\n",
      "Iter 170 - Available Memory: 4524.17 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4603, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3297257.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7275e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4531, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3648e-01,  9.3573e-01,  9.3535e-01,  9.3517e-01,  9.3503e-01,\n",
      "         9.3495e-01,  9.3490e-01, -2.3498e-06, -2.9634e-06, -3.2711e-06,\n",
      "        -3.7494e-06, -4.6772e-06, -5.0830e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 170: Normalized Gradient = 0.050244223326444626, Adaptive learning rate = 0.001\n",
      "ite 171\n",
      "Iter 171 - Available Memory: 4359.31 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4604, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3298127.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7327e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4622, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3611e-01,  9.3535e-01,  9.3497e-01,  9.3479e-01,  9.3465e-01,\n",
      "         9.3457e-01,  9.3452e-01, -2.3485e-06, -2.9625e-06, -3.2691e-06,\n",
      "        -3.7463e-06, -4.6761e-06, -5.0829e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 172\n",
      "Iter 172 - Available Memory: 4200.78 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4605, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3299002.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7380e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4713, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3574e-01,  9.3498e-01,  9.3459e-01,  9.3441e-01,  9.3428e-01,\n",
      "         9.3419e-01,  9.3414e-01, -2.3477e-06, -2.9598e-06, -3.2687e-06,\n",
      "        -3.7437e-06, -4.6730e-06, -5.0816e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 173\n",
      "Iter 173 - Available Memory: 4096.63 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4606, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3299874.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7433e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4805, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3537e-01,  9.3460e-01,  9.3421e-01,  9.3403e-01,  9.3390e-01,\n",
      "         9.3381e-01,  9.3376e-01, -2.3460e-06, -2.9593e-06, -3.2664e-06,\n",
      "        -3.7425e-06, -4.6710e-06, -5.0783e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 174\n",
      "Iter 174 - Available Memory: 4263.53 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4607, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3300749.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7486e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4897, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3500e-01,  9.3422e-01,  9.3383e-01,  9.3365e-01,  9.3352e-01,\n",
      "         9.3343e-01,  9.3338e-01, -2.3443e-06, -2.9576e-06, -3.2643e-06,\n",
      "        -3.7410e-06, -4.6685e-06, -5.0780e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 175\n",
      "Iter 175 - Available Memory: 4069.76 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4608, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3301624.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7539e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.4988, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3463e-01,  9.3385e-01,  9.3346e-01,  9.3327e-01,  9.3314e-01,\n",
      "         9.3305e-01,  9.3300e-01, -2.3422e-06, -2.9551e-06, -3.2616e-06,\n",
      "        -3.7380e-06, -4.6655e-06, -5.0747e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 175: Normalized Gradient = 0.050220586359500885, Adaptive learning rate = 0.001\n",
      "ite 176\n",
      "Iter 176 - Available Memory: 3797.34 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4609, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3302497., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7592e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5080, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3425e-01,  9.3347e-01,  9.3308e-01,  9.3289e-01,  9.3276e-01,\n",
      "         9.3267e-01,  9.3262e-01, -2.3410e-06, -2.9527e-06, -3.2610e-06,\n",
      "        -3.7363e-06, -4.6653e-06, -5.0761e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 177\n",
      "Iter 177 - Available Memory: 6280.18 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4611, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3303376., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7645e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5172, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3388e-01,  9.3309e-01,  9.3270e-01,  9.3251e-01,  9.3238e-01,\n",
      "         9.3229e-01,  9.3224e-01, -2.3394e-06, -2.9516e-06, -3.2582e-06,\n",
      "        -3.7344e-06, -4.6630e-06, -5.0730e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 178\n",
      "Iter 178 - Available Memory: 6036.12 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4612, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3304253.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7698e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5264, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3351e-01,  9.3272e-01,  9.3232e-01,  9.3214e-01,  9.3200e-01,\n",
      "         9.3190e-01,  9.3186e-01, -2.3385e-06, -2.9498e-06, -3.2573e-06,\n",
      "        -3.7333e-06, -4.6613e-06, -5.0725e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 179\n",
      "Iter 179 - Available Memory: 5789.44 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4613, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3305131., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7752e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5356, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3314e-01,  9.3234e-01,  9.3194e-01,  9.3176e-01,  9.3162e-01,\n",
      "         9.3152e-01,  9.3148e-01, -2.3363e-06, -2.9478e-06, -3.2545e-06,\n",
      "        -3.7303e-06, -4.6594e-06, -5.0702e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 180\n",
      "Iter 180 - Available Memory: 5569.05 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4614, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3306011.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7805e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5448, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3277e-01,  9.3197e-01,  9.3157e-01,  9.3138e-01,  9.3124e-01,\n",
      "         9.3114e-01,  9.3110e-01, -2.3357e-06, -2.9472e-06, -3.2542e-06,\n",
      "        -3.7291e-06, -4.6583e-06, -5.0699e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 180: Normalized Gradient = 0.05019700899720192, Adaptive learning rate = 0.001\n",
      "ite 181\n",
      "Iter 181 - Available Memory: 5232.23 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4615, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3306891., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7858e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5540, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3239e-01,  9.3159e-01,  9.3119e-01,  9.3100e-01,  9.3086e-01,\n",
      "         9.3076e-01,  9.3072e-01, -2.3337e-06, -2.9446e-06, -3.2510e-06,\n",
      "        -3.7270e-06, -4.6555e-06, -5.0675e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 182\n",
      "Iter 182 - Available Memory: 4935.08 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4616, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3307773.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7912e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5632, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3202e-01,  9.3121e-01,  9.3081e-01,  9.3062e-01,  9.3048e-01,\n",
      "         9.3038e-01,  9.3034e-01, -2.3325e-06, -2.9434e-06, -3.2504e-06,\n",
      "        -3.7250e-06, -4.6532e-06, -5.0656e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 183\n",
      "Iter 183 - Available Memory: 6891.45 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4617, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3308652., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.7965e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5724, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3165e-01,  9.3084e-01,  9.3043e-01,  9.3024e-01,  9.3010e-01,\n",
      "         9.3000e-01,  9.2996e-01, -2.3306e-06, -2.9411e-06, -3.2480e-06,\n",
      "        -3.7230e-06, -4.6520e-06, -5.0635e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 184\n",
      "Iter 184 - Available Memory: 6626.73 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4618, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3309537., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8019e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5817, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3128e-01,  9.3046e-01,  9.3005e-01,  9.2986e-01,  9.2972e-01,\n",
      "         9.2962e-01,  9.2958e-01, -2.3293e-06, -2.9396e-06, -3.2459e-06,\n",
      "        -3.7216e-06, -4.6494e-06, -5.0626e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 185\n",
      "Iter 185 - Available Memory: 5649.84 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4620, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3310425., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8073e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.5909, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3091e-01,  9.3008e-01,  9.2968e-01,  9.2948e-01,  9.2934e-01,\n",
      "         9.2924e-01,  9.2920e-01, -2.3276e-06, -2.9372e-06, -3.2436e-06,\n",
      "        -3.7189e-06, -4.6466e-06, -5.0613e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 185: Normalized Gradient = 0.05017377436161041, Adaptive learning rate = 0.001\n",
      "ite 186\n",
      "Iter 186 - Available Memory: 5448.02 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4621, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3311307., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8126e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6002, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3054e-01,  9.2971e-01,  9.2930e-01,  9.2910e-01,  9.2896e-01,\n",
      "         9.2886e-01,  9.2882e-01, -2.3265e-06, -2.9359e-06, -3.2431e-06,\n",
      "        -3.7178e-06, -4.6462e-06, -5.0610e-06])\n",
      "Wins_grad tensor([0.0187, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 187\n",
      "Iter 187 - Available Memory: 5404.44 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4622, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3312192.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8180e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6094, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.3016e-01,  9.2933e-01,  9.2892e-01,  9.2872e-01,  9.2858e-01,\n",
      "         9.2848e-01,  9.2844e-01, -2.3251e-06, -2.9338e-06, -3.2414e-06,\n",
      "        -3.7155e-06, -4.6455e-06, -5.0597e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 188\n",
      "Iter 188 - Available Memory: 5342.87 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4623, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3313079., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8234e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6187, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2979e-01,  9.2895e-01,  9.2854e-01,  9.2835e-01,  9.2820e-01,\n",
      "         9.2810e-01,  9.2806e-01, -2.3237e-06, -2.9323e-06, -3.2374e-06,\n",
      "        -3.7134e-06, -4.6431e-06, -5.0575e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 189\n",
      "Iter 189 - Available Memory: 5283.65 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4624, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3313970.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8288e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6280, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2942e-01,  9.2858e-01,  9.2816e-01,  9.2797e-01,  9.2782e-01,\n",
      "         9.2772e-01,  9.2768e-01, -2.3224e-06, -2.9317e-06, -3.2369e-06,\n",
      "        -3.7108e-06, -4.6383e-06, -5.0550e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 190\n",
      "Iter 190 - Available Memory: 4237.35 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4625, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3314856., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8342e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6372, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2905e-01,  9.2820e-01,  9.2779e-01,  9.2759e-01,  9.2744e-01,\n",
      "         9.2734e-01,  9.2729e-01, -2.3210e-06, -2.9294e-06, -3.2341e-06,\n",
      "        -3.7098e-06, -4.6395e-06, -5.0531e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 190: Normalized Gradient = 0.050150178372859955, Adaptive learning rate = 0.001\n",
      "ite 191\n",
      "Iter 191 - Available Memory: 3991.61 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4626, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3315744.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8396e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6465, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2868e-01,  9.2783e-01,  9.2741e-01,  9.2721e-01,  9.2706e-01,\n",
      "         9.2696e-01,  9.2691e-01, -2.3195e-06, -2.9277e-06, -3.2339e-06,\n",
      "        -3.7080e-06, -4.6375e-06, -5.0536e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 192\n",
      "Iter 192 - Available Memory: 4016.03 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4627, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3316635., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8450e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6558, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2831e-01,  9.2745e-01,  9.2703e-01,  9.2683e-01,  9.2668e-01,\n",
      "         9.2658e-01,  9.2653e-01, -2.3181e-06, -2.9253e-06, -3.2314e-06,\n",
      "        -3.7046e-06, -4.6347e-06, -5.0515e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 193\n",
      "Iter 193 - Available Memory: 3875.41 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4629, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3317528.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8505e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6651, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2793e-01,  9.2707e-01,  9.2665e-01,  9.2645e-01,  9.2630e-01,\n",
      "         9.2620e-01,  9.2615e-01, -2.3165e-06, -2.9236e-06, -3.2301e-06,\n",
      "        -3.7048e-06, -4.6326e-06, -5.0502e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 194\n",
      "Iter 194 - Available Memory: 3740.86 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4630, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3318422., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8559e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6744, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2756e-01,  9.2670e-01,  9.2627e-01,  9.2607e-01,  9.2592e-01,\n",
      "         9.2582e-01,  9.2577e-01, -2.3148e-06, -2.9216e-06, -3.2272e-06,\n",
      "        -3.7015e-06, -4.6287e-06, -5.0480e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 195\n",
      "Iter 195 - Available Memory: 4787.77 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4631, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3319313., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8613e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6838, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2719e-01,  9.2632e-01,  9.2589e-01,  9.2569e-01,  9.2554e-01,\n",
      "         9.2544e-01,  9.2539e-01, -2.3132e-06, -2.9208e-06, -3.2260e-06,\n",
      "        -3.7027e-06, -4.6307e-06, -5.0466e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 195: Normalized Gradient = 0.05012684687972069, Adaptive learning rate = 0.001\n",
      "ite 196\n",
      "Iter 196 - Available Memory: 3643.06 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4632, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3320205.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8667e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.6931, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2682e-01,  9.2594e-01,  9.2552e-01,  9.2531e-01,  9.2516e-01,\n",
      "         9.2506e-01,  9.2501e-01, -2.3118e-06, -2.9185e-06, -3.2237e-06,\n",
      "        -3.6981e-06, -4.6271e-06, -5.0439e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 197\n",
      "Iter 197 - Available Memory: 3303.61 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4633, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3321101., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8722e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7024, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2645e-01,  9.2557e-01,  9.2514e-01,  9.2494e-01,  9.2478e-01,\n",
      "         9.2468e-01,  9.2463e-01, -2.3105e-06, -2.9178e-06, -3.2229e-06,\n",
      "        -3.6970e-06, -4.6257e-06, -5.0427e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 198\n",
      "Iter 198 - Available Memory: 4023.23 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4634, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3321997.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8777e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7118, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2607e-01,  9.2519e-01,  9.2476e-01,  9.2456e-01,  9.2440e-01,\n",
      "         9.2430e-01,  9.2425e-01, -2.3092e-06, -2.9148e-06, -3.2206e-06,\n",
      "        -3.6952e-06, -4.6239e-06, -5.0447e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 199\n",
      "Iter 199 - Available Memory: 5701.36 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4636, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3322896.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8831e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7211, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2570e-01,  9.2481e-01,  9.2438e-01,  9.2418e-01,  9.2402e-01,\n",
      "         9.2392e-01,  9.2387e-01, -2.3080e-06, -2.9130e-06, -3.2189e-06,\n",
      "        -3.6919e-06, -4.6211e-06, -5.0419e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0191, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 200\n",
      "Iter 200 - Available Memory: 4986.25 MB\n",
      "Ratio tensor(0.9983, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4637, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3323792.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8886e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7305, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2533e-01,  9.2444e-01,  9.2400e-01,  9.2380e-01,  9.2364e-01,\n",
      "         9.2354e-01,  9.2349e-01, -2.3060e-06, -2.9114e-06, -3.2163e-06,\n",
      "        -3.6912e-06, -4.6209e-06, -5.0406e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 200: Normalized Gradient = 0.050103381276130676, Adaptive learning rate = 0.001\n",
      "ite 201\n",
      "Iter 201 - Available Memory: 5045.19 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4638, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3324689.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8941e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7398, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2496e-01,  9.2406e-01,  9.2363e-01,  9.2342e-01,  9.2326e-01,\n",
      "         9.2316e-01,  9.2311e-01, -2.3048e-06, -2.9109e-06, -3.2133e-06,\n",
      "        -3.6900e-06, -4.6183e-06, -5.0395e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 202\n",
      "Iter 202 - Available Memory: 6609.00 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4639, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3325589.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.8996e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7492, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2459e-01,  9.2368e-01,  9.2325e-01,  9.2304e-01,  9.2288e-01,\n",
      "         9.2278e-01,  9.2273e-01, -2.3036e-06, -2.9085e-06, -3.2136e-06,\n",
      "        -3.6876e-06, -4.6165e-06, -5.0371e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 203\n",
      "Iter 203 - Available Memory: 5786.23 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4640, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3326485.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9050e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7586, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2422e-01,  9.2331e-01,  9.2287e-01,  9.2266e-01,  9.2250e-01,\n",
      "         9.2240e-01,  9.2235e-01, -2.3018e-06, -2.9068e-06, -3.2120e-06,\n",
      "        -3.6858e-06, -4.6132e-06, -5.0354e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 204\n",
      "Iter 204 - Available Memory: 5318.35 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4641, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3327392., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9106e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7680, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2384e-01,  9.2293e-01,  9.2249e-01,  9.2228e-01,  9.2213e-01,\n",
      "         9.2202e-01,  9.2197e-01, -2.3003e-06, -2.9049e-06, -3.2100e-06,\n",
      "        -3.6849e-06, -4.6130e-06, -5.0345e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 205\n",
      "Iter 205 - Available Memory: 5456.70 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4642, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3328293.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9160e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7774, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2347e-01,  9.2255e-01,  9.2211e-01,  9.2190e-01,  9.2175e-01,\n",
      "         9.2164e-01,  9.2159e-01, -2.2989e-06, -2.9030e-06, -3.2077e-06,\n",
      "        -3.6823e-06, -4.6127e-06, -5.0327e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 205: Normalized Gradient = 0.05007993057370186, Adaptive learning rate = 0.001\n",
      "ite 206\n",
      "Iter 206 - Available Memory: 4490.31 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4644, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3329199.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9216e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7868, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2310e-01,  9.2218e-01,  9.2174e-01,  9.2153e-01,  9.2137e-01,\n",
      "         9.2126e-01,  9.2121e-01, -2.2975e-06, -2.9014e-06, -3.2048e-06,\n",
      "        -3.6789e-06, -4.6094e-06, -5.0310e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0191, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 207\n",
      "Iter 207 - Available Memory: 4385.50 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4645, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3330099.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9271e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.7962, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2273e-01,  9.2180e-01,  9.2136e-01,  9.2115e-01,  9.2099e-01,\n",
      "         9.2088e-01,  9.2083e-01, -2.2954e-06, -2.8996e-06, -3.2047e-06,\n",
      "        -3.6774e-06, -4.6054e-06, -5.0296e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 208\n",
      "Iter 208 - Available Memory: 6073.75 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4646, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3331006.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9326e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8056, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2236e-01,  9.2142e-01,  9.2098e-01,  9.2077e-01,  9.2061e-01,\n",
      "         9.2050e-01,  9.2045e-01, -2.2945e-06, -2.8977e-06, -3.2028e-06,\n",
      "        -3.6773e-06, -4.6036e-06, -5.0275e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 209\n",
      "Iter 209 - Available Memory: 5734.88 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4647, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3331913.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9381e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8150, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2198e-01,  9.2105e-01,  9.2060e-01,  9.2039e-01,  9.2023e-01,\n",
      "         9.2012e-01,  9.2007e-01, -2.2933e-06, -2.8966e-06, -3.2019e-06,\n",
      "        -3.6748e-06, -4.6037e-06, -5.0271e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 210\n",
      "Iter 210 - Available Memory: 5317.32 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4648, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3332820., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9437e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8245, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2161e-01,  9.2067e-01,  9.2022e-01,  9.2001e-01,  9.1985e-01,\n",
      "         9.1974e-01,  9.1969e-01, -2.2918e-06, -2.8944e-06, -3.1995e-06,\n",
      "        -3.6744e-06, -4.6026e-06, -5.0267e-06])\n",
      "Wins_grad tensor([0.0186, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 210: Normalized Gradient = 0.05005670711398125, Adaptive learning rate = 0.001\n",
      "ite 211\n",
      "Iter 211 - Available Memory: 4848.57 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4649, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3333727.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9492e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8339, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2124e-01,  9.2030e-01,  9.1985e-01,  9.1963e-01,  9.1947e-01,\n",
      "         9.1936e-01,  9.1930e-01, -2.2901e-06, -2.8925e-06, -3.1978e-06,\n",
      "        -3.6711e-06, -4.5991e-06, -5.0242e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 212\n",
      "Iter 212 - Available Memory: 5593.37 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4651, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3334636.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9548e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8434, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2087e-01,  9.1992e-01,  9.1947e-01,  9.1925e-01,  9.1909e-01,\n",
      "         9.1898e-01,  9.1892e-01, -2.2889e-06, -2.8898e-06, -3.1954e-06,\n",
      "        -3.6685e-06, -4.5965e-06, -5.0221e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 213\n",
      "Iter 213 - Available Memory: 4922.07 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4652, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3335545.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9603e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8528, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2050e-01,  9.1954e-01,  9.1909e-01,  9.1887e-01,  9.1871e-01,\n",
      "         9.1860e-01,  9.1854e-01, -2.2877e-06, -2.8895e-06, -3.1939e-06,\n",
      "        -3.6660e-06, -4.5950e-06, -5.0216e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 214\n",
      "Iter 214 - Available Memory: 4856.07 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4653, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3336454.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9659e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8623, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.2013e-01,  9.1917e-01,  9.1871e-01,  9.1850e-01,  9.1833e-01,\n",
      "         9.1822e-01,  9.1816e-01, -2.2857e-06, -2.8877e-06, -3.1910e-06,\n",
      "        -3.6662e-06, -4.5939e-06, -5.0189e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 215\n",
      "Iter 215 - Available Memory: 5702.48 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4654, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3337366.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9714e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8717, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1975e-01,  9.1879e-01,  9.1833e-01,  9.1812e-01,  9.1795e-01,\n",
      "         9.1784e-01,  9.1778e-01, -2.2846e-06, -2.8860e-06, -3.1901e-06,\n",
      "        -3.6610e-06, -4.5911e-06, -5.0179e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 215: Normalized Gradient = 0.050033263862133026, Adaptive learning rate = 0.001\n",
      "ite 216\n",
      "Iter 216 - Available Memory: 4939.15 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4655, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3338279., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9770e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8812, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1938e-01,  9.1841e-01,  9.1796e-01,  9.1774e-01,  9.1757e-01,\n",
      "         9.1746e-01,  9.1740e-01, -2.2833e-06, -2.8837e-06, -3.1870e-06,\n",
      "        -3.6604e-06, -4.5902e-06, -5.0144e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 217\n",
      "Iter 217 - Available Memory: 4726.79 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4656, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3339198.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9827e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.8907, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1901e-01,  9.1804e-01,  9.1758e-01,  9.1736e-01,  9.1719e-01,\n",
      "         9.1708e-01,  9.1702e-01, -2.2811e-06, -2.8823e-06, -3.1866e-06,\n",
      "        -3.6599e-06, -4.5863e-06, -5.0147e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0190, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 218\n",
      "Iter 218 - Available Memory: 4431.69 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4658, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3340107., grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9882e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9002, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1864e-01,  9.1766e-01,  9.1720e-01,  9.1698e-01,  9.1681e-01,\n",
      "         9.1670e-01,  9.1664e-01, -2.2800e-06, -2.8806e-06, -3.1844e-06,\n",
      "        -3.6560e-06, -4.5841e-06, -5.0122e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 219\n",
      "Iter 219 - Available Memory: 4274.23 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4659, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3341024.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9938e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9097, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1827e-01,  9.1728e-01,  9.1682e-01,  9.1660e-01,  9.1643e-01,\n",
      "         9.1632e-01,  9.1626e-01, -2.2786e-06, -2.8788e-06, -3.1839e-06,\n",
      "        -3.6560e-06, -4.5851e-06, -5.0144e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 220\n",
      "Iter 220 - Available Memory: 4171.77 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4660, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3341940.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(9.9994e-07, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9192, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1789e-01,  9.1691e-01,  9.1644e-01,  9.1622e-01,  9.1605e-01,\n",
      "         9.1594e-01,  9.1588e-01, -2.2769e-06, -2.8766e-06, -3.1800e-06,\n",
      "        -3.6523e-06, -4.5807e-06, -5.0102e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 220: Normalized Gradient = 0.050010111182928085, Adaptive learning rate = 0.001\n",
      "ite 221\n",
      "Iter 221 - Available Memory: 4177.50 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4661, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3342855., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0005e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9287, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1752e-01,  9.1653e-01,  9.1606e-01,  9.1584e-01,  9.1567e-01,\n",
      "         9.1556e-01,  9.1550e-01, -2.2756e-06, -2.8741e-06, -3.1783e-06,\n",
      "        -3.6513e-06, -4.5784e-06, -5.0088e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 222\n",
      "Iter 222 - Available Memory: 3988.94 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4662, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3343774.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0011e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9383, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1715e-01,  9.1615e-01,  9.1569e-01,  9.1546e-01,  9.1529e-01,\n",
      "         9.1518e-01,  9.1512e-01, -2.2744e-06, -2.8732e-06, -3.1767e-06,\n",
      "        -3.6518e-06, -4.5791e-06, -5.0072e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 223\n",
      "Iter 223 - Available Memory: 6233.70 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4663, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3344695., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0016e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9478, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1678e-01,  9.1578e-01,  9.1531e-01,  9.1509e-01,  9.1491e-01,\n",
      "         9.1480e-01,  9.1474e-01, -2.2726e-06, -2.8701e-06, -3.1751e-06,\n",
      "        -3.6469e-06, -4.5759e-06, -5.0062e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 224\n",
      "Iter 224 - Available Memory: 5288.95 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4665, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3345614.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0022e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9573, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1641e-01,  9.1540e-01,  9.1493e-01,  9.1471e-01,  9.1453e-01,\n",
      "         9.1442e-01,  9.1436e-01, -2.2714e-06, -2.8704e-06, -3.1728e-06,\n",
      "        -3.6455e-06, -4.5746e-06, -5.0053e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 225\n",
      "Iter 225 - Available Memory: 5806.05 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4666, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3346536.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0028e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9669, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1604e-01,  9.1502e-01,  9.1455e-01,  9.1433e-01,  9.1415e-01,\n",
      "         9.1404e-01,  9.1398e-01, -2.2705e-06, -2.8681e-06, -3.1712e-06,\n",
      "        -3.6445e-06, -4.5723e-06, -5.0041e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "Iteration 225: Normalized Gradient = 0.049986883997917175, Adaptive learning rate = 0.001\n",
      "ite 226\n",
      "Iter 226 - Available Memory: 5321.71 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4667, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3347458., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0033e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9765, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1566e-01,  9.1465e-01,  9.1417e-01,  9.1395e-01,  9.1377e-01,\n",
      "         9.1366e-01,  9.1360e-01, -2.2685e-06, -2.8672e-06, -3.1698e-06,\n",
      "        -3.6422e-06, -4.5703e-06, -5.0020e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0003])\n",
      "ite 227\n",
      "Iter 227 - Available Memory: 4985.21 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4668, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3348381., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0039e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9860, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1529e-01,  9.1427e-01,  9.1380e-01,  9.1357e-01,  9.1339e-01,\n",
      "         9.1328e-01,  9.1322e-01, -2.2676e-06, -2.8652e-06, -3.1680e-06,\n",
      "        -3.6390e-06, -4.5686e-06, -5.0000e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 228\n",
      "Iter 228 - Available Memory: 4710.85 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4669, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3349305.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0045e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(22.9956, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1492e-01,  9.1389e-01,  9.1342e-01,  9.1319e-01,  9.1301e-01,\n",
      "         9.1290e-01,  9.1284e-01, -2.2658e-06, -2.8632e-06, -3.1660e-06,\n",
      "        -3.6379e-06, -4.5670e-06, -4.9995e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 229\n",
      "Iter 229 - Available Memory: 4465.09 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4671, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3350228.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0050e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0052, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1455e-01,  9.1352e-01,  9.1304e-01,  9.1281e-01,  9.1263e-01,\n",
      "         9.1252e-01,  9.1246e-01, -2.2642e-06, -2.8606e-06, -3.1635e-06,\n",
      "        -3.6366e-06, -4.5639e-06, -4.9981e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 230\n",
      "Iter 230 - Available Memory: 4442.10 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4672, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3351155.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0056e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0148, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1418e-01,  9.1314e-01,  9.1266e-01,  9.1243e-01,  9.1226e-01,\n",
      "         9.1214e-01,  9.1208e-01, -2.2625e-06, -2.8594e-06, -3.1620e-06,\n",
      "        -3.6325e-06, -4.5622e-06, -4.9946e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 230: Normalized Gradient = 0.04996364191174507, Adaptive learning rate = 0.001\n",
      "ite 231\n",
      "Iter 231 - Available Memory: 6088.14 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4673, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3352083.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0062e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0244, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1380e-01,  9.1276e-01,  9.1228e-01,  9.1206e-01,  9.1188e-01,\n",
      "         9.1175e-01,  9.1170e-01, -2.2611e-06, -2.8569e-06, -3.1597e-06,\n",
      "        -3.6310e-06, -4.5593e-06, -4.9941e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 232\n",
      "Iter 232 - Available Memory: 5795.97 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4674, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3353009.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0067e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0340, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1343e-01,  9.1239e-01,  9.1191e-01,  9.1168e-01,  9.1150e-01,\n",
      "         9.1137e-01,  9.1132e-01, -2.2595e-06, -2.8548e-06, -3.1593e-06,\n",
      "        -3.6304e-06, -4.5591e-06, -4.9925e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 233\n",
      "Iter 233 - Available Memory: 5588.33 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4675, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3353937., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0073e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0436, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1306e-01,  9.1201e-01,  9.1153e-01,  9.1130e-01,  9.1112e-01,\n",
      "         9.1099e-01,  9.1094e-01, -2.2579e-06, -2.8536e-06, -3.1568e-06,\n",
      "        -3.6284e-06, -4.5571e-06, -4.9920e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 234\n",
      "Iter 234 - Available Memory: 5308.43 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4676, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3354867.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0079e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0532, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1269e-01,  9.1163e-01,  9.1115e-01,  9.1092e-01,  9.1074e-01,\n",
      "         9.1061e-01,  9.1056e-01, -2.2567e-06, -2.8522e-06, -3.1546e-06,\n",
      "        -3.6261e-06, -4.5542e-06, -4.9904e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 235\n",
      "Iter 235 - Available Memory: 6131.05 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4678, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3355797.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0084e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0628, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1232e-01,  9.1126e-01,  9.1077e-01,  9.1054e-01,  9.1036e-01,\n",
      "         9.1023e-01,  9.1018e-01, -2.2552e-06, -2.8503e-06, -3.1532e-06,\n",
      "        -3.6238e-06, -4.5537e-06, -4.9882e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 235: Normalized Gradient = 0.04994037374854088, Adaptive learning rate = 0.001\n",
      "ite 236\n",
      "Iter 236 - Available Memory: 5506.28 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4679, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3356730.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0090e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0725, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1194e-01,  9.1088e-01,  9.1039e-01,  9.1016e-01,  9.0998e-01,\n",
      "         9.0985e-01,  9.0979e-01, -2.2542e-06, -2.8483e-06, -3.1521e-06,\n",
      "        -3.6231e-06, -4.5516e-06, -4.9868e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 237\n",
      "Iter 237 - Available Memory: 5366.82 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4680, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3357664., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0096e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0821, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1157e-01,  9.1050e-01,  9.1002e-01,  9.0978e-01,  9.0960e-01,\n",
      "         9.0947e-01,  9.0941e-01, -2.2523e-06, -2.8468e-06, -3.1500e-06,\n",
      "        -3.6222e-06, -4.5503e-06, -4.9862e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0190, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 238\n",
      "Iter 238 - Available Memory: 5186.28 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4681, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3358594.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0102e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.0918, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1120e-01,  9.1012e-01,  9.0964e-01,  9.0940e-01,  9.0922e-01,\n",
      "         9.0909e-01,  9.0903e-01, -2.2507e-06, -2.8458e-06, -3.1480e-06,\n",
      "        -3.6201e-06, -4.5482e-06, -4.9838e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 239\n",
      "Iter 239 - Available Memory: 4784.08 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4682, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3359526.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0107e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1014, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1083e-01,  9.0975e-01,  9.0926e-01,  9.0902e-01,  9.0884e-01,\n",
      "         9.0871e-01,  9.0865e-01, -2.2496e-06, -2.8441e-06, -3.1472e-06,\n",
      "        -3.6172e-06, -4.5448e-06, -4.9814e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 240\n",
      "Iter 240 - Available Memory: 4626.16 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4684, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3360463.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0113e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1111, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1046e-01,  9.0937e-01,  9.0888e-01,  9.0865e-01,  9.0846e-01,\n",
      "         9.0833e-01,  9.0827e-01, -2.2476e-06, -2.8414e-06, -3.1442e-06,\n",
      "        -3.6164e-06, -4.5451e-06, -4.9804e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 240: Normalized Gradient = 0.049917083233594894, Adaptive learning rate = 0.001\n",
      "ite 241\n",
      "Iter 241 - Available Memory: 4438.32 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4685, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3361400.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0119e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1208, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.1009e-01,  9.0899e-01,  9.0850e-01,  9.0827e-01,  9.0808e-01,\n",
      "         9.0795e-01,  9.0789e-01, -2.2471e-06, -2.8393e-06, -3.1426e-06,\n",
      "        -3.6127e-06, -4.5428e-06, -4.9812e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 242\n",
      "Iter 242 - Available Memory: 4364.43 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4686, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3362338.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0125e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1305, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0971e-01,  9.0862e-01,  9.0813e-01,  9.0789e-01,  9.0770e-01,\n",
      "         9.0757e-01,  9.0751e-01, -2.2451e-06, -2.8382e-06, -3.1403e-06,\n",
      "        -3.6117e-06, -4.5406e-06, -4.9789e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 243\n",
      "Iter 243 - Available Memory: 4338.67 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4687, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3363278., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0130e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1402, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0934e-01,  9.0824e-01,  9.0775e-01,  9.0751e-01,  9.0732e-01,\n",
      "         9.0719e-01,  9.0713e-01, -2.2433e-06, -2.8359e-06, -3.1390e-06,\n",
      "        -3.6089e-06, -4.5373e-06, -4.9755e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 244\n",
      "Iter 244 - Available Memory: 4219.44 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4688, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3364216.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0136e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1499, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0897e-01,  9.0786e-01,  9.0737e-01,  9.0713e-01,  9.0694e-01,\n",
      "         9.0681e-01,  9.0675e-01, -2.2412e-06, -2.8348e-06, -3.1359e-06,\n",
      "        -3.6088e-06, -4.5366e-06, -4.9742e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 245\n",
      "Iter 245 - Available Memory: 4159.56 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4690, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3365160., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0142e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1596, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0860e-01,  9.0749e-01,  9.0699e-01,  9.0675e-01,  9.0656e-01,\n",
      "         9.0643e-01,  9.0637e-01, -2.2404e-06, -2.8329e-06, -3.1346e-06,\n",
      "        -3.6058e-06, -4.5329e-06, -4.9712e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 245: Normalized Gradient = 0.049894265830516815, Adaptive learning rate = 0.001\n",
      "ite 246\n",
      "Iter 246 - Available Memory: 5054.28 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4691, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3366096.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0148e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1693, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0823e-01,  9.0711e-01,  9.0661e-01,  9.0637e-01,  9.0618e-01,\n",
      "         9.0605e-01,  9.0599e-01, -2.2389e-06, -2.8327e-06, -3.1325e-06,\n",
      "        -3.6049e-06, -4.5328e-06, -4.9739e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 247\n",
      "Iter 247 - Available Memory: 5364.64 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4692, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3367038., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0154e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1791, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0785e-01,  9.0673e-01,  9.0623e-01,  9.0599e-01,  9.0580e-01,\n",
      "         9.0567e-01,  9.0561e-01, -2.2373e-06, -2.8287e-06, -3.1305e-06,\n",
      "        -3.6020e-06, -4.5303e-06, -4.9712e-06])\n",
      "Wins_grad tensor([0.0186, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 248\n",
      "Iter 248 - Available Memory: 5224.16 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4693, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3367983.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0159e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1888, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0748e-01,  9.0636e-01,  9.0586e-01,  9.0562e-01,  9.0542e-01,\n",
      "         9.0529e-01,  9.0523e-01, -2.2361e-06, -2.8274e-06, -3.1305e-06,\n",
      "        -3.6007e-06, -4.5295e-06, -4.9712e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 249\n",
      "Iter 249 - Available Memory: 4810.64 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4695, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3368927., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0165e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.1985, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0711e-01,  9.0598e-01,  9.0548e-01,  9.0524e-01,  9.0504e-01,\n",
      "         9.0491e-01,  9.0485e-01, -2.2347e-06, -2.8266e-06, -3.1285e-06,\n",
      "        -3.5983e-06, -4.5280e-06, -4.9700e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 250\n",
      "Iter 250 - Available Memory: 3543.77 MB\n",
      "Ratio tensor(0.9984, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4696, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3369871.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0171e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2083, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0674e-01,  9.0560e-01,  9.0510e-01,  9.0486e-01,  9.0466e-01,\n",
      "         9.0453e-01,  9.0447e-01, -2.2333e-06, -2.8232e-06, -3.1259e-06,\n",
      "        -3.5957e-06, -4.5260e-06, -4.9671e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 250: Normalized Gradient = 0.04987097159028053, Adaptive learning rate = 0.001\n",
      "ite 251\n",
      "Iter 251 - Available Memory: 2976.12 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4697, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3370819.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0177e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2180, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0637e-01,  9.0523e-01,  9.0472e-01,  9.0448e-01,  9.0428e-01,\n",
      "         9.0415e-01,  9.0409e-01, -2.2321e-06, -2.8227e-06, -3.1237e-06,\n",
      "        -3.5948e-06, -4.5233e-06, -4.9655e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 252\n",
      "Iter 252 - Available Memory: 6491.21 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4698, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3371766., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0183e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2278, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0599e-01,  9.0485e-01,  9.0434e-01,  9.0410e-01,  9.0390e-01,\n",
      "         9.0377e-01,  9.0371e-01, -2.2303e-06, -2.8195e-06, -3.1213e-06,\n",
      "        -3.5908e-06, -4.5194e-06, -4.9627e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 253\n",
      "Iter 253 - Available Memory: 6135.38 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4699, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3372713.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0189e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2376, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0562e-01,  9.0447e-01,  9.0397e-01,  9.0372e-01,  9.0353e-01,\n",
      "         9.0339e-01,  9.0333e-01, -2.2291e-06, -2.8189e-06, -3.1210e-06,\n",
      "        -3.5923e-06, -4.5192e-06, -4.9621e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 254\n",
      "Iter 254 - Available Memory: 4138.53 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4701, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3373660.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0194e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2474, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0525e-01,  9.0410e-01,  9.0359e-01,  9.0334e-01,  9.0315e-01,\n",
      "         9.0301e-01,  9.0295e-01, -2.2273e-06, -2.8176e-06, -3.1178e-06,\n",
      "        -3.5889e-06, -4.5177e-06, -4.9614e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 255\n",
      "Iter 255 - Available Memory: 7160.10 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4702, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3374611.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0200e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2572, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0488e-01,  9.0372e-01,  9.0321e-01,  9.0297e-01,  9.0277e-01,\n",
      "         9.0263e-01,  9.0257e-01, -2.2258e-06, -2.8155e-06, -3.1169e-06,\n",
      "        -3.5890e-06, -4.5159e-06, -4.9607e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 255: Normalized Gradient = 0.049847766757011414, Adaptive learning rate = 0.001\n",
      "ite 256\n",
      "Iter 256 - Available Memory: 6029.25 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4703, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3375562.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0206e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2669, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0451e-01,  9.0334e-01,  9.0283e-01,  9.0259e-01,  9.0239e-01,\n",
      "         9.0225e-01,  9.0219e-01, -2.2246e-06, -2.8141e-06, -3.1149e-06,\n",
      "        -3.5850e-06, -4.5143e-06, -4.9580e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 257\n",
      "Iter 257 - Available Memory: 5792.08 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4704, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3376513., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0212e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2767, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0413e-01,  9.0296e-01,  9.0245e-01,  9.0221e-01,  9.0201e-01,\n",
      "         9.0187e-01,  9.0181e-01, -2.2228e-06, -2.8122e-06, -3.1129e-06,\n",
      "        -3.5835e-06, -4.5121e-06, -4.9578e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 258\n",
      "Iter 258 - Available Memory: 5391.02 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4706, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3377465.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0218e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2866, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0376e-01,  9.0259e-01,  9.0208e-01,  9.0183e-01,  9.0163e-01,\n",
      "         9.0149e-01,  9.0143e-01, -2.2218e-06, -2.8103e-06, -3.1112e-06,\n",
      "        -3.5825e-06, -4.5099e-06, -4.9560e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 259\n",
      "Iter 259 - Available Memory: 5197.68 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4707, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3378421., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0224e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.2964, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0339e-01,  9.0221e-01,  9.0170e-01,  9.0145e-01,  9.0125e-01,\n",
      "         9.0111e-01,  9.0105e-01, -2.2203e-06, -2.8086e-06, -3.1100e-06,\n",
      "        -3.5799e-06, -4.5053e-06, -4.9535e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 260\n",
      "Iter 260 - Available Memory: 5041.48 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4708, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3379375.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0230e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3062, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0302e-01,  9.0183e-01,  9.0132e-01,  9.0107e-01,  9.0087e-01,\n",
      "         9.0073e-01,  9.0067e-01, -2.2189e-06, -2.8070e-06, -3.1071e-06,\n",
      "        -3.5773e-06, -4.5055e-06, -4.9530e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0190, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 260: Normalized Gradient = 0.049824632704257965, Adaptive learning rate = 0.001\n",
      "ite 261\n",
      "Iter 261 - Available Memory: 4915.58 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4709, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3380331.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0236e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3161, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0265e-01,  9.0146e-01,  9.0094e-01,  9.0069e-01,  9.0049e-01,\n",
      "         9.0035e-01,  9.0029e-01, -2.2170e-06, -2.8044e-06, -3.1051e-06,\n",
      "        -3.5753e-06, -4.5051e-06, -4.9525e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 262\n",
      "Iter 262 - Available Memory: 4784.24 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4710, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3381286., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0241e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3259, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0228e-01,  9.0108e-01,  9.0056e-01,  9.0031e-01,  9.0011e-01,\n",
      "         8.9997e-01,  8.9991e-01, -2.2157e-06, -2.8031e-06, -3.1046e-06,\n",
      "        -3.5747e-06, -4.5025e-06, -4.9487e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 263\n",
      "Iter 263 - Available Memory: 4664.51 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4712, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3382245.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0247e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3358, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0190e-01,  9.0070e-01,  9.0019e-01,  8.9994e-01,  8.9973e-01,\n",
      "         8.9959e-01,  8.9953e-01, -2.2146e-06, -2.8017e-06, -3.1013e-06,\n",
      "        -3.5705e-06, -4.4985e-06, -4.9467e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 264\n",
      "Iter 264 - Available Memory: 4882.88 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4713, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3383204.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0253e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3456, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0153e-01,  9.0033e-01,  8.9981e-01,  8.9956e-01,  8.9935e-01,\n",
      "         8.9921e-01,  8.9915e-01, -2.2127e-06, -2.8007e-06, -3.0997e-06,\n",
      "        -3.5690e-06, -4.4976e-06, -4.9473e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 265\n",
      "Iter 265 - Available Memory: 4743.19 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4714, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3384162.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0259e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3555, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0116e-01,  8.9995e-01,  8.9943e-01,  8.9918e-01,  8.9897e-01,\n",
      "         8.9883e-01,  8.9876e-01, -2.2112e-06, -2.7979e-06, -3.0990e-06,\n",
      "        -3.5687e-06, -4.4969e-06, -4.9456e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 265: Normalized Gradient = 0.049801573157310486, Adaptive learning rate = 0.001\n",
      "ite 266\n",
      "Iter 266 - Available Memory: 4630.59 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4715, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3385125.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0265e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3654, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0079e-01,  8.9957e-01,  8.9905e-01,  8.9880e-01,  8.9859e-01,\n",
      "         8.9845e-01,  8.9838e-01, -2.2103e-06, -2.7958e-06, -3.0960e-06,\n",
      "        -3.5650e-06, -4.4957e-06, -4.9439e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 267\n",
      "Iter 267 - Available Memory: 4509.60 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4717, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3386088.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0271e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3753, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0042e-01,  8.9919e-01,  8.9867e-01,  8.9842e-01,  8.9821e-01,\n",
      "         8.9807e-01,  8.9800e-01, -2.2082e-06, -2.7945e-06, -3.0943e-06,\n",
      "        -3.5649e-06, -4.4923e-06, -4.9440e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 268\n",
      "Iter 268 - Available Memory: 4632.73 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4718, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3387054.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0277e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3852, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 9.0004e-01,  8.9882e-01,  8.9830e-01,  8.9804e-01,  8.9783e-01,\n",
      "         8.9769e-01,  8.9762e-01, -2.2069e-06, -2.7938e-06, -3.0942e-06,\n",
      "        -3.5634e-06, -4.4928e-06, -4.9426e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 269\n",
      "Iter 269 - Available Memory: 4545.57 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4719, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3388011.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0283e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.3951, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9967e-01,  8.9844e-01,  8.9792e-01,  8.9766e-01,  8.9745e-01,\n",
      "         8.9731e-01,  8.9724e-01, -2.2054e-06, -2.7910e-06, -3.0904e-06,\n",
      "        -3.5602e-06, -4.4883e-06, -4.9390e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 270\n",
      "Iter 270 - Available Memory: 5635.43 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4720, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3388982.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0289e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4050, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9930e-01,  8.9806e-01,  8.9754e-01,  8.9728e-01,  8.9707e-01,\n",
      "         8.9693e-01,  8.9686e-01, -2.2042e-06, -2.7895e-06, -3.0886e-06,\n",
      "        -3.5592e-06, -4.4865e-06, -4.9368e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 270: Normalized Gradient = 0.04977881535887718, Adaptive learning rate = 0.001\n",
      "ite 271\n",
      "Iter 271 - Available Memory: 5244.19 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4722, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3389943.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0295e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4149, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9893e-01,  8.9769e-01,  8.9716e-01,  8.9691e-01,  8.9669e-01,\n",
      "         8.9655e-01,  8.9648e-01, -2.2028e-06, -2.7869e-06, -3.0874e-06,\n",
      "        -3.5560e-06, -4.4861e-06, -4.9378e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 272\n",
      "Iter 272 - Available Memory: 4962.06 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4723, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3390912., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0301e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4249, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9856e-01,  8.9731e-01,  8.9678e-01,  8.9653e-01,  8.9631e-01,\n",
      "         8.9617e-01,  8.9610e-01, -2.2007e-06, -2.7852e-06, -3.0845e-06,\n",
      "        -3.5538e-06, -4.4819e-06, -4.9347e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 273\n",
      "Iter 273 - Available Memory: 4242.23 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4724, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3391880.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0307e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4348, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9818e-01,  8.9693e-01,  8.9641e-01,  8.9615e-01,  8.9593e-01,\n",
      "         8.9579e-01,  8.9572e-01, -2.1995e-06, -2.7842e-06, -3.0848e-06,\n",
      "        -3.5531e-06, -4.4821e-06, -4.9333e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 274\n",
      "Iter 274 - Available Memory: 4330.64 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4725, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3392850.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0313e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4448, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9781e-01,  8.9656e-01,  8.9603e-01,  8.9577e-01,  8.9556e-01,\n",
      "         8.9541e-01,  8.9534e-01, -2.1985e-06, -2.7818e-06, -3.0821e-06,\n",
      "        -3.5519e-06, -4.4804e-06, -4.9345e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 275\n",
      "Iter 275 - Available Memory: 3948.79 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4727, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3393819., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0319e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4547, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9744e-01,  8.9618e-01,  8.9565e-01,  8.9539e-01,  8.9518e-01,\n",
      "         8.9503e-01,  8.9496e-01, -2.1962e-06, -2.7801e-06, -3.0790e-06,\n",
      "        -3.5474e-06, -4.4778e-06, -4.9297e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 275: Normalized Gradient = 0.04975566267967224, Adaptive learning rate = 0.001\n",
      "ite 276\n",
      "Iter 276 - Available Memory: 3765.25 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4728, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3394787., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0325e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4647, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9707e-01,  8.9580e-01,  8.9527e-01,  8.9501e-01,  8.9480e-01,\n",
      "         8.9465e-01,  8.9458e-01, -2.1946e-06, -2.7782e-06, -3.0777e-06,\n",
      "        -3.5472e-06, -4.4766e-06, -4.9292e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 277\n",
      "Iter 277 - Available Memory: 6886.93 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4729, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3395763.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0331e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4747, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9670e-01,  8.9542e-01,  8.9489e-01,  8.9463e-01,  8.9442e-01,\n",
      "         8.9427e-01,  8.9420e-01, -2.1936e-06, -2.7766e-06, -3.0765e-06,\n",
      "        -3.5444e-06, -4.4740e-06, -4.9278e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 278\n",
      "Iter 278 - Available Memory: 6302.96 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4730, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3396734.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0337e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4846, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9632e-01,  8.9505e-01,  8.9452e-01,  8.9426e-01,  8.9404e-01,\n",
      "         8.9389e-01,  8.9382e-01, -2.1922e-06, -2.7747e-06, -3.0751e-06,\n",
      "        -3.5437e-06, -4.4729e-06, -4.9269e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 279\n",
      "Iter 279 - Available Memory: 6045.15 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4732, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3397710.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0343e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.4946, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9595e-01,  8.9467e-01,  8.9414e-01,  8.9388e-01,  8.9366e-01,\n",
      "         8.9351e-01,  8.9344e-01, -2.1910e-06, -2.7731e-06, -3.0723e-06,\n",
      "        -3.5405e-06, -4.4709e-06, -4.9242e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 280\n",
      "Iter 280 - Available Memory: 5557.59 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4733, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3398683., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0349e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5046, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9558e-01,  8.9429e-01,  8.9376e-01,  8.9350e-01,  8.9328e-01,\n",
      "         8.9313e-01,  8.9306e-01, -2.1893e-06, -2.7716e-06, -3.0718e-06,\n",
      "        -3.5396e-06, -4.4704e-06, -4.9244e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 280: Normalized Gradient = 0.04973271116614342, Adaptive learning rate = 0.001\n",
      "ite 281\n",
      "Iter 281 - Available Memory: 6061.60 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4734, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3399660.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0355e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5147, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9521e-01,  8.9392e-01,  8.9338e-01,  8.9312e-01,  8.9290e-01,\n",
      "         8.9275e-01,  8.9268e-01, -2.1880e-06, -2.7689e-06, -3.0687e-06,\n",
      "        -3.5383e-06, -4.4662e-06, -4.9238e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 282\n",
      "Iter 282 - Available Memory: 5744.79 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4735, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3400635.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0361e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5247, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9484e-01,  8.9354e-01,  8.9300e-01,  8.9274e-01,  8.9252e-01,\n",
      "         8.9237e-01,  8.9230e-01, -2.1868e-06, -2.7691e-06, -3.0672e-06,\n",
      "        -3.5363e-06, -4.4638e-06, -4.9210e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 283\n",
      "Iter 283 - Available Memory: 5305.76 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4737, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3401614., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0367e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5347, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9446e-01,  8.9316e-01,  8.9262e-01,  8.9236e-01,  8.9214e-01,\n",
      "         8.9199e-01,  8.9192e-01, -2.1854e-06, -2.7661e-06, -3.0649e-06,\n",
      "        -3.5347e-06, -4.4629e-06, -4.9202e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 284\n",
      "Iter 284 - Available Memory: 5026.87 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4738, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3402591.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0374e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5447, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9409e-01,  8.9278e-01,  8.9225e-01,  8.9198e-01,  8.9176e-01,\n",
      "         8.9161e-01,  8.9154e-01, -2.1837e-06, -2.7650e-06, -3.0624e-06,\n",
      "        -3.5324e-06, -4.4606e-06, -4.9184e-06])\n",
      "Wins_grad tensor([0.0185, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 285\n",
      "Iter 285 - Available Memory: 4668.38 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4739, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3403572., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0380e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5548, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9372e-01,  8.9241e-01,  8.9187e-01,  8.9160e-01,  8.9138e-01,\n",
      "         8.9123e-01,  8.9116e-01, -2.1817e-06, -2.7630e-06, -3.0620e-06,\n",
      "        -3.5320e-06, -4.4604e-06, -4.9164e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 285: Normalized Gradient = 0.04970965534448624, Adaptive learning rate = 0.001\n",
      "ite 286\n",
      "Iter 286 - Available Memory: 4378.87 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4740, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3404552., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0386e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5648, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9335e-01,  8.9203e-01,  8.9149e-01,  8.9123e-01,  8.9100e-01,\n",
      "         8.9085e-01,  8.9078e-01, -2.1805e-06, -2.7613e-06, -3.0598e-06,\n",
      "        -3.5284e-06, -4.4581e-06, -4.9159e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 287\n",
      "Iter 287 - Available Memory: 4119.19 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4742, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3405536., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0392e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5749, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9298e-01,  8.9165e-01,  8.9111e-01,  8.9085e-01,  8.9062e-01,\n",
      "         8.9047e-01,  8.9040e-01, -2.1790e-06, -2.7599e-06, -3.0580e-06,\n",
      "        -3.5262e-06, -4.4539e-06, -4.9139e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 288\n",
      "Iter 288 - Available Memory: 3776.49 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4743, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3406523.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0398e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5849, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9261e-01,  8.9127e-01,  8.9073e-01,  8.9047e-01,  8.9024e-01,\n",
      "         8.9009e-01,  8.9002e-01, -2.1772e-06, -2.7568e-06, -3.0561e-06,\n",
      "        -3.5255e-06, -4.4530e-06, -4.9150e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 289\n",
      "Iter 289 - Available Memory: 3536.50 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4744, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3407502.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0404e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.5950, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9223e-01,  8.9090e-01,  8.9036e-01,  8.9009e-01,  8.8986e-01,\n",
      "         8.8971e-01,  8.8964e-01, -2.1760e-06, -2.7557e-06, -3.0539e-06,\n",
      "        -3.5238e-06, -4.4517e-06, -4.9132e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 290\n",
      "Iter 290 - Available Memory: 3402.34 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4745, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3408485.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0410e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6051, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9186e-01,  8.9052e-01,  8.8998e-01,  8.8971e-01,  8.8948e-01,\n",
      "         8.8933e-01,  8.8926e-01, -2.1750e-06, -2.7546e-06, -3.0520e-06,\n",
      "        -3.5211e-06, -4.4497e-06, -4.9091e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 290: Normalized Gradient = 0.04968660697340965, Adaptive learning rate = 0.001\n",
      "ite 291\n",
      "Iter 291 - Available Memory: 3455.82 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4747, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3409474.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0416e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6152, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9149e-01,  8.9014e-01,  8.8960e-01,  8.8933e-01,  8.8910e-01,\n",
      "         8.8895e-01,  8.8888e-01, -2.1732e-06, -2.7523e-06, -3.0509e-06,\n",
      "        -3.5196e-06, -4.4483e-06, -4.9081e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0189, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 292\n",
      "Iter 292 - Available Memory: 3293.30 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4748, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3410462.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0423e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6253, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9112e-01,  8.8977e-01,  8.8922e-01,  8.8895e-01,  8.8872e-01,\n",
      "         8.8857e-01,  8.8850e-01, -2.1718e-06, -2.7513e-06, -3.0493e-06,\n",
      "        -3.5183e-06, -4.4474e-06, -4.9099e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 293\n",
      "Iter 293 - Available Memory: 3014.80 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4749, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3411451., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0429e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6354, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9075e-01,  8.8939e-01,  8.8884e-01,  8.8858e-01,  8.8835e-01,\n",
      "         8.8819e-01,  8.8812e-01, -2.1703e-06, -2.7493e-06, -3.0477e-06,\n",
      "        -3.5163e-06, -4.4449e-06, -4.9066e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 294\n",
      "Iter 294 - Available Memory: 2825.31 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4751, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3412438., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0435e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6455, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9037e-01,  8.8901e-01,  8.8847e-01,  8.8820e-01,  8.8797e-01,\n",
      "         8.8781e-01,  8.8774e-01, -2.1685e-06, -2.7463e-06, -3.0448e-06,\n",
      "        -3.5117e-06, -4.4425e-06, -4.9036e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 295\n",
      "Iter 295 - Available Memory: 2509.16 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4752, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3413429.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0441e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6557, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.9000e-01,  8.8863e-01,  8.8809e-01,  8.8782e-01,  8.8759e-01,\n",
      "         8.8743e-01,  8.8736e-01, -2.1675e-06, -2.7451e-06, -3.0424e-06,\n",
      "        -3.5125e-06, -4.4430e-06, -4.9044e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 295: Normalized Gradient = 0.04966387897729874, Adaptive learning rate = 0.001\n",
      "ite 296\n",
      "Iter 296 - Available Memory: 2420.09 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4753, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3414421.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0447e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6658, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8963e-01,  8.8826e-01,  8.8771e-01,  8.8744e-01,  8.8721e-01,\n",
      "         8.8705e-01,  8.8698e-01, -2.1660e-06, -2.7435e-06, -3.0419e-06,\n",
      "        -3.5107e-06, -4.4394e-06, -4.9013e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 297\n",
      "Iter 297 - Available Memory: 6939.14 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4754, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3415413.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0453e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6759, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8926e-01,  8.8788e-01,  8.8733e-01,  8.8706e-01,  8.8683e-01,\n",
      "         8.8667e-01,  8.8660e-01, -2.1646e-06, -2.7415e-06, -3.0385e-06,\n",
      "        -3.5084e-06, -4.4368e-06, -4.9000e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 298\n",
      "Iter 298 - Available Memory: 6581.80 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4756, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3416406., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0460e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6861, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8889e-01,  8.8750e-01,  8.8695e-01,  8.8668e-01,  8.8645e-01,\n",
      "         8.8629e-01,  8.8622e-01, -2.1633e-06, -2.7390e-06, -3.0366e-06,\n",
      "        -3.5045e-06, -4.4354e-06, -4.8985e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 299\n",
      "Iter 299 - Available Memory: 6100.61 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4757, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3417399.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0466e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.6963, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8851e-01,  8.8712e-01,  8.8658e-01,  8.8630e-01,  8.8607e-01,\n",
      "         8.8591e-01,  8.8584e-01, -2.1615e-06, -2.7373e-06, -3.0363e-06,\n",
      "        -3.5041e-06, -4.4335e-06, -4.8975e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 300\n",
      "Iter 300 - Available Memory: 5643.29 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4758, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3418395.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0472e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7064, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8814e-01,  8.8675e-01,  8.8620e-01,  8.8593e-01,  8.8569e-01,\n",
      "         8.8553e-01,  8.8546e-01, -2.1602e-06, -2.7360e-06, -3.0335e-06,\n",
      "        -3.5013e-06, -4.4308e-06, -4.8962e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 300: Normalized Gradient = 0.04964090883731842, Adaptive learning rate = 0.001\n",
      "ite 301\n",
      "Iter 301 - Available Memory: 5105.84 MB\n",
      "Ratio tensor(0.9985, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4760, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3419391.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0478e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7166, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8777e-01,  8.8637e-01,  8.8582e-01,  8.8555e-01,  8.8531e-01,\n",
      "         8.8515e-01,  8.8507e-01, -2.1583e-06, -2.7344e-06, -3.0319e-06,\n",
      "        -3.5015e-06, -4.4297e-06, -4.8952e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 302\n",
      "Iter 302 - Available Memory: 4807.09 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4761, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3420392.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0484e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7268, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8740e-01,  8.8599e-01,  8.8544e-01,  8.8517e-01,  8.8493e-01,\n",
      "         8.8477e-01,  8.8469e-01, -2.1570e-06, -2.7313e-06, -3.0295e-06,\n",
      "        -3.4992e-06, -4.4296e-06, -4.8944e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 303\n",
      "Iter 303 - Available Memory: 7084.83 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4762, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3421387., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0491e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7370, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8703e-01,  8.8561e-01,  8.8506e-01,  8.8479e-01,  8.8455e-01,\n",
      "         8.8439e-01,  8.8431e-01, -2.1555e-06, -2.7307e-06, -3.0295e-06,\n",
      "        -3.4954e-06, -4.4243e-06, -4.8914e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 304\n",
      "Iter 304 - Available Memory: 6557.50 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4763, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3422386.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0497e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7472, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8665e-01,  8.8524e-01,  8.8469e-01,  8.8441e-01,  8.8417e-01,\n",
      "         8.8401e-01,  8.8393e-01, -2.1540e-06, -2.7294e-06, -3.0273e-06,\n",
      "        -3.4945e-06, -4.4245e-06, -4.8902e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "ite 305\n",
      "Iter 305 - Available Memory: 6329.02 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4765, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3423387., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0503e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7574, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8628e-01,  8.8486e-01,  8.8431e-01,  8.8403e-01,  8.8379e-01,\n",
      "         8.8363e-01,  8.8355e-01, -2.1523e-06, -2.7275e-06, -3.0237e-06,\n",
      "        -3.4933e-06, -4.4224e-06, -4.8893e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0002, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 305: Normalized Gradient = 0.04961801692843437, Adaptive learning rate = 0.001\n",
      "ite 306\n",
      "Iter 306 - Available Memory: 5983.85 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4766, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3424390.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0509e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7676, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8591e-01,  8.8448e-01,  8.8393e-01,  8.8365e-01,  8.8341e-01,\n",
      "         8.8325e-01,  8.8317e-01, -2.1510e-06, -2.7259e-06, -3.0225e-06,\n",
      "        -3.4924e-06, -4.4210e-06, -4.8877e-06])\n",
      "Wins_grad tensor([0.0185, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 307\n",
      "Iter 307 - Available Memory: 5225.05 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4767, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3425390.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0516e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7779, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8554e-01,  8.8410e-01,  8.8355e-01,  8.8328e-01,  8.8303e-01,\n",
      "         8.8287e-01,  8.8279e-01, -2.1498e-06, -2.7237e-06, -3.0208e-06,\n",
      "        -3.4893e-06, -4.4174e-06, -4.8852e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 308\n",
      "Iter 308 - Available Memory: 5072.19 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4769, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3426398., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0522e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7881, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8517e-01,  8.8373e-01,  8.8317e-01,  8.8290e-01,  8.8265e-01,\n",
      "         8.8249e-01,  8.8241e-01, -2.1481e-06, -2.7213e-06, -3.0188e-06,\n",
      "        -3.4865e-06, -4.4144e-06, -4.8858e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 309\n",
      "Iter 309 - Available Memory: 4878.11 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4770, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3427402.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0528e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.7984, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8479e-01,  8.8335e-01,  8.8280e-01,  8.8252e-01,  8.8227e-01,\n",
      "         8.8211e-01,  8.8203e-01, -2.1466e-06, -2.7200e-06, -3.0191e-06,\n",
      "        -3.4863e-06, -4.4165e-06, -4.8848e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 310\n",
      "Iter 310 - Available Memory: 4787.51 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4771, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3428410.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0535e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8086, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8442e-01,  8.8297e-01,  8.8242e-01,  8.8214e-01,  8.8190e-01,\n",
      "         8.8173e-01,  8.8165e-01, -2.1455e-06, -2.7187e-06, -3.0148e-06,\n",
      "        -3.4825e-06, -4.4127e-06, -4.8830e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 310: Normalized Gradient = 0.0495954230427742, Adaptive learning rate = 0.001\n",
      "ite 311\n",
      "Iter 311 - Available Memory: 4667.95 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4773, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3429415., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0541e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8189, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8405e-01,  8.8260e-01,  8.8204e-01,  8.8176e-01,  8.8152e-01,\n",
      "         8.8135e-01,  8.8127e-01, -2.1443e-06, -2.7169e-06, -3.0144e-06,\n",
      "        -3.4806e-06, -4.4102e-06, -4.8817e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 312\n",
      "Iter 312 - Available Memory: 4483.41 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4774, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3430426.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0547e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8292, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8368e-01,  8.8222e-01,  8.8166e-01,  8.8138e-01,  8.8114e-01,\n",
      "         8.8097e-01,  8.8089e-01, -2.1431e-06, -2.7155e-06, -3.0123e-06,\n",
      "        -3.4806e-06, -4.4102e-06, -4.8798e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 313\n",
      "Iter 313 - Available Memory: 4379.87 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4775, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3431433.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0553e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8395, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8331e-01,  8.8184e-01,  8.8128e-01,  8.8100e-01,  8.8076e-01,\n",
      "         8.8059e-01,  8.8051e-01, -2.1411e-06, -2.7138e-06, -3.0104e-06,\n",
      "        -3.4781e-06, -4.4076e-06, -4.8780e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 314\n",
      "Iter 314 - Available Memory: 4156.34 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4776, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3432443., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0560e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8498, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8293e-01,  8.8146e-01,  8.8091e-01,  8.8063e-01,  8.8038e-01,\n",
      "         8.8021e-01,  8.8013e-01, -2.1394e-06, -2.7113e-06, -3.0077e-06,\n",
      "        -3.4763e-06, -4.4047e-06, -4.8772e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0189, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 315\n",
      "Iter 315 - Available Memory: 3961.29 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4778, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3433453., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0566e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8601, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8256e-01,  8.8109e-01,  8.8053e-01,  8.8025e-01,  8.8000e-01,\n",
      "         8.7983e-01,  8.7975e-01, -2.1374e-06, -2.7098e-06, -3.0071e-06,\n",
      "        -3.4757e-06, -4.4033e-06, -4.8754e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 315: Normalized Gradient = 0.049572475254535675, Adaptive learning rate = 0.001\n",
      "ite 316\n",
      "Iter 316 - Available Memory: 3926.32 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4779, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3434468., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0572e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8704, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8219e-01,  8.8071e-01,  8.8015e-01,  8.7987e-01,  8.7962e-01,\n",
      "         8.7945e-01,  8.7937e-01, -2.1364e-06, -2.7068e-06, -3.0034e-06,\n",
      "        -3.4729e-06, -4.4008e-06, -4.8741e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 317\n",
      "Iter 317 - Available Memory: 3817.23 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4780, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3435480., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0579e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8807, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8182e-01,  8.8033e-01,  8.7977e-01,  8.7949e-01,  8.7924e-01,\n",
      "         8.7907e-01,  8.7899e-01, -2.1354e-06, -2.7060e-06, -3.0020e-06,\n",
      "        -3.4712e-06, -4.4013e-06, -4.8734e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 318\n",
      "Iter 318 - Available Memory: 3809.49 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4782, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3436494.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0585e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.8910, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8145e-01,  8.7995e-01,  8.7939e-01,  8.7911e-01,  8.7886e-01,\n",
      "         8.7869e-01,  8.7861e-01, -2.1335e-06, -2.7045e-06, -3.0001e-06,\n",
      "        -3.4679e-06, -4.3969e-06, -4.8713e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 319\n",
      "Iter 319 - Available Memory: 3838.95 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4783, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3437510., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0592e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9014, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8108e-01,  8.7957e-01,  8.7902e-01,  8.7873e-01,  8.7848e-01,\n",
      "         8.7831e-01,  8.7823e-01, -2.1317e-06, -2.7031e-06, -2.9985e-06,\n",
      "        -3.4667e-06, -4.3972e-06, -4.8714e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 320\n",
      "Iter 320 - Available Memory: 3745.54 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4784, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3438530., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0598e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9117, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8070e-01,  8.7920e-01,  8.7864e-01,  8.7835e-01,  8.7810e-01,\n",
      "         8.7793e-01,  8.7785e-01, -2.1306e-06, -2.7014e-06, -2.9972e-06,\n",
      "        -3.4654e-06, -4.3942e-06, -4.8680e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 320: Normalized Gradient = 0.049550071358680725, Adaptive learning rate = 0.001\n",
      "ite 321\n",
      "Iter 321 - Available Memory: 6174.84 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4786, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3439545., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0604e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9221, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.8033e-01,  8.7882e-01,  8.7826e-01,  8.7798e-01,  8.7772e-01,\n",
      "         8.7755e-01,  8.7747e-01, -2.1288e-06, -2.6980e-06, -2.9932e-06,\n",
      "        -3.4621e-06, -4.3935e-06, -4.8684e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 322\n",
      "Iter 322 - Available Memory: 6466.68 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4787, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3440562., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0611e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9324, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7996e-01,  8.7844e-01,  8.7788e-01,  8.7760e-01,  8.7734e-01,\n",
      "         8.7717e-01,  8.7709e-01, -2.1280e-06, -2.6979e-06, -2.9932e-06,\n",
      "        -3.4619e-06, -4.3931e-06, -4.8657e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 323\n",
      "Iter 323 - Available Memory: 6001.36 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4788, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3441584.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0617e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9428, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7959e-01,  8.7806e-01,  8.7750e-01,  8.7722e-01,  8.7696e-01,\n",
      "         8.7679e-01,  8.7671e-01, -2.1264e-06, -2.6962e-06, -2.9921e-06,\n",
      "        -3.4595e-06, -4.3895e-06, -4.8642e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 324\n",
      "Iter 324 - Available Memory: 5746.77 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4790, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3442604.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0623e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9532, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7922e-01,  8.7769e-01,  8.7713e-01,  8.7684e-01,  8.7658e-01,\n",
      "         8.7641e-01,  8.7633e-01, -2.1245e-06, -2.6929e-06, -2.9902e-06,\n",
      "        -3.4569e-06, -4.3872e-06, -4.8648e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 325\n",
      "Iter 325 - Available Memory: 5529.31 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4791, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3443629., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0630e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9636, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7884e-01,  8.7731e-01,  8.7675e-01,  8.7646e-01,  8.7620e-01,\n",
      "         8.7603e-01,  8.7595e-01, -2.1233e-06, -2.6930e-06, -2.9878e-06,\n",
      "        -3.4555e-06, -4.3859e-06, -4.8620e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 325: Normalized Gradient = 0.049527253955602646, Adaptive learning rate = 0.001\n",
      "ite 326\n",
      "Iter 326 - Available Memory: 5259.57 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4792, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3444652.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0636e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9740, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7847e-01,  8.7693e-01,  8.7637e-01,  8.7608e-01,  8.7582e-01,\n",
      "         8.7565e-01,  8.7557e-01, -2.1215e-06, -2.6901e-06, -2.9846e-06,\n",
      "        -3.4524e-06, -4.3837e-06, -4.8604e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 327\n",
      "Iter 327 - Available Memory: 6661.34 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4794, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3445671.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0643e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9844, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7810e-01,  8.7655e-01,  8.7599e-01,  8.7570e-01,  8.7545e-01,\n",
      "         8.7527e-01,  8.7519e-01, -2.1203e-06, -2.6882e-06, -2.9840e-06,\n",
      "        -3.4531e-06, -4.3820e-06, -4.8591e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 328\n",
      "Iter 328 - Available Memory: 6038.23 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4795, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3446701., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0649e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(23.9948, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7773e-01,  8.7618e-01,  8.7561e-01,  8.7533e-01,  8.7507e-01,\n",
      "         8.7489e-01,  8.7481e-01, -2.1189e-06, -2.6866e-06, -2.9817e-06,\n",
      "        -3.4488e-06, -4.3799e-06, -4.8595e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 329\n",
      "Iter 329 - Available Memory: 5654.19 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4796, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3447724.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0656e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0052, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7736e-01,  8.7580e-01,  8.7524e-01,  8.7495e-01,  8.7469e-01,\n",
      "         8.7451e-01,  8.7443e-01, -2.1176e-06, -2.6841e-06, -2.9792e-06,\n",
      "        -3.4477e-06, -4.3777e-06, -4.8571e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 330\n",
      "Iter 330 - Available Memory: 5471.21 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4798, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3448749., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0662e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0157, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7698e-01,  8.7542e-01,  8.7486e-01,  8.7457e-01,  8.7431e-01,\n",
      "         8.7413e-01,  8.7405e-01, -2.1160e-06, -2.6834e-06, -2.9793e-06,\n",
      "        -3.4472e-06, -4.3757e-06, -4.8571e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 330: Normalized Gradient = 0.04950424283742905, Adaptive learning rate = 0.001\n",
      "ite 331\n",
      "Iter 331 - Available Memory: 5192.65 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4799, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3449781.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0669e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0261, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7661e-01,  8.7504e-01,  8.7448e-01,  8.7419e-01,  8.7393e-01,\n",
      "         8.7375e-01,  8.7367e-01, -2.1144e-06, -2.6816e-06, -2.9768e-06,\n",
      "        -3.4450e-06, -4.3747e-06, -4.8539e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 332\n",
      "Iter 332 - Available Memory: 4866.38 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4800, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3450809.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0675e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0366, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7624e-01,  8.7466e-01,  8.7410e-01,  8.7381e-01,  8.7355e-01,\n",
      "         8.7337e-01,  8.7329e-01, -2.1127e-06, -2.6794e-06, -2.9744e-06,\n",
      "        -3.4422e-06, -4.3727e-06, -4.8540e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 333\n",
      "Iter 333 - Available Memory: 4676.35 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4802, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3451841., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0682e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0471, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7587e-01,  8.7429e-01,  8.7372e-01,  8.7343e-01,  8.7317e-01,\n",
      "         8.7299e-01,  8.7291e-01, -2.1112e-06, -2.6787e-06, -2.9737e-06,\n",
      "        -3.4418e-06, -4.3708e-06, -4.8523e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 334\n",
      "Iter 334 - Available Memory: 4238.06 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4803, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3452873.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0688e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0575, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7550e-01,  8.7391e-01,  8.7335e-01,  8.7306e-01,  8.7279e-01,\n",
      "         8.7261e-01,  8.7253e-01, -2.1100e-06, -2.6757e-06, -2.9719e-06,\n",
      "        -3.4386e-06, -4.3701e-06, -4.8527e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 335\n",
      "Iter 335 - Available Memory: 3956.56 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4804, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3453906.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0695e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0680, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7512e-01,  8.7353e-01,  8.7297e-01,  8.7268e-01,  8.7241e-01,\n",
      "         8.7223e-01,  8.7215e-01, -2.1087e-06, -2.6746e-06, -2.9693e-06,\n",
      "        -3.4382e-06, -4.3682e-06, -4.8496e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 335: Normalized Gradient = 0.04948180541396141, Adaptive learning rate = 0.001\n",
      "ite 336\n",
      "Iter 336 - Available Memory: 3824.31 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4806, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3454938., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0701e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0785, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7475e-01,  8.7315e-01,  8.7259e-01,  8.7230e-01,  8.7203e-01,\n",
      "         8.7185e-01,  8.7177e-01, -2.1066e-06, -2.6723e-06, -2.9673e-06,\n",
      "        -3.4370e-06, -4.3659e-06, -4.8479e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 337\n",
      "Iter 337 - Available Memory: 3973.93 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4807, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3455974.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0708e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0890, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7438e-01,  8.7278e-01,  8.7221e-01,  8.7192e-01,  8.7165e-01,\n",
      "         8.7147e-01,  8.7139e-01, -2.1060e-06, -2.6719e-06, -2.9667e-06,\n",
      "        -3.4340e-06, -4.3653e-06, -4.8457e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 338\n",
      "Iter 338 - Available Memory: 3795.11 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4808, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3457006., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0714e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.0995, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7401e-01,  8.7240e-01,  8.7183e-01,  8.7154e-01,  8.7127e-01,\n",
      "         8.7109e-01,  8.7101e-01, -2.1041e-06, -2.6688e-06, -2.9644e-06,\n",
      "        -3.4330e-06, -4.3635e-06, -4.8464e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 339\n",
      "Iter 339 - Available Memory: 3657.50 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4810, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3458046.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0721e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1100, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7364e-01,  8.7202e-01,  8.7146e-01,  8.7116e-01,  8.7089e-01,\n",
      "         8.7071e-01,  8.7063e-01, -2.1029e-06, -2.6670e-06, -2.9608e-06,\n",
      "        -3.4299e-06, -4.3598e-06, -4.8444e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 340\n",
      "Iter 340 - Available Memory: 3186.41 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4811, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3459087., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0727e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1206, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7327e-01,  8.7164e-01,  8.7108e-01,  8.7079e-01,  8.7051e-01,\n",
      "         8.7033e-01,  8.7025e-01, -2.1017e-06, -2.6655e-06, -2.9605e-06,\n",
      "        -3.4278e-06, -4.3589e-06, -4.8428e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 340: Normalized Gradient = 0.049459174275398254, Adaptive learning rate = 0.001\n",
      "ite 341\n",
      "Iter 341 - Available Memory: 3025.15 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4812, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3460125.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0734e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1311, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7289e-01,  8.7126e-01,  8.7070e-01,  8.7041e-01,  8.7013e-01,\n",
      "         8.6995e-01,  8.6987e-01, -2.0998e-06, -2.6638e-06, -2.9576e-06,\n",
      "        -3.4280e-06, -4.3576e-06, -4.8430e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 342\n",
      "Iter 342 - Available Memory: 3380.16 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4814, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3461165.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0740e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1416, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7252e-01,  8.7089e-01,  8.7032e-01,  8.7003e-01,  8.6976e-01,\n",
      "         8.6957e-01,  8.6949e-01, -2.0977e-06, -2.6618e-06, -2.9556e-06,\n",
      "        -3.4242e-06, -4.3548e-06, -4.8414e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 343\n",
      "Iter 343 - Available Memory: 3272.74 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4815, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3462205.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0747e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1522, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7215e-01,  8.7051e-01,  8.6994e-01,  8.6965e-01,  8.6938e-01,\n",
      "         8.6919e-01,  8.6911e-01, -2.0972e-06, -2.6609e-06, -2.9551e-06,\n",
      "        -3.4232e-06, -4.3529e-06, -4.8388e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 344\n",
      "Iter 344 - Available Memory: 3234.37 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4816, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3463249.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0753e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1628, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7178e-01,  8.7013e-01,  8.6957e-01,  8.6927e-01,  8.6900e-01,\n",
      "         8.6881e-01,  8.6873e-01, -2.0957e-06, -2.6584e-06, -2.9530e-06,\n",
      "        -3.4208e-06, -4.3520e-06, -4.8365e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 345\n",
      "Iter 345 - Available Memory: 3291.96 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4818, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3464293.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0760e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1733, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7141e-01,  8.6975e-01,  8.6919e-01,  8.6889e-01,  8.6862e-01,\n",
      "         8.6843e-01,  8.6835e-01, -2.0938e-06, -2.6569e-06, -2.9512e-06,\n",
      "        -3.4193e-06, -4.3493e-06, -4.8350e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 345: Normalized Gradient = 0.049436476081609726, Adaptive learning rate = 0.001\n",
      "ite 346\n",
      "Iter 346 - Available Memory: 3236.16 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4819, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3465339.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0767e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1839, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7103e-01,  8.6937e-01,  8.6881e-01,  8.6851e-01,  8.6824e-01,\n",
      "         8.6805e-01,  8.6797e-01, -2.0928e-06, -2.6561e-06, -2.9494e-06,\n",
      "        -3.4158e-06, -4.3473e-06, -4.8338e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 347\n",
      "Iter 347 - Available Memory: 3207.93 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4820, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3466385.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0773e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.1945, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7066e-01,  8.6900e-01,  8.6843e-01,  8.6814e-01,  8.6786e-01,\n",
      "         8.6767e-01,  8.6759e-01, -2.0908e-06, -2.6529e-06, -2.9481e-06,\n",
      "        -3.4150e-06, -4.3464e-06, -4.8344e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 348\n",
      "Iter 348 - Available Memory: 3184.36 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4822, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3467429., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0780e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2051, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.7029e-01,  8.6862e-01,  8.6805e-01,  8.6776e-01,  8.6748e-01,\n",
      "         8.6729e-01,  8.6721e-01, -2.0892e-06, -2.6507e-06, -2.9467e-06,\n",
      "        -3.4144e-06, -4.3446e-06, -4.8324e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 349\n",
      "Iter 349 - Available Memory: 3176.89 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4823, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3468478.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0786e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2157, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6992e-01,  8.6824e-01,  8.6768e-01,  8.6738e-01,  8.6710e-01,\n",
      "         8.6691e-01,  8.6683e-01, -2.0881e-06, -2.6496e-06, -2.9437e-06,\n",
      "        -3.4113e-06, -4.3434e-06, -4.8313e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 350\n",
      "Iter 350 - Available Memory: 7372.45 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4825, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3469527.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0793e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2263, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6955e-01,  8.6786e-01,  8.6730e-01,  8.6700e-01,  8.6672e-01,\n",
      "         8.6653e-01,  8.6645e-01, -2.0861e-06, -2.6474e-06, -2.9409e-06,\n",
      "        -3.4093e-06, -4.3411e-06, -4.8292e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 350: Normalized Gradient = 0.04941384121775627, Adaptive learning rate = 0.001\n",
      "ite 351\n",
      "Iter 351 - Available Memory: 7194.99 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4826, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3470577.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0800e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2370, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6917e-01,  8.6748e-01,  8.6692e-01,  8.6662e-01,  8.6634e-01,\n",
      "         8.6615e-01,  8.6607e-01, -2.0852e-06, -2.6464e-06, -2.9393e-06,\n",
      "        -3.4071e-06, -4.3396e-06, -4.8298e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 352\n",
      "Iter 352 - Available Memory: 6930.18 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4827, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3471632., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0806e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2476, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6880e-01,  8.6711e-01,  8.6654e-01,  8.6624e-01,  8.6596e-01,\n",
      "         8.6577e-01,  8.6568e-01, -2.0835e-06, -2.6445e-06, -2.9383e-06,\n",
      "        -3.4063e-06, -4.3387e-06, -4.8282e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 353\n",
      "Iter 353 - Available Memory: 6274.55 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4829, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3472682., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0813e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2582, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6843e-01,  8.6673e-01,  8.6617e-01,  8.6587e-01,  8.6558e-01,\n",
      "         8.6539e-01,  8.6530e-01, -2.0824e-06, -2.6429e-06, -2.9368e-06,\n",
      "        -3.4039e-06, -4.3358e-06, -4.8261e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 354\n",
      "Iter 354 - Available Memory: 5137.16 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4830, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3473737., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0820e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2689, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6806e-01,  8.6635e-01,  8.6579e-01,  8.6549e-01,  8.6520e-01,\n",
      "         8.6501e-01,  8.6492e-01, -2.0807e-06, -2.6408e-06, -2.9332e-06,\n",
      "        -3.4031e-06, -4.3330e-06, -4.8247e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 355\n",
      "Iter 355 - Available Memory: 4107.76 MB\n",
      "Ratio tensor(0.9986, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4831, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3474790.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0826e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2796, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6769e-01,  8.6597e-01,  8.6541e-01,  8.6511e-01,  8.6482e-01,\n",
      "         8.6463e-01,  8.6454e-01, -2.0789e-06, -2.6389e-06, -2.9324e-06,\n",
      "        -3.4004e-06, -4.3325e-06, -4.8243e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 355: Normalized Gradient = 0.049391187727451324, Adaptive learning rate = 0.001\n",
      "ite 356\n",
      "Iter 356 - Available Memory: 6769.71 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4833, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3475847., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0833e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.2902, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6731e-01,  8.6559e-01,  8.6503e-01,  8.6473e-01,  8.6444e-01,\n",
      "         8.6425e-01,  8.6416e-01, -2.0776e-06, -2.6387e-06, -2.9312e-06,\n",
      "        -3.3994e-06, -4.3316e-06, -4.8230e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 357\n",
      "Iter 357 - Available Memory: 6331.74 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4834, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3476906., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0840e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3009, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6694e-01,  8.6522e-01,  8.6465e-01,  8.6435e-01,  8.6407e-01,\n",
      "         8.6387e-01,  8.6378e-01, -2.0765e-06, -2.6360e-06, -2.9292e-06,\n",
      "        -3.3980e-06, -4.3305e-06, -4.8234e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 358\n",
      "Iter 358 - Available Memory: 4766.67 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4836, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3477963.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0846e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3117, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6657e-01,  8.6484e-01,  8.6428e-01,  8.6397e-01,  8.6369e-01,\n",
      "         8.6349e-01,  8.6340e-01, -2.0749e-06, -2.6345e-06, -2.9274e-06,\n",
      "        -3.3959e-06, -4.3259e-06, -4.8192e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 359\n",
      "Iter 359 - Available Memory: 5245.20 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4837, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3479020.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0853e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3223, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6620e-01,  8.6446e-01,  8.6390e-01,  8.6360e-01,  8.6331e-01,\n",
      "         8.6311e-01,  8.6302e-01, -2.0734e-06, -2.6319e-06, -2.9259e-06,\n",
      "        -3.3942e-06, -4.3261e-06, -4.8175e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 360\n",
      "Iter 360 - Available Memory: 3973.02 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4838, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3480083.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0860e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3330, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6583e-01,  8.6408e-01,  8.6352e-01,  8.6322e-01,  8.6293e-01,\n",
      "         8.6273e-01,  8.6264e-01, -2.0712e-06, -2.6306e-06, -2.9233e-06,\n",
      "        -3.3915e-06, -4.3238e-06, -4.8181e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 360: Normalized Gradient = 0.04936879873275757, Adaptive learning rate = 0.001\n",
      "ite 361\n",
      "Iter 361 - Available Memory: 5445.71 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4840, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3481144.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0867e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3438, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6546e-01,  8.6370e-01,  8.6314e-01,  8.6284e-01,  8.6255e-01,\n",
      "         8.6235e-01,  8.6226e-01, -2.0700e-06, -2.6282e-06, -2.9219e-06,\n",
      "        -3.3887e-06, -4.3235e-06, -4.8177e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 362\n",
      "Iter 362 - Available Memory: 5807.95 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4841, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3482205.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0873e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3545, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6508e-01,  8.6333e-01,  8.6276e-01,  8.6246e-01,  8.6217e-01,\n",
      "         8.6197e-01,  8.6188e-01, -2.0686e-06, -2.6269e-06, -2.9195e-06,\n",
      "        -3.3875e-06, -4.3212e-06, -4.8164e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 363\n",
      "Iter 363 - Available Memory: 5123.87 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4842, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3483269., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0880e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3652, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6471e-01,  8.6295e-01,  8.6239e-01,  8.6208e-01,  8.6179e-01,\n",
      "         8.6159e-01,  8.6150e-01, -2.0672e-06, -2.6245e-06, -2.9179e-06,\n",
      "        -3.3858e-06, -4.3180e-06, -4.8131e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0187, 0.0187, 0.0187, 0.0187, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 364\n",
      "Iter 364 - Available Memory: 3995.28 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4844, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3484338.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0887e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3760, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6434e-01,  8.6257e-01,  8.6201e-01,  8.6170e-01,  8.6141e-01,\n",
      "         8.6121e-01,  8.6112e-01, -2.0659e-06, -2.6233e-06, -2.9166e-06,\n",
      "        -3.3839e-06, -4.3179e-06, -4.8134e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 365\n",
      "Iter 365 - Available Memory: 6271.91 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4845, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3485403.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0894e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3868, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6397e-01,  8.6219e-01,  8.6163e-01,  8.6133e-01,  8.6103e-01,\n",
      "         8.6084e-01,  8.6074e-01, -2.0641e-06, -2.6206e-06, -2.9137e-06,\n",
      "        -3.3822e-06, -4.3145e-06, -4.8128e-06])\n",
      "Wins_grad tensor([0.0184, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 365: Normalized Gradient = 0.04934638738632202, Adaptive learning rate = 0.001\n",
      "ite 366\n",
      "Iter 366 - Available Memory: 5773.95 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4847, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3486467.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0900e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.3975, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6360e-01,  8.6181e-01,  8.6125e-01,  8.6095e-01,  8.6065e-01,\n",
      "         8.6046e-01,  8.6036e-01, -2.0627e-06, -2.6200e-06, -2.9142e-06,\n",
      "        -3.3818e-06, -4.3130e-06, -4.8114e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 367\n",
      "Iter 367 - Available Memory: 5345.91 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4848, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3487537.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0907e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4083, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6322e-01,  8.6143e-01,  8.6087e-01,  8.6057e-01,  8.6027e-01,\n",
      "         8.6008e-01,  8.5998e-01, -2.0610e-06, -2.6180e-06, -2.9103e-06,\n",
      "        -3.3787e-06, -4.3117e-06, -4.8079e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 368\n",
      "Iter 368 - Available Memory: 5024.70 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4849, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3488605.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0914e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4191, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6285e-01,  8.6106e-01,  8.6050e-01,  8.6019e-01,  8.5989e-01,\n",
      "         8.5970e-01,  8.5960e-01, -2.0599e-06, -2.6153e-06, -2.9075e-06,\n",
      "        -3.3780e-06, -4.3105e-06, -4.8072e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0188, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 369\n",
      "Iter 369 - Available Memory: 6327.23 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4851, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3489676.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0921e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4299, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6248e-01,  8.6068e-01,  8.6012e-01,  8.5981e-01,  8.5951e-01,\n",
      "         8.5932e-01,  8.5922e-01, -2.0588e-06, -2.6141e-06, -2.9072e-06,\n",
      "        -3.3758e-06, -4.3077e-06, -4.8063e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 370\n",
      "Iter 370 - Available Memory: 6008.51 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4852, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3490751.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0927e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4407, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6211e-01,  8.6030e-01,  8.5974e-01,  8.5943e-01,  8.5913e-01,\n",
      "         8.5894e-01,  8.5884e-01, -2.0570e-06, -2.6128e-06, -2.9044e-06,\n",
      "        -3.3732e-06, -4.3071e-06, -4.8058e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 370: Normalized Gradient = 0.04932372272014618, Adaptive learning rate = 0.001\n",
      "ite 371\n",
      "Iter 371 - Available Memory: 5632.36 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4854, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3491821.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0934e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4515, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6174e-01,  8.5992e-01,  8.5936e-01,  8.5906e-01,  8.5876e-01,\n",
      "         8.5856e-01,  8.5846e-01, -2.0548e-06, -2.6109e-06, -2.9025e-06,\n",
      "        -3.3717e-06, -4.3050e-06, -4.8044e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 372\n",
      "Iter 372 - Available Memory: 5429.45 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4855, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3492895.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0941e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4623, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6137e-01,  8.5954e-01,  8.5898e-01,  8.5868e-01,  8.5838e-01,\n",
      "         8.5818e-01,  8.5808e-01, -2.0539e-06, -2.6094e-06, -2.9010e-06,\n",
      "        -3.3703e-06, -4.3018e-06, -4.8031e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 373\n",
      "Iter 373 - Available Memory: 5295.74 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4856, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3493971.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0948e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4732, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6099e-01,  8.5916e-01,  8.5861e-01,  8.5830e-01,  8.5800e-01,\n",
      "         8.5780e-01,  8.5770e-01, -2.0527e-06, -2.6076e-06, -2.8979e-06,\n",
      "        -3.3684e-06, -4.3018e-06, -4.8019e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 374\n",
      "Iter 374 - Available Memory: 5229.93 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4858, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3495046.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0955e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4840, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6062e-01,  8.5879e-01,  8.5823e-01,  8.5792e-01,  8.5762e-01,\n",
      "         8.5742e-01,  8.5732e-01, -2.0512e-06, -2.6055e-06, -2.8972e-06,\n",
      "        -3.3661e-06, -4.2999e-06, -4.7997e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 375\n",
      "Iter 375 - Available Memory: 5054.38 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4859, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3496123.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0962e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.4949, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.6025e-01,  8.5841e-01,  8.5785e-01,  8.5754e-01,  8.5724e-01,\n",
      "         8.5704e-01,  8.5694e-01, -2.0493e-06, -2.6036e-06, -2.8955e-06,\n",
      "        -3.3661e-06, -4.2985e-06, -4.7977e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0187, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 375: Normalized Gradient = 0.04930107668042183, Adaptive learning rate = 0.001\n",
      "ite 376\n",
      "Iter 376 - Available Memory: 4940.57 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4861, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3497205.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0968e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5057, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5988e-01,  8.5803e-01,  8.5747e-01,  8.5716e-01,  8.5686e-01,\n",
      "         8.5666e-01,  8.5656e-01, -2.0483e-06, -2.6018e-06, -2.8936e-06,\n",
      "        -3.3638e-06, -4.2958e-06, -4.7982e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 377\n",
      "Iter 377 - Available Memory: 4387.84 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4862, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3498282.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0975e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5166, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5951e-01,  8.5765e-01,  8.5710e-01,  8.5679e-01,  8.5648e-01,\n",
      "         8.5628e-01,  8.5618e-01, -2.0470e-06, -2.6001e-06, -2.8930e-06,\n",
      "        -3.3609e-06, -4.2941e-06, -4.7953e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 378\n",
      "Iter 378 - Available Memory: 4396.95 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4863, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3499367.7500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0982e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5275, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5913e-01,  8.5727e-01,  8.5672e-01,  8.5641e-01,  8.5610e-01,\n",
      "         8.5590e-01,  8.5580e-01, -2.0454e-06, -2.5982e-06, -2.8899e-06,\n",
      "        -3.3579e-06, -4.2920e-06, -4.7962e-06])\n",
      "Wins_grad tensor([0.0183, 0.0187, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 379\n",
      "Iter 379 - Available Memory: 4224.89 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4865, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3500445.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0989e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5384, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5876e-01,  8.5689e-01,  8.5634e-01,  8.5603e-01,  8.5572e-01,\n",
      "         8.5552e-01,  8.5542e-01, -2.0441e-06, -2.5972e-06, -2.8879e-06,\n",
      "        -3.3573e-06, -4.2919e-06, -4.7948e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 380\n",
      "Iter 380 - Available Memory: 4085.77 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4866, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3501529., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.0996e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5493, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5839e-01,  8.5652e-01,  8.5596e-01,  8.5565e-01,  8.5534e-01,\n",
      "         8.5514e-01,  8.5504e-01, -2.0420e-06, -2.5953e-06, -2.8859e-06,\n",
      "        -3.3555e-06, -4.2893e-06, -4.7949e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 380: Normalized Gradient = 0.049278732389211655, Adaptive learning rate = 0.001\n",
      "ite 381\n",
      "Iter 381 - Available Memory: 6695.73 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4868, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3502616.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1003e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5602, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5802e-01,  8.5614e-01,  8.5558e-01,  8.5527e-01,  8.5496e-01,\n",
      "         8.5476e-01,  8.5466e-01, -2.0407e-06, -2.5929e-06, -2.8850e-06,\n",
      "        -3.3543e-06, -4.2861e-06, -4.7918e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 382\n",
      "Iter 382 - Available Memory: 6240.21 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4869, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3503699.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1010e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5711, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5765e-01,  8.5576e-01,  8.5521e-01,  8.5489e-01,  8.5458e-01,\n",
      "         8.5438e-01,  8.5428e-01, -2.0396e-06, -2.5918e-06, -2.8835e-06,\n",
      "        -3.3520e-06, -4.2870e-06, -4.7919e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 383\n",
      "Iter 383 - Available Memory: 5953.04 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4870, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3504783.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1017e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5821, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5728e-01,  8.5538e-01,  8.5483e-01,  8.5452e-01,  8.5420e-01,\n",
      "         8.5400e-01,  8.5390e-01, -2.0375e-06, -2.5897e-06, -2.8808e-06,\n",
      "        -3.3501e-06, -4.2846e-06, -4.7895e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 384\n",
      "Iter 384 - Available Memory: 5689.02 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4872, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3505874.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1024e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.5930, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5690e-01,  8.5500e-01,  8.5445e-01,  8.5414e-01,  8.5383e-01,\n",
      "         8.5362e-01,  8.5352e-01, -2.0356e-06, -2.5879e-06, -2.8797e-06,\n",
      "        -3.3500e-06, -4.2829e-06, -4.7882e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 385\n",
      "Iter 385 - Available Memory: 5463.08 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4873, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3506964.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1031e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6039, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5653e-01,  8.5462e-01,  8.5407e-01,  8.5376e-01,  8.5345e-01,\n",
      "         8.5324e-01,  8.5314e-01, -2.0351e-06, -2.5864e-06, -2.8773e-06,\n",
      "        -3.3463e-06, -4.2811e-06, -4.7864e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "Iteration 385: Normalized Gradient = 0.049256373196840286, Adaptive learning rate = 0.001\n",
      "ite 386\n",
      "Iter 386 - Available Memory: 6170.71 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4875, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3508055.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1038e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6149, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5616e-01,  8.5424e-01,  8.5369e-01,  8.5338e-01,  8.5307e-01,\n",
      "         8.5286e-01,  8.5276e-01, -2.0326e-06, -2.5837e-06, -2.8738e-06,\n",
      "        -3.3441e-06, -4.2782e-06, -4.7857e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 387\n",
      "Iter 387 - Available Memory: 5841.23 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4876, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3509146.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1045e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6259, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5579e-01,  8.5387e-01,  8.5332e-01,  8.5300e-01,  8.5269e-01,\n",
      "         8.5248e-01,  8.5238e-01, -2.0323e-06, -2.5836e-06, -2.8731e-06,\n",
      "        -3.3419e-06, -4.2775e-06, -4.7852e-06])\n",
      "Wins_grad tensor([0.0183, 0.0186, 0.0186, 0.0186, 0.0187, 0.0187, 0.0187, 0.0001, 0.0001,\n",
      "        0.0001, 0.0002, 0.0002, 0.0002])\n",
      "ite 388\n",
      "Iter 388 - Available Memory: 5408.50 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4878, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3510239.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1051e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6369, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5542e-01,  8.5349e-01,  8.5294e-01,  8.5262e-01,  8.5231e-01,\n",
      "         8.5210e-01,  8.5200e-01, -2.0299e-06, -2.5803e-06, -2.8708e-06,\n",
      "        -3.3418e-06, -4.2742e-06, -4.7844e-06])\n",
      "Wins_grad tensor([1.8304e-02, 1.8646e-02, 1.8607e-02, 1.8626e-02, 1.8675e-02, 1.8702e-02,\n",
      "        1.8717e-02, 9.9959e-05, 1.2706e-04, 1.4137e-04, 1.6456e-04, 2.1047e-04,\n",
      "        2.3560e-04])\n",
      "ite 389\n",
      "Iter 389 - Available Memory: 5192.22 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4879, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3511332., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1058e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6479, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5504e-01,  8.5311e-01,  8.5256e-01,  8.5225e-01,  8.5193e-01,\n",
      "         8.5172e-01,  8.5162e-01, -2.0291e-06, -2.5801e-06, -2.8706e-06,\n",
      "        -3.3410e-06, -4.2747e-06, -4.7837e-06])\n",
      "Wins_grad tensor([1.8305e-02, 1.8645e-02, 1.8603e-02, 1.8625e-02, 1.8672e-02, 1.8699e-02,\n",
      "        1.8716e-02, 9.9912e-05, 1.2704e-04, 1.4135e-04, 1.6451e-04, 2.1048e-04,\n",
      "        2.3554e-04])\n",
      "ite 390\n",
      "Iter 390 - Available Memory: 4738.31 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4880, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3512431.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1065e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6589, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5467e-01,  8.5273e-01,  8.5218e-01,  8.5187e-01,  8.5155e-01,\n",
      "         8.5134e-01,  8.5124e-01, -2.0277e-06, -2.5770e-06, -2.8682e-06,\n",
      "        -3.3376e-06, -4.2735e-06, -4.7825e-06])\n",
      "Wins_grad tensor([1.8302e-02, 1.8645e-02, 1.8603e-02, 1.8622e-02, 1.8669e-02, 1.8700e-02,\n",
      "        1.8713e-02, 9.9833e-05, 1.2688e-04, 1.4121e-04, 1.6432e-04, 2.1040e-04,\n",
      "        2.3546e-04])\n",
      "Iteration 390: Normalized Gradient = 0.04923439398407936, Adaptive learning rate = 0.001\n",
      "ite 391\n",
      "Iter 391 - Available Memory: 4961.12 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4882, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3513522.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1072e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6699, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5430e-01,  8.5235e-01,  8.5181e-01,  8.5149e-01,  8.5117e-01,\n",
      "         8.5096e-01,  8.5086e-01, -2.0258e-06, -2.5755e-06, -2.8667e-06,\n",
      "        -3.3370e-06, -4.2711e-06, -4.7798e-06])\n",
      "Wins_grad tensor([1.8301e-02, 1.8645e-02, 1.8598e-02, 1.8621e-02, 1.8669e-02, 1.8698e-02,\n",
      "        1.8710e-02, 9.9727e-05, 1.2679e-04, 1.4113e-04, 1.6428e-04, 2.1027e-04,\n",
      "        2.3531e-04])\n",
      "ite 392\n",
      "Iter 392 - Available Memory: 4033.51 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4883, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3514619.2500, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1079e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6809, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5393e-01,  8.5197e-01,  8.5143e-01,  8.5111e-01,  8.5079e-01,\n",
      "         8.5058e-01,  8.5048e-01, -2.0244e-06, -2.5745e-06, -2.8652e-06,\n",
      "        -3.3341e-06, -4.2691e-06, -4.7804e-06])\n",
      "Wins_grad tensor([1.8300e-02, 1.8640e-02, 1.8600e-02, 1.8618e-02, 1.8666e-02, 1.8695e-02,\n",
      "        1.8710e-02, 9.9651e-05, 1.2673e-04, 1.4104e-04, 1.6412e-04, 2.1015e-04,\n",
      "        2.3532e-04])\n",
      "ite 393\n",
      "Iter 393 - Available Memory: 7485.39 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4885, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3515719., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1086e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.6919, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5356e-01,  8.5159e-01,  8.5105e-01,  8.5073e-01,  8.5041e-01,\n",
      "         8.5020e-01,  8.5010e-01, -2.0231e-06, -2.5712e-06, -2.8630e-06,\n",
      "        -3.3336e-06, -4.2677e-06, -4.7798e-06])\n",
      "Wins_grad tensor([1.8298e-02, 1.8639e-02, 1.8598e-02, 1.8617e-02, 1.8666e-02, 1.8693e-02,\n",
      "        1.8707e-02, 9.9580e-05, 1.2655e-04, 1.4092e-04, 1.6408e-04, 2.1006e-04,\n",
      "        2.3526e-04])\n",
      "ite 394\n",
      "Iter 394 - Available Memory: 7312.72 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4886, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3516820.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1094e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7030, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5319e-01,  8.5122e-01,  8.5067e-01,  8.5036e-01,  8.5003e-01,\n",
      "         8.4982e-01,  8.4972e-01, -2.0214e-06, -2.5704e-06, -2.8605e-06,\n",
      "        -3.3305e-06, -4.2665e-06, -4.7766e-06])\n",
      "Wins_grad tensor([1.8297e-02, 1.8638e-02, 1.8595e-02, 1.8616e-02, 1.8664e-02, 1.8692e-02,\n",
      "        1.8704e-02, 9.9486e-05, 1.2651e-04, 1.4078e-04, 1.6391e-04, 2.0998e-04,\n",
      "        2.3509e-04])\n",
      "ite 395\n",
      "Iter 395 - Available Memory: 6967.40 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4888, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3517922., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1101e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7140, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5281e-01,  8.5084e-01,  8.5029e-01,  8.4998e-01,  8.4965e-01,\n",
      "         8.4944e-01,  8.4934e-01, -2.0197e-06, -2.5682e-06, -2.8588e-06,\n",
      "        -3.3296e-06, -4.2657e-06, -4.7774e-06])\n",
      "Wins_grad tensor([1.8295e-02, 1.8637e-02, 1.8593e-02, 1.8611e-02, 1.8664e-02, 1.8691e-02,\n",
      "        1.8702e-02, 9.9391e-05, 1.2639e-04, 1.4068e-04, 1.6386e-04, 2.0992e-04,\n",
      "        2.3510e-04])\n",
      "Iteration 395: Normalized Gradient = 0.04921184480190277, Adaptive learning rate = 0.001\n",
      "ite 396\n",
      "Iter 396 - Available Memory: 6722.48 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4889, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3519020.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1108e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7251, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5244e-01,  8.5046e-01,  8.4992e-01,  8.4960e-01,  8.4927e-01,\n",
      "         8.4906e-01,  8.4896e-01, -2.0182e-06, -2.5665e-06, -2.8575e-06,\n",
      "        -3.3274e-06, -4.2633e-06, -4.7746e-06])\n",
      "Wins_grad tensor([1.8292e-02, 1.8637e-02, 1.8592e-02, 1.8611e-02, 1.8660e-02, 1.8690e-02,\n",
      "        1.8701e-02, 9.9311e-05, 1.2629e-04, 1.4061e-04, 1.6373e-04, 2.0978e-04,\n",
      "        2.3495e-04])\n",
      "ite 397\n",
      "Iter 397 - Available Memory: 6268.39 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4890, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3520124.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1115e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7361, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5207e-01,  8.5008e-01,  8.4954e-01,  8.4922e-01,  8.4890e-01,\n",
      "         8.4868e-01,  8.4858e-01, -2.0168e-06, -2.5642e-06, -2.8569e-06,\n",
      "        -3.3274e-06, -4.2629e-06, -4.7747e-06])\n",
      "Wins_grad tensor([1.8289e-02, 1.8638e-02, 1.8590e-02, 1.8610e-02, 1.8659e-02, 1.8687e-02,\n",
      "        1.8699e-02, 9.9231e-05, 1.2617e-04, 1.4057e-04, 1.6372e-04, 2.0974e-04,\n",
      "        2.3493e-04])\n",
      "ite 398\n",
      "Iter 398 - Available Memory: 6038.06 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4892, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3521230., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1122e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7472, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5170e-01,  8.4970e-01,  8.4916e-01,  8.4884e-01,  8.4852e-01,\n",
      "         8.4830e-01,  8.4820e-01, -2.0155e-06, -2.5632e-06, -2.8537e-06,\n",
      "        -3.3250e-06, -4.2611e-06, -4.7738e-06])\n",
      "Wins_grad tensor([1.8288e-02, 1.8637e-02, 1.8588e-02, 1.8608e-02, 1.8656e-02, 1.8683e-02,\n",
      "        1.8699e-02, 9.9157e-05, 1.2610e-04, 1.4040e-04, 1.6358e-04, 2.0964e-04,\n",
      "        2.3486e-04])\n",
      "ite 399\n",
      "Iter 399 - Available Memory: 5698.75 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4893, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3522336.5000, grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1129e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7583, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5133e-01,  8.4932e-01,  8.4878e-01,  8.4846e-01,  8.4814e-01,\n",
      "         8.4792e-01,  8.4782e-01, -2.0138e-06, -2.5608e-06, -2.8514e-06,\n",
      "        -3.3235e-06, -4.2589e-06, -4.7717e-06])\n",
      "Wins_grad tensor([1.8286e-02, 1.8636e-02, 1.8585e-02, 1.8605e-02, 1.8656e-02, 1.8683e-02,\n",
      "        1.8696e-02, 9.9067e-05, 1.2598e-04, 1.4027e-04, 1.6349e-04, 2.0951e-04,\n",
      "        2.3474e-04])\n",
      "ite 400\n",
      "Iter 400 - Available Memory: 5861.37 MB\n",
      "Ratio tensor(0.9987, grad_fn=<DivBackward0>)\n",
      "Estrain: tensor(0.4895, grad_fn=<SumBackward0>)\n",
      "load_path tensor(3523442., grad_fn=<DotBackward0>)\n",
      "R: tensor(1.1136e-06, grad_fn=<VarBackward0>)\n",
      "ite height: tensor(24.7694, grad_fn=<UnbindBackward0>)\n",
      "Wins_q tensor([ 8.5096e-01,  8.4894e-01,  8.4841e-01,  8.4809e-01,  8.4776e-01,\n",
      "         8.4754e-01,  8.4744e-01, -2.0126e-06, -2.5595e-06, -2.8514e-06,\n",
      "        -3.3219e-06, -4.2580e-06, -4.7715e-06])\n",
      "Wins_grad tensor([1.8285e-02, 1.8637e-02, 1.8581e-02, 1.8604e-02, 1.8651e-02, 1.8684e-02,\n",
      "        1.8693e-02, 9.8998e-05, 1.2590e-04, 1.4026e-04, 1.6340e-04, 2.0945e-04,\n",
      "        2.3471e-04])\n",
      "Saved full states to results/FDM_States_6.png\n",
      "Iteration 400: Normalized Gradient = 0.04918934777379036, Adaptive learning rate = 0.001\n",
      "Optimization completed.\n",
      "tensor([0.8510, 0.8489, 0.8484, 0.8481, 0.8478, 0.8475, 0.8474, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000], requires_grad=True)\n",
      "Estrain: tensor(0.4895, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "############## Optimization loop\n",
    "\n",
    "#### Initializing Data storage\n",
    "os.makedirs(\"data_records\", exist_ok=True)\n",
    "optimization_data = {\n",
    "    \"metadata\": {\n",
    "        \"project\": \"Structural Optimization\",\n",
    "        \"Context\": \"FDM + FE\",\n",
    "        \"device\": str(device),\n",
    "        \"parameters\": {\n",
    "            \"length\": length,\n",
    "            \"width\": width,\n",
    "            \"grid_size\": f\"{n1}x{n2}\",\n",
    "            \"epochs\": epochs,\n",
    "            \"step_size\": step\n",
    "        }\n",
    "    },\n",
    "    \"iterations\": []\n",
    "}\n",
    "\n",
    "####### Loop start\n",
    "n_elem = len(connectivity)\n",
    "q = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], requires_grad=True, device=device)\n",
    "start_time = time.time()\n",
    "cut = epochs / 5\n",
    "ES_his = []\n",
    "LP_his = []\n",
    "LS_his = []\n",
    "R_his = []\n",
    "Ratio = []\n",
    "\n",
    "# Loop start\n",
    "for iteration in range(epochs + 1):\n",
    "    print('ite', iteration)\n",
    "    \n",
    "    iter_start = time.time() \n",
    "    \n",
    "    avail_mem = check_available_memory()\n",
    "    print(f\"Iter {iteration} - Available Memory: {avail_mem:.2f} MB\")\n",
    "    if avail_mem < 1000: \n",
    "        print(f\"⚠️  Low memory warning: {avail_mem:.2f} MB left!\")\n",
    "    \n",
    "    # Forwards\n",
    "    q_vec = torch.zeros(n_elements, requires_grad=True, device=device).clone()\n",
    "    for i in range(len(idx_X)):\n",
    "        q_vec[idx_X[i,:]] = q[i] \n",
    "    for j in range(len(idx_Y)):\n",
    "        q_vec[idx_Y[j,:]] = q[j+len(idx_X)]  \n",
    "    q_vec = q_vec * 1 / r\n",
    "    Q = torch.diag(q_vec) \n",
    "    new_node_coords = FDM(Q, F_value)\n",
    "    height = max(new_node_coords[:,2])\n",
    "    \n",
    "    \n",
    "    ####### FDM time\n",
    "    FDM_time = (time.time() - iter_start) / 60\n",
    "        \n",
    "    N_coords = new_node_coords.clone()\n",
    "    FE_str = time.time()\n",
    "    Strain_energy, forces, displacements, ASE, Beam_lens, R, V = Strain_E(N_coords, connectivity, fixed_dof, F_fe)\n",
    "    \n",
    "    ######## FE time\n",
    "    FE_time = (time.time() - FE_str) / 60       \n",
    "    force = abs(forces[:, 0, 0])\n",
    "    load_path = torch.dot(force , Beam_lens)\n",
    "\n",
    "\n",
    "    Total_ES = torch.sum(Strain_energy) \n",
    "    Axial_rate = torch.sum(ASE) / Total_ES\n",
    "\n",
    "    Volume = torch.sum(V)\n",
    "    Loss = torch.dot(abs(q_vec * Beam_lens), Beam_lens)\n",
    "\n",
    "    \n",
    "    # Loss_his.append(loss.item())\n",
    "    R_his.append(R.clone().detach().item())\n",
    "    LP_his.append(load_path.item()) \n",
    "    ES_his.append(Total_ES.item())\n",
    "    Ratio.append(torch.sum(ASE) / Total_ES) \n",
    "    LS_his.append(Loss.clone().detach().item())\n",
    "    \n",
    "    print('Ratio', torch.sum(ASE) / Total_ES)\n",
    "    print(\"Estrain:\", Total_ES)\n",
    "    print('load_path', load_path)\n",
    "    print(\"R:\", R)\n",
    "    print('ite height:', height)\n",
    "\n",
    "    ############################ Deformation\n",
    "    N_coords = N_coords.reshape(-1)\n",
    "    New_Coordinates = torch.zeros(n_nodes * 3, dtype=torch.float32, device=device)\n",
    "    for n in range(n_nodes):\n",
    "        New_Coordinates[3*n : 3*n+3] = N_coords[3*n : 3*n+3] + displacements[6*n : 6*n+3]\n",
    "    New_Coordinates = New_Coordinates.view(n_nodes, 3).clone()\n",
    "        \n",
    "    # Backwards\n",
    "    \n",
    "    Back_str = time.time()\n",
    "    if q.grad is not None:\n",
    "        q.grad.detach_()\n",
    "        q.grad.zero_()\n",
    "       \n",
    "    Total_ES.backward(retain_graph=True)\n",
    "    Back_time = (time.time() - Back_str) / 60\n",
    "    \n",
    "    # Grad\n",
    "    gradients = q.grad\n",
    "    frob_norm = torch.norm(gradients)\n",
    "    q = optimizer(q, gradients, step)\n",
    "    \n",
    "    Wins_q = q.cpu().clone().detach()\n",
    "    print('Wins_q', Wins_q)    \n",
    "    print('Wins_grad', gradients) \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        q[:5].clamp_(min=0.8, max=1.0)\n",
    "        q[5:].clamp_(min=0.0, max=2.0)\n",
    "\n",
    "    ####### Data storage:\n",
    "    iteration_record = {\n",
    "    \"iteration\": iteration,\n",
    "    \"variables\": q.detach().cpu().numpy().tolist(),\n",
    "    \"strain_energy\": Total_ES.item(),\n",
    "    \"Load_path\": load_path.item(),\n",
    "    \"Axial SE ratio\": Axial_rate.item(),\n",
    "    \"Volume\": Volume.item(),\n",
    "    \"R\": R.item(),\n",
    "    \"gradient_norm\": torch.norm(gradients).item() if q.grad is not None else 0.0,\n",
    "               \"timing\": {\n",
    "            \"FDM_time\": FDM_time,\n",
    "            \"FE_time\": FE_time,\n",
    "            \"Back_propagation time\": Back_time,\n",
    "        },\n",
    "    }  \n",
    "    optimization_data[\"iterations\"].append(iteration_record)\n",
    "\n",
    "    if iteration % cut == 0 or iteration == 0:\n",
    "        state_idx = iteration // cut  \n",
    "        save_fdm(state_idx, grid_points, new_node_coords, \n",
    "                connectivity, Free_nodes, Fixed_nodes, \n",
    "                force, Total_ES.detach().cpu().item())\n",
    "    \n",
    "    # print iteration\n",
    "    if iteration % 5 == 0:\n",
    "        print(f\"Iteration {iteration}: Normalized Gradient = {frob_norm}, Adaptive learning rate = {step}\")\n",
    "\n",
    "    if iteration % 10 == 0:\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        gc.collect()\n",
    "            \n",
    "    ######## Early stopping\n",
    "    if iteration > 0:  \n",
    "        Pre_Total_ES = ES_his[iteration - 1]  \n",
    "        change = abs(Total_ES - Pre_Total_ES) / Pre_Total_ES \n",
    "        if change < 1/10000:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0 \n",
    "        if count >= patience:\n",
    "            print(f\"Early stopping at iteration {iteration}: Total_ES change < 1%% for {patience} consecutive iterations.\")\n",
    "            break \n",
    "            \n",
    "\n",
    "finalize_fdm()\n",
    "total_time = (time.time() - iter_start) / 60\n",
    "optimization_data[\"metadata\"].update({\n",
    "    \"Ite_time\": total_time,\n",
    "})\n",
    "\n",
    "with open(os.path.join(\"data_records\", \"FULL_data.json\"), 'w') as f:\n",
    "    json.dump(optimization_data, f, indent=2)\n",
    "    \n",
    "print(\"Optimization completed.\")\n",
    "print(q)\n",
    "print(\"Estrain:\", Total_ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ddfddc03-2f29-429b-8f09-73f481c74fee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ite 0\n",
      "18.25650930404663\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0002e+00,\n",
      "        1.0001e+00, 0.0000e+00, 2.0343e-04, 0.0000e+00, 0.0000e+00, 1.2593e-04,\n",
      "        2.1312e-04])\n",
      "Wins_grad tensor([-0.0477, -0.0432, -0.0551, -0.0373, -0.0373, -0.0253, -0.0119,  0.0596,\n",
      "        -0.0313,  0.0745,  0.0373, -0.0194, -0.0328])\n",
      "Strain_energy tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "ite 1\n",
      "17.94102716445923\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0005e+00,\n",
      "        1.0004e+00, 9.2854e-05, 1.9183e-04, 1.0446e-04, 1.1607e-05, 2.6522e-04,\n",
      "        4.5686e-04])\n",
      "Wins_grad tensor([-0.0447, -0.0477, -0.0283, -0.0715, -0.0283, -0.0432, -0.0447, -0.0119,\n",
      "         0.0015, -0.0134, -0.0015, -0.0179, -0.0313])\n",
      "Strain_energy tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "ite 2\n",
      "62.07524800300598\n",
      "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0006e+00,\n",
      "        1.0006e+00, 2.0913e-04, 4.2438e-04, 1.4599e-04, 2.6077e-04, 8.0507e-04,\n",
      "        2.9075e-04])\n",
      "Wins_grad tensor([-0.0462, -0.0402, -0.0417, -0.0626, -0.0834, -0.0119, -0.0343, -0.0209,\n",
      "        -0.0417, -0.0075, -0.0447, -0.0969,  0.0298])\n",
      "Strain_energy tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "ite 3\n",
      "14.50350832939148\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0010e+00,\n",
      "        1.0008e+00, 1.0451e-04, 5.2900e-04, 1.1610e-04, 4.2517e-04, 6.4067e-04,\n",
      "        3.5054e-04])\n",
      "Wins_grad tensor([-0.0402, -0.0313, -0.0417, -0.0417, -0.0343, -0.0402, -0.0164,  0.0104,\n",
      "        -0.0104,  0.0030, -0.0164,  0.0164, -0.0060])\n",
      "Strain_energy tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "ite 4\n",
      "17.8754620552063\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0012e+00,\n",
      "        1.0008e+00, 0.0000e+00, 7.5614e-04, 4.8670e-04, 2.4585e-04, 4.8526e-04,\n",
      "        5.4181e-04])\n",
      "Wins_grad tensor([-0.0313, -0.0149, -0.0402, -0.0522, -0.0417, -0.0224,  0.0000,  0.0581,\n",
      "        -0.0283, -0.0462,  0.0224,  0.0194, -0.0238])\n",
      "Strain_energy tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "ite 5\n",
      "18.75036382675171\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0016e+00,\n",
      "        1.0013e+00, 0.0000e+00, 6.5956e-04, 5.1429e-04, 8.0277e-05, 3.7488e-04,\n",
      "        4.7283e-04])\n",
      "Wins_grad tensor([-0.0209, -0.0387, -0.0373, -0.0402, -0.0060, -0.0492, -0.0596,  0.0089,\n",
      "         0.0104, -0.0030,  0.0179,  0.0119,  0.0075])\n",
      "Strain_energy tensor(0.4431, grad_fn=<SumBackward0>)\n",
      "ite 6\n",
      "13.854185819625854\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0019e+00,\n",
      "        1.0016e+00, 4.8349e-04, 9.3517e-05, 6.6759e-04, 9.5219e-06, 2.2157e-04,\n",
      "        4.2566e-04])\n",
      "Wins_grad tensor([-0.0164, -0.0387, -0.0119, -0.0313, -0.0238, -0.0402, -0.0343, -0.0611,\n",
      "         0.0715, -0.0194,  0.0089,  0.0194,  0.0060])\n",
      "Strain_energy tensor(0.4430, grad_fn=<SumBackward0>)\n",
      "ite 7\n",
      "13.164789915084839\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0022e+00,\n",
      "        1.0019e+00, 3.6445e-04, 7.8636e-05, 1.0545e-03, 0.0000e+00, 2.3645e-04,\n",
      "        4.4054e-04])\n",
      "Wins_grad tensor([-0.0313, -0.0402, -0.0283,  0.0000, -0.0536, -0.0313, -0.0313,  0.0119,\n",
      "         0.0015, -0.0387,  0.0119, -0.0015, -0.0015])\n",
      "Strain_energy tensor(0.4430, grad_fn=<SumBackward0>)\n",
      "ite 8\n",
      "13.94986605644226\n",
      "Wins_q tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0023e+00,\n",
      "        1.0022e+00, 3.8455e-04, 8.2905e-06, 1.4665e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.8024e-04])\n",
      "Wins_grad tensor([-0.0447, -0.0358, -0.0343, -0.0507, -0.0313, -0.0045, -0.0477, -0.0030,\n",
      "         0.0104, -0.0611,  0.0060,  0.0879,  0.0089])\n",
      "Strain_energy tensor(0.4430, grad_fn=<SumBackward0>)\n",
      "ite 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     fdES_his\u001b[38;5;241m.\u001b[39mappend(FD_ES\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Grad\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m \u001b[43mfinite_difference_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43midx_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx_Y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnectivity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_dof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_dof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF_fe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mF_fe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\n\u001b[1;32m     41\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     45\u001b[0m         q \u001b[38;5;241m=\u001b[39m optimizer(q, gradients, fd_step)\n",
      "Cell \u001b[0;32mIn[109], line 21\u001b[0m, in \u001b[0;36mfinite_difference_gradient\u001b[0;34m(q, idx_X, idx_Y, r, F_value, connectivity, fixed_dof, F_fe, h)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(idx_Y)):\n\u001b[1;32m     20\u001b[0m     q_vec_plus[idx_Y[j,:]] \u001b[38;5;241m=\u001b[39m q_plus[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mlen\u001b[39m(idx_X)]\n\u001b[0;32m---> 21\u001b[0m SE_plus \u001b[38;5;241m=\u001b[39m \u001b[43mStrain_E\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFDM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_vec_plus\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_dof\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_fe\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 负向扰动计算\u001b[39;00m\n\u001b[1;32m     24\u001b[0m q_vec_minus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(q_vec_plus)\n",
      "Cell \u001b[0;32mIn[108], line 219\u001b[0m, in \u001b[0;36mStrain_E\u001b[0;34m(node_coords, connectivity, fixed_dof, F)\u001b[0m\n\u001b[1;32m    216\u001b[0m     Beam_lens\u001b[38;5;241m.\u001b[39mappend(beam\u001b[38;5;241m.\u001b[39mlength)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Stiffness renewal\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m K_global \u001b[38;5;241m=\u001b[39m \u001b[43massemble_stiffness_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnode_coords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_dof_per_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnectivity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m K_global[fixed_dof, :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    221\u001b[0m K_global[:, fixed_dof] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[108], line 142\u001b[0m, in \u001b[0;36massemble_stiffness_matrix\u001b[0;34m(beams, n_nodes, n_dof_per_node, connectivity)\u001b[0m\n\u001b[1;32m    139\u001b[0m K_global \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((total_dof, total_dof), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (i, j) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(connectivity):\n\u001b[0;32m--> 142\u001b[0m     Matrix_T \u001b[38;5;241m=\u001b[39m \u001b[43mbeams\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSystem_Transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get transformation matrix\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     K_element \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(torch\u001b[38;5;241m.\u001b[39mtranspose(Matrix_T, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    144\u001b[0m                              torch\u001b[38;5;241m.\u001b[39mmatmul(beams[idx]\u001b[38;5;241m.\u001b[39mget_element_stiffness_matrix(), Matrix_T))\n\u001b[1;32m    146\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m n_dof_per_node\n",
      "Cell \u001b[0;32mIn[108], line 105\u001b[0m, in \u001b[0;36mBeam.System_Transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m matrix_T \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m12\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 105\u001b[0m     \u001b[43mmatrix_T\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m lambda_matrix\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m matrix_T\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############## Optimization loop\n",
    "\n",
    "####### Loop start\n",
    "fdES_his = []\n",
    "fd_epochs = 500\n",
    "fd_step =  0.001\n",
    "q = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "# Loop start\n",
    "for iteration in range(fd_epochs + 1):\n",
    "    print('ite', iteration)\n",
    "    \n",
    "    q_vec = torch.zeros(n_elements, requires_grad=True, device=device).clone()\n",
    "    for i in range(len(idx_X)):\n",
    "        q_vec[idx_X[i,:]] = q[i] \n",
    "    for j in range(len(idx_Y)):\n",
    "        q_vec[idx_Y[j,:]] = q[j+len(idx_X)]  \n",
    "    q_vec = q_vec * 1 / r\n",
    "    Q = torch.diag(q_vec) \n",
    "    new_node_coords = FDM(Q, F_value)\n",
    "    height = max(new_node_coords[:,2])\n",
    "    \n",
    "    N_coords = new_node_coords.clone()\n",
    "    FE_str = time.time()\n",
    "    Strain_energy, forces, displacements, ASE, Beam_lens, R, V = Strain_E(N_coords, connectivity, fixed_dof, F_fe)\n",
    "    \n",
    "    ######## FE time   \n",
    "    FD_ES = torch.sum(Strain_energy)\n",
    "    fdES_his.append(FD_ES.item())\n",
    "\n",
    "    # Grad\n",
    "    gradients = finite_difference_gradient(\n",
    "    q=q,\n",
    "    idx_X=idx_X,\n",
    "    idx_Y=idx_Y,\n",
    "    r=r,\n",
    "    F_value=F_value,\n",
    "    connectivity=connectivity,\n",
    "    fixed_dof=fixed_dof,\n",
    "    F_fe=F_fe,\n",
    "    h=1e-5\n",
    ")\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        q = optimizer(q, gradients, fd_step)\n",
    "        # 参数约束\n",
    "        q[:5].clamp_(min=0.8, max=1.0)\n",
    "        q[5:].clamp_(min=0.0, max=2.0)\n",
    "        \n",
    "    frob_norm = torch.norm(gradients)\n",
    "    Wins_q = q\n",
    "    print('Wins_q', Wins_q)    \n",
    "    print('Wins_grad', gradients)\n",
    "    print('Strain_energy',FD_ES)\n",
    "    \n",
    "    ######## Early stopping\n",
    "    if iteration > 0:  \n",
    "        Pre_FD_ES = fdES_his[iteration - 1]  \n",
    "        change = abs(FD_ES - Pre_FD_ES) / Pre_FD_ES\n",
    "        \n",
    "        if change < 1/100000:\n",
    "            count += 1\n",
    "        else:\n",
    "            count = 0 \n",
    "        if count >= patience:\n",
    "            print(f\"Early stopping at iteration {iteration}: Total_ES change < 1%% for {patience} consecutive iterations.\")\n",
    "            break \n",
    "\n",
    "    \n",
    "print(\"Optimization completed.\")\n",
    "print(q)\n",
    "print(\"Estrain:\", FD_ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20949e9-2a61-44ba-8a64-7d01a5e52eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 第一条曲线（自动微分 - ES_his）\n",
    "color1 = 'tab:blue'\n",
    "ax1.set_xlabel('Iterations')\n",
    "ax1.set_ylabel('Strain Energy', color='black')\n",
    "line1 = ax1.plot(ES_his, \n",
    "                label='AutoDiff (ES_his)', \n",
    "                color=color1, \n",
    "                linewidth=2,\n",
    "                linestyle='-')\n",
    "\n",
    "# 第二条曲线（有限差分 - fdES_his）\n",
    "color2 = 'tab:red'\n",
    "line2 = ax1.plot(fdES_his, \n",
    "                label='FiniteDiff (fdES_his)', \n",
    "                color=color2, \n",
    "                linewidth=2,\n",
    "                linestyle='--')\n",
    "\n",
    "# 标记点设置（同时标记两条曲线）\n",
    "marker_points = [0, *range(50, max(len(ES_his), len(fdES_his)), 50), max(len(ES_his), len(fdES_his))-1]\n",
    "\n",
    "for point in marker_points:\n",
    "    if point < len(ES_his):\n",
    "        ax1.scatter(point, ES_his[point], color=color1, zorder=5, s=60)\n",
    "        ax1.text(point, ES_his[point], \n",
    "                f'Auto: {ES_his[point]:.2e}',\n",
    "                ha='right' if point == len(ES_his)-1 else 'left',\n",
    "                va='bottom',\n",
    "                fontsize=8,\n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "    \n",
    "    if point < len(fdES_his):\n",
    "        ax1.scatter(point, fdES_his[point], color=color2, zorder=5, s=60, marker='s')\n",
    "        ax1.text(point, fdES_his[point], \n",
    "                f'FD: {fdES_his[point]:.2e}',\n",
    "                ha='right' if point == len(fdES_his)-1 else 'left',\n",
    "                va='top',\n",
    "                fontsize=8,\n",
    "                bbox=dict(facecolor='white', alpha=0.7))\n",
    "\n",
    "# 图例和样式\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.title('Strain Energy Comparison: AutoDiff vs FiniteDiff')\n",
    "\n",
    "# 自动调整y轴范围\n",
    "combined = ES_his + fdES_his\n",
    "ax1.set_ylim(min(combined)*0.95, max(combined)*1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ES_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c31755-1a58-46b0-bb86-70bd1918048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'black'\n",
    "ax1.set_ylabel('Strain energy', color=color)\n",
    "ax1.plot(range(len(ES_his)), ES_his, label='Total_Es', color=color, linewidth=2, linestyle='--')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Mark specific points\n",
    "marker_points = [\n",
    "    0,  # First point\n",
    "    *range(50, len(ES_his), 50),  # Every 200th point\n",
    "    len(ES_his)-1  # Last point\n",
    "]\n",
    "\n",
    "for point in marker_points:\n",
    "    ax1.scatter(point, ES_his[point], color='blue', zorder=5)\n",
    "    ax1.text(point, ES_his[point], \n",
    "             f'({ES_his[point]:.4f})',\n",
    "             ha='right' if point == len(ES_his)-1 else 'left',\n",
    "             va='bottom',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "ax1.legend(loc='upper right')\n",
    "plt.title('Total_Strain energy vs. Iterations')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Es_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babc17a8-5f05-4ac7-87b1-3b494f829ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "Ratio = torch.tensor(Ratio)\n",
    "\n",
    "\n",
    "color = 'red'\n",
    "ax1.set_ylabel('Axial_se_Ratio', color=color)\n",
    "ax1.plot(range(len(Ratio)), Ratio.cpu().numpy(), label='LP', color=color, linewidth=2, linestyle='--')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Mark specific points\n",
    "marker_points = [\n",
    "    0,  # First point\n",
    "    *range(200, len(Ratio), 200),  # Every 200th point\n",
    "    len(Ratio)-1  # Last point\n",
    "]\n",
    "\n",
    "for point in marker_points:\n",
    "    ax1.scatter(point, Ratio[point], color='blue', zorder=5)\n",
    "    ax1.text(point, Ratio[point]* 1.02, \n",
    "             f'({Ratio[point]:.4f})',\n",
    "             ha='right' if point == len(Ratio)-1 else 'left',\n",
    "             va='bottom',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "ax1.legend(loc='upper right')\n",
    "plt.title('Axial_Ratio vs. Iterations')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Axial_ratio_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a2edd-8747-4b1f-abdc-4f28f79eef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "Ratio = torch.tensor(Ratio)\n",
    "LP_his = torch.tensor(LP_his)\n",
    "\n",
    "color = 'red'\n",
    "ax1.set_ylabel('Load_path', color=color)\n",
    "ax1.plot(range(len(LP_his)), LP_his.cpu().numpy(), label='LP', color=color, linewidth=2, linestyle='--')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Mark specific points\n",
    "marker_points = [\n",
    "    0,  # First point\n",
    "    *range(200, len(LP_his), 200),  \n",
    "    len(LP_his)-1  # Last point\n",
    "]\n",
    "\n",
    "for point in marker_points:\n",
    "    ax1.scatter(point, LP_his[point], color='blue', zorder=5)\n",
    "    ax1.text(point, LP_his[point]* 1.002, \n",
    "             f'({LP_his[point]:.4f})',\n",
    "             ha='right' if point == len(Ratio)-1 else 'left',\n",
    "             va='bottom',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'))\n",
    "\n",
    "ax1.legend(loc='upper right')\n",
    "plt.title('Load_path vs. Iterations')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Load_path_his.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c530ee70-b011-4232-b37b-4455be1dab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf2ef4-6d3f-4269-9e40-eb488a7b29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### SCaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scaling::\n",
    "# Q_N = torch.diag(q_vec) * 1 / r * 8.9244 / 12 # scaling\n",
    "# new_coords = FDM(Q_N, F_value)\n",
    "# height = max(new_coords[:,2])\n",
    "\n",
    "\n",
    "# ####### FDM time\n",
    "# FDM_time = (time.time() - iter_start) / 60\n",
    "\n",
    "# N_coords = new_coords.clone()\n",
    "# FE_str = time.time()\n",
    "# Strain_energy, forces, displacements, ASE, Beam_lens, R, V = Strain_E(N_coords, connectivity, fixed_dof, F_fe)\n",
    "\n",
    "# ######## FE time\n",
    "# FE_time = (time.time() - FE_str) / 60       \n",
    "# force = abs(forces[:, 0, 0])\n",
    "# load_path = torch.dot(force , Beam_lens)\n",
    "\n",
    "# Total_ES = torch.sum(Strain_energy) \n",
    "# Axial_rate = torch.sum(ASE) / Total_ES\n",
    "\n",
    "# Volume = torch.sum(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d51e3f-c2ad-46f5-9b0f-107a761ac2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Visual\n",
    "#############################################################################################################\n",
    "## Visualization 1\n",
    "x_orig = grid_points[:, 0].cpu().detach().numpy()\n",
    "y_orig = grid_points[:, 1].cpu().detach().numpy()\n",
    "z_orig = grid_points[:, 2].cpu().detach().numpy()\n",
    "\n",
    "new_coords = new_node_coords\n",
    "x_fdm = new_coords[:, 0].cpu().detach().numpy()\n",
    "y_fdm = new_coords[:, 1].cpu().detach().numpy()\n",
    "z_fdm = new_coords[:, 2].cpu().detach().numpy()\n",
    "\n",
    "Max_height = max(z_fdm)\n",
    "fig = go.Figure()\n",
    "\n",
    "force_np = force.cpu().detach().numpy()\n",
    "abs_forces = np.abs(force_np)\n",
    "abs_forces = np.round(abs_forces)\n",
    "\n",
    "ratio = [0.01, 0.3, 0.7, 0.9]  \n",
    "max_force = np.max(abs_forces)  \n",
    "thresholds = np.array(ratio) * max_force  \n",
    "width_levels = np.digitize(abs_forces, thresholds) \n",
    "line_widths = [1, 3, 5, 7, 9] \n",
    "\n",
    "# First clear all existing traces (optional, depends on your needs)\n",
    "fig.data = []\n",
    "\n",
    "for connection in connectivity:\n",
    "    i, j = connection\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_orig[i-1], x_orig[j-1]],\n",
    "        y=[y_orig[i-1], y_orig[j-1]],\n",
    "        z=[z_orig[i-1], z_orig[j-1]],\n",
    "        mode='lines',\n",
    "        line=dict(\n",
    "            color='blue',\n",
    "            width=1\n",
    "        ),\n",
    "        opacity=0.1,  # 修改 opacity 为数值（0.0~1.0），而不是字符串\n",
    "        name='Grid',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "# Add FDM solution traces with width based on force magnitude\n",
    "for idx, connection in enumerate(connectivity):\n",
    "    i, j = connection\n",
    "    width_level = width_levels[idx]  # digitize returns 1-based index\n",
    "    current_width = line_widths[width_level]\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[i-1], x_fdm[j-1]],\n",
    "        y=[y_fdm[i-1], y_fdm[j-1]],\n",
    "        z=[z_fdm[i-1], z_fdm[j-1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='firebrick', width=current_width),\n",
    "        name=f'FDM solution (Level {width_level+1})',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "\n",
    "arrow_scale = 1.2  # Adjust this to change arrow size\n",
    "for node in Free_nodes:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[node-1], x_fdm[node-1]],\n",
    "        y=[y_fdm[node-1], y_fdm[node-1]],\n",
    "        z=[z_fdm[node-1], z_fdm[node-1] - arrow_scale],\n",
    "        mode='lines',\n",
    "        line=dict(\n",
    "            color='red',\n",
    "            width=1  # Arrow shaft width\n",
    "        ),\n",
    "        name=f'Load at Node {node}',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    # Add arrow head\n",
    "    fig.add_trace(go.Cone(\n",
    "        x=[x_fdm[node-1]],\n",
    "        y=[y_fdm[node-1]],\n",
    "        z=[z_fdm[node-1] - arrow_scale],\n",
    "        u=[0],\n",
    "        v=[0],\n",
    "        w=[-0.1],\n",
    "        sizemode=\"absolute\",\n",
    "        sizeref=0.4,\n",
    "        anchor=\"tip\",\n",
    "        colorscale=[[0, 'red'], [1, 'red']],\n",
    "        showscale=False\n",
    "    ))\n",
    "\n",
    "\n",
    "# Add fixed nodes\n",
    "for node in Fixed_nodes:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[node-1]],\n",
    "        y=[y_fdm[node-1]],\n",
    "        z=[z_fdm[node-1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=5, color='black'),\n",
    "        name=f'Fixed Node {node}',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    # 白点配置\n",
    "    \n",
    "node_marker_config = {\n",
    "    'size': 3,          \n",
    "    'color': 'white',   \n",
    "    'opacity': 1,       \n",
    "    'line': {           \n",
    "        'width': 4,     \n",
    "        'color': 'black' \n",
    "    }\n",
    "}\n",
    "\n",
    "# 然后在使用时：\n",
    "# 将Fixed_nodes从Tensor转换为list\n",
    "if torch.is_tensor(Fixed_nodes):\n",
    "    Fixed_nodes_list = Fixed_nodes.cpu().tolist()\n",
    "else:\n",
    "    Fixed_nodes_list = list(Fixed_nodes)\n",
    "    \n",
    "all_nodes = list(set(Fixed_nodes_list + Free_nodes)) \n",
    "for node in all_nodes:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[node-1]],\n",
    "        y=[y_fdm[node-1]],\n",
    "        z=[z_fdm[node-1]],\n",
    "        mode='markers',\n",
    "        marker=node_marker_config,\n",
    "        name=f'Node {node}',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    \n",
    "         \n",
    "force_traces = []\n",
    "for idx, connection in enumerate(connectivity):\n",
    "    i, j = connection\n",
    "    mid_x = (x_fdm[i-1] + x_fdm[j-1]) / 2\n",
    "    mid_y = (y_fdm[i-1] + y_fdm[j-1]) / 2\n",
    "    mid_z = (z_fdm[i-1] + z_fdm[j-1]) / 2\n",
    "    trace = go.Scatter3d(\n",
    "        x=[mid_x],\n",
    "        y=[mid_y],\n",
    "        z=[mid_z],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=1, color='green'),\n",
    "        text=[f\"{force_np[idx]:.0f}\"],\n",
    "        textposition='top center',\n",
    "        textfont=dict(size=8),\n",
    "        name=f'Force {idx+1}',\n",
    "        visible=True\n",
    "    )\n",
    "    force_traces.append(trace)\n",
    "    fig.add_trace(trace)\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"right\",\n",
    "            x=0.1,\n",
    "            y=1.1,\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"✅ Show forces\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [True] * len(fig.data)}],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"❌ Hide forces\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [True] * (len(fig.data) - len(force_traces)) + [False] * len(force_traces)}],\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            \n",
    "            title=''\n",
    "        ),\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    title='OPT',\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0.05,  # X position (0-1, left to right)\n",
    "            y=0.95,  # Y position (0-1, bottom to top)\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            text=f\"Strain energy= {Total_ES:.4f}, Volume = {Volume:.4f}, Max_height = {Max_height:.4f}, Load_path  = {load_path :.4f} \",\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                size=14,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            bgcolor=\"white\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "            borderpad=4\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "fig.write_html(\"E_strain Opt(Z).html\")\n",
    "\n",
    "print(f\"Strain energy= {Total_ES:.4f}, Volume = {Volume:.4f}, Max_height = {Max_height:.4f}, Load_path  = {load_path :.4f} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04141fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import compas\n",
    "# from compas_view2.app import App\n",
    "\n",
    "# # 猴子补丁解决缺失模块问题\n",
    "# import sys\n",
    "# import types\n",
    "# sys.modules['compas.robots'] = types.ModuleType('compas.robots')\n",
    "\n",
    "# # 现在可以正常导入\n",
    "# from compas_view2.app import App\n",
    "\n",
    "# print(f\"COMPAS版本: {compas.__version__}\")\n",
    "\n",
    "# viewer = App()\n",
    "# viewer.add_point([0,0,0], size=20, color=(1,0,0))\n",
    "# viewer.add_line([(0,0,0), (1,1,1)], linewidth=3)\n",
    "# viewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3662f252-0018-40cd-a1e8-8f07f1a760d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######## Fe_test\n",
    "####### Set FE context\n",
    "F_test = torch.zeros(total_dof, dtype=torch.float32, device=device)\n",
    "f_test = [2] * len(Free_nodes)  # The force type\n",
    "F_vatest = torch.tensor([-1] * len(Free_nodes), device=device) * 1000 # The force value/direction\n",
    "\n",
    "for idx, i in enumerate(Free_nodes):\n",
    "    F_test[6 * (i - 1) + f_test [idx]] = F_vatest [idx]  # unit: KN / KN*m\n",
    "\n",
    "\n",
    "Test_coords = new_coords.clone()\n",
    "Strain_energy_test, forces_test, displacements_t, _, Beam_lens, _,_ = Strain_E(Test_coords, connectivity, fixed_dof, F_test)\n",
    "\n",
    "force_t = forces_test[:, 0, 0]\n",
    "load_path_t = torch.dot(force_t , Beam_lens)\n",
    "print('load_path', load_path_t)\n",
    "\n",
    "Total_ES_t = torch.sum(Strain_energy_test)\n",
    "print(Total_ES_t)\n",
    "\n",
    "SED = Total_ES_t / Volume\n",
    "\n",
    "\n",
    "x_orig = grid_points[:, 0].cpu().detach().numpy()\n",
    "y_orig = grid_points[:, 1].cpu().detach().numpy()\n",
    "z_orig = grid_points[:, 2].cpu().detach().numpy()\n",
    "\n",
    "x_fdm = Test_coords[:, 0].cpu().detach().numpy()\n",
    "y_fdm = Test_coords[:, 1].cpu().detach().numpy()\n",
    "z_fdm = Test_coords[:, 2].cpu().detach().numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "force_np = force_t.cpu().detach().numpy()\n",
    "abs_forces = np.abs(force_np)\n",
    "\n",
    "# Define 5 quantiles for force magnitude categorization\n",
    "quantiles = np.quantile(abs_forces, [0.1, 0.6, 0.7, 0.85, 1.0])\n",
    "\n",
    "# Define corresponding line widths for each level\n",
    "line_widths = [1, 2, 4, 6, 8, 10]  # Adjust these values as needed\n",
    "\n",
    "# Create a list to store which width level each beam belongs to\n",
    "width_levels = np.digitize(abs_forces, quantiles)\n",
    "\n",
    "# First clear all existing traces (optional, depends on your needs)\n",
    "fig.data = []\n",
    "\n",
    "# Add grid traces (original structure)\n",
    "for connection in connectivity:\n",
    "    i, j = connection\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_orig[i-1], x_orig[j-1]],\n",
    "        y=[y_orig[i-1], y_orig[j-1]],\n",
    "        z=[z_orig[i-1], z_orig[j-1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', width=1),\n",
    "        name='Grid',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "# Add FDM solution traces with width based on force magnitude\n",
    "for idx, connection in enumerate(connectivity):\n",
    "    i, j = connection\n",
    "    width_level = width_levels[idx]  # digitize returns 1-based index\n",
    "    current_width = line_widths[width_level]\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[i-1], x_fdm[j-1]],\n",
    "        y=[y_fdm[i-1], y_fdm[j-1]],\n",
    "        z=[z_fdm[i-1], z_fdm[j-1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', width=current_width),\n",
    "        name=f'FDM solution (Level {width_level+1})',\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "# Add fixed nodes\n",
    "for node in Fixed_nodes:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[node-1]],\n",
    "        y=[y_fdm[node-1]],\n",
    "        z=[z_fdm[node-1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=5, color='black'),\n",
    "        name=f'Fixed Node {node}',\n",
    "        showlegend=False\n",
    "    ))\n",
    "    \n",
    "         \n",
    "force_traces = []\n",
    "for idx, connection in enumerate(connectivity):\n",
    "    i, j = connection\n",
    "    mid_x = (x_fdm[i-1] + x_fdm[j-1]) / 2\n",
    "    mid_y = (y_fdm[i-1] + y_fdm[j-1]) / 2\n",
    "    mid_z = (z_fdm[i-1] + z_fdm[j-1]) / 2\n",
    "    trace = go.Scatter3d(\n",
    "        x=[mid_x],\n",
    "        y=[mid_y],\n",
    "        z=[mid_z],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=1, color='green'),\n",
    "        text=[f\"{force_np[idx]:.0f}\"],\n",
    "        textposition='top center',\n",
    "        textfont=dict(size=8),\n",
    "        name=f'Force {idx+1}',\n",
    "        visible=True\n",
    "    )\n",
    "    force_traces.append(trace)\n",
    "    fig.add_trace(trace)\n",
    "    \n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            type=\"buttons\",\n",
    "            direction=\"right\",\n",
    "            x=0.1,\n",
    "            y=1.1,\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"✅ Show forces\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [True] * len(fig.data)}],\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"❌ Hide forces\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [True] * (len(fig.data) - len(force_traces)) + [False] * len(force_traces)}],\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    # title='Test with lateral load (Y)',\n",
    "    title='Test with gravity load',\n",
    "    annotations=[\n",
    "        dict(\n",
    "            x=0.05,  # X position (0-1, left to right)\n",
    "            y=0.95,  # Y position (0-1, bottom to top)\n",
    "            xref=\"paper\",\n",
    "            yref=\"paper\",\n",
    "            text=f\"Strain energy = {Total_ES_t:.4f}, Volume = {Volume:.4f}, Max_height = {Max_height:.4f}, , Load_path  = {load_path_t :.4f}\",\n",
    "            showarrow=False,\n",
    "            font=dict(\n",
    "                size=14,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            bgcolor=\"white\",\n",
    "            bordercolor=\"black\",\n",
    "            borderwidth=1,\n",
    "            borderpad=4\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"E_strain Test(Z).html\")\n",
    "print(f\"Strain energy = {Total_ES_t:.4f}, Volume = {Volume:.4f}, Max_height = {Max_height:.4f}, , Load_path  = {load_path_t :.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_force_test(direction):\n",
    "    \"\"\"Run force test in specified direction (0, 1, or 2)\"\"\"\n",
    "    F_test = torch.zeros(total_dof, dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Set force type and value based on direction\n",
    "    if direction == 2:\n",
    "        F_vatest = torch.tensor([-1] * len(Free_nodes), device=device) * 1000  # Negative for direction 2\n",
    "    else:\n",
    "        F_vatest = torch.tensor([1] * len(Free_nodes), device=device) * 1000\n",
    "    \n",
    "    # Apply forces in specified direction\n",
    "    for idx, i in enumerate(Free_nodes):\n",
    "        F_test[6 * (i - 1) + direction] = F_vatest[idx]  # unit: KN / KN*m\n",
    "\n",
    "    Test_coords = new_coords.clone()\n",
    "    Strain_energy_test, forces_test, _, _, Beam_lens, _,_ = Strain_E(Test_coords, connectivity, fixed_dof, F_test)\n",
    "    \n",
    "    force_t = forces_test[:, 0, 0]\n",
    "    load_path_t = torch.dot(force_t, Beam_lens)\n",
    "    Total_ES_t = torch.sum(Strain_energy_test)\n",
    "    \n",
    "    return {\n",
    "        'direction': direction,\n",
    "        'strain_energy': Total_ES_t.item(),\n",
    "        'volume': Volume,\n",
    "        'max_height': Max_height,\n",
    "        'load_path': load_path_t.item()\n",
    "    }\n",
    "\n",
    "# Run tests for all three directions\n",
    "results = []\n",
    "for direction in [0, 1, 2]:\n",
    "    results.append(run_force_test(direction))\n",
    "\n",
    "# Prepare output text\n",
    "output_lines = []\n",
    "for res in results:\n",
    "    line = (f\"Direction {res['direction']}: \"\n",
    "            f\"Strain energy = {res['strain_energy']:.4f}, \"\n",
    "            f\"Volume = {res['volume']:.4f}, \"\n",
    "            f\"Max_height = {res['max_height']:.4f}, \"\n",
    "            f\"Load_path = {res['load_path']:.4f}\")\n",
    "    output_lines.append(line)\n",
    "\n",
    "# Write to text file\n",
    "with open(\"force_test_results.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(output_lines))\n",
    "\n",
    "print(\"Test results saved to force_test_results.txt\")\n",
    "print(\"\\n\".join(output_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721bb84-1438-4a46-aed7-aab9bf705e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "## Visualization 2\n",
    "x_fdm = new_node_coords[:, 0].cpu().detach().numpy()\n",
    "y_fdm = new_node_coords[:, 1].cpu().detach().numpy()\n",
    "z_fdm = new_node_coords[:, 2].cpu().detach().numpy()\n",
    "N_coords_t = N_coords\n",
    "New_Coordinates_t = torch.zeros(n_nodes * 3, dtype=torch.float32, device=device)\n",
    "for n in range(n_nodes):\n",
    "    New_Coordinates_t[3*n : 3*n+3] = N_coords_t[3*n : 3*n+3] + displacements_t[6*n : 6*n+3]\n",
    "New_Coordinates_t = New_Coordinates_t.view(n_nodes, 3).clone()\n",
    "x_def = New_Coordinates_t[:, 0].cpu().detach().numpy()\n",
    "y_def = New_Coordinates_t[:, 1].cpu().detach().numpy()\n",
    "z_def = New_Coordinates_t[:, 2].cpu().detach().numpy()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for connection in connectivity:\n",
    "    i, j = connection\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[i-1], x_fdm[j-1]],\n",
    "        y=[y_fdm[i-1], y_fdm[j-1]],\n",
    "        z=[z_fdm[i-1], z_fdm[j-1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='blue', width=4),\n",
    "        name='Original Geometry'\n",
    "    ))\n",
    "\n",
    "\n",
    "for connection in connectivity:\n",
    "    i, j = connection\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_def[i-1], x_def[j-1]],\n",
    "        y=[y_def[i-1], y_def[j-1]],\n",
    "        z=[z_def[i-1], z_def[j-1]],\n",
    "        mode='lines',\n",
    "        line=dict(color='red', width=4),\n",
    "        name='Deformed Geometry'\n",
    "    ))\n",
    "\n",
    "\n",
    "for node in Fixed_nodes:\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=[x_fdm[node-1]],\n",
    "        y=[y_fdm[node-1]],\n",
    "        z=[z_fdm[node-1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=5, color='black'),\n",
    "#         text=[f'Node {node}'],\n",
    "        textposition='top center',\n",
    "        name=f'Fixed Node {node}'\n",
    "    ))    \n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            showbackground=False,\n",
    "            showgrid=False,\n",
    "            showline=False,\n",
    "            showticklabels=False,\n",
    "            title=''\n",
    "        ),\n",
    "        aspectmode='data'\n",
    "    ),\n",
    "    title='Deformation Comparison: Original vs. Deformed Geometry (FE Analysis)',\n",
    "    legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_html(\"Deformation.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33878dd4-494b-4396-b8fe-ffa9533df466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Visualization 3\n",
    "\n",
    "# q_ = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 0.1, 0.1], requires_grad=True, device=device)\n",
    "# q_vec = torch.zeros(n_elements, requires_grad=True, device=device).clone()\n",
    "# for i in range(len(idx_X)):\n",
    "#     q_vec[idx_X[i,:]] = q_[i] \n",
    "# for j in range(len(idx_Y)):\n",
    "#     q_vec[idx_Y[j,:]] = q_[j+len(idx_X)]  \n",
    "# Q = torch.diag(q_vec) * 1 / r  # scaling\n",
    "# new_node_coords = FDM(Q, F_value) \n",
    "\n",
    "# x_orig = grid_points[:, 0].cpu().detach().numpy()\n",
    "# y_orig = grid_points[:, 1].cpu().detach().numpy()\n",
    "# z_orig = grid_points[:, 2].cpu().detach().numpy()\n",
    "\n",
    "# x_fdm = new_node_coords[:, 0].cpu().detach().numpy()\n",
    "# y_fdm = new_node_coords[:, 1].cpu().detach().numpy()\n",
    "# z_fdm = new_node_coords[:, 2].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "# fig = go.Figure()\n",
    "\n",
    "\n",
    "# for connection in connectivity:\n",
    "#     i, j = connection\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=[x_orig[i-1], x_orig[j-1]],\n",
    "#         y=[y_orig[i-1], y_orig[j-1]],\n",
    "#         z=[z_orig[i-1], z_orig[j-1]],\n",
    "#         mode='lines',\n",
    "#         line=dict(color='blue', width=1),\n",
    "#         name='Grid',\n",
    "#         showlegend=False\n",
    "#     ))\n",
    "\n",
    "\n",
    "# for connection in connectivity:\n",
    "#     i, j = connection\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=[x_fdm[i-1], x_fdm[j-1]],\n",
    "#         y=[y_fdm[i-1], y_fdm[j-1]],\n",
    "#         z=[z_fdm[i-1], z_fdm[j-1]],\n",
    "#         mode='lines',\n",
    "#         line=dict(color='red', width=4),\n",
    "#         name='Initial Geometry',\n",
    "#         showlegend=False\n",
    "#     ))\n",
    "\n",
    "\n",
    "# for node in Free_nodes:\n",
    "    \n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=[x_fdm[node-1], x_fdm[node-1]],  \n",
    "#         y=[y_fdm[node-1], y_fdm[node-1]],  \n",
    "#         z=[z_fdm[node-1], z_fdm[node-1] - 2.0], \n",
    "#         mode='lines',\n",
    "#         line=dict(color='green', width=3),\n",
    "#         showlegend=False,\n",
    "#         hoverinfo='none'\n",
    "#     ))\n",
    "    \n",
    "#     fig.add_trace(go.Cone(\n",
    "#         x=[x_fdm[node-1]],\n",
    "#         y=[y_fdm[node-1]],\n",
    "#         z=[z_fdm[node-1] - 2.0],  \n",
    "#         u=[0], v=[0], w=[-0.5], \n",
    "#         sizemode='scaled',\n",
    "#         sizeref=0.9,\n",
    "#         colorscale=[[0, 'green'], [1, 'green']],\n",
    "#         showscale=False\n",
    "#     ))\n",
    "\n",
    "\n",
    "\n",
    "# for node in Fixed_nodes:\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=[x_fdm[node-1]],\n",
    "#         y=[y_fdm[node-1]],\n",
    "#         z=[z_fdm[node-1]],\n",
    "#         mode='markers+text',\n",
    "#         marker=dict(size=5, color='black'),\n",
    "# #         text=[f'Node {node}'],\n",
    "#         textposition='top center',\n",
    "#         name=f'Fixed Node {node}',\n",
    "#         showlegend=False\n",
    "#     ))    \n",
    "\n",
    "# fig.update_layout(\n",
    "#     scene=dict(\n",
    "#         xaxis=dict(\n",
    "#             showbackground=False,\n",
    "#             showgrid=False,\n",
    "#             showline=False,\n",
    "#             showticklabels=False,\n",
    "#             title=''\n",
    "#         ),\n",
    "#         yaxis=dict(\n",
    "#             showbackground=False,\n",
    "#             showgrid=False,\n",
    "#             showline=False,\n",
    "#             showticklabels=False,\n",
    "#             title=''\n",
    "#         ),\n",
    "#         zaxis=dict(\n",
    "#             showbackground=False,\n",
    "#             showgrid=False,\n",
    "#             showline=False,\n",
    "#             showticklabels=False,\n",
    "#             title=''\n",
    "#         ),\n",
    "#         aspectmode='data'\n",
    "#     ),\n",
    "#     title='Initialization for FE solver',\n",
    "#     legend=dict(\n",
    "#         yanchor=\"top\",\n",
    "#         y=0.99,\n",
    "#         xanchor=\"left\",\n",
    "#         x=0.01\n",
    "#     ),\n",
    "#     annotations=[\n",
    "#         dict(\n",
    "#             x=0.05,\n",
    "#             y=0.95,\n",
    "#             xref=\"paper\",\n",
    "#             yref=\"paper\",\n",
    "#             text=f\"Load: Gravity {20} KN\\n\",\n",
    "#             showarrow=False,\n",
    "#             font=dict(size=14, color=\"black\"),\n",
    "#             bgcolor=\"white\",\n",
    "#             bordercolor=\"black\",\n",
    "#             borderwidth=1,\n",
    "#             borderpad=4\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# fig.show()\n",
    "\n",
    "# fig.write_html(\"Problem context.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcdef8a-c4a7-461d-907d-80a3b8bb91e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_FE(iteration, new_node_coords, New_Coordinates, \n",
    "#                       connectivity, Free_nodes, Fixed_nodes, force, save_dir=\"visualizations\"):\n",
    "    \n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#     x_fdm = new_node_coords[:, 0].cpu().detach().numpy()\n",
    "#     y_fdm = new_node_coords[:, 1].cpu().detach().numpy()\n",
    "#     z_fdm = new_node_coords[:, 2].cpu().detach().numpy()\n",
    "\n",
    "#     x_def = New_Coordinates[:, 0].cpu().detach().numpy()\n",
    "#     y_def = New_Coordinates[:, 1].cpu().detach().numpy()\n",
    "#     z_def = New_Coordinates[:, 2].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     for connection in connectivity:\n",
    "#         i, j = connection\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=[x_fdm[i-1], x_fdm[j-1]],\n",
    "#             y=[y_fdm[i-1], y_fdm[j-1]],\n",
    "#             z=[z_fdm[i-1], z_fdm[j-1]],\n",
    "#             mode='lines',\n",
    "#             line=dict(color='blue', width=4),\n",
    "#             name='Original Geometry'\n",
    "#         ))\n",
    "    \n",
    "    \n",
    "#     for connection in connectivity:\n",
    "#         i, j = connection\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=[x_def[i-1], x_def[j-1]],\n",
    "#             y=[y_def[i-1], y_def[j-1]],\n",
    "#             z=[z_def[i-1], z_def[j-1]],\n",
    "#             mode='lines',\n",
    "#             line=dict(color='red', width=4),\n",
    "#             name='Deformed Geometry'\n",
    "#         ))\n",
    "    \n",
    "    \n",
    "    \n",
    "#     for node in Fixed_nodes:\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=[x_fdm[node-1]],\n",
    "#             y=[y_fdm[node-1]],\n",
    "#             z=[z_fdm[node-1]],\n",
    "#             mode='markers+text',\n",
    "#             marker=dict(size=5, color='black'),\n",
    "#     #         text=[f'Node {node}'],\n",
    "#             textposition='top center',\n",
    "#             name=f'Fixed Node {node}'\n",
    "#         )) \n",
    "\n",
    "    \n",
    "#     fig.update_layout(\n",
    "#         scene=dict(\n",
    "#             xaxis_title='X',\n",
    "#             yaxis_title='Y',\n",
    "#             zaxis_title='Z',\n",
    "#             aspectmode='data'\n",
    "#         ),\n",
    "#         title='Deformed Geometry (FE Analysis)',\n",
    "#         legend=dict(yanchor=\"top\", y=0.99, xanchor=\"left\", x=0.01)\n",
    "#     )\n",
    "\n",
    "#     filename = os.path.join(save_dir, f\"Deformation_iter_{iteration}.html\")\n",
    "#     fig.write_html(filename)\n",
    "#     print(f\"Saved deformation to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
